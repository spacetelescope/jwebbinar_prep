{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"title_ID\"></a>\n",
    "# JWST Data Products: Ensemble Processing Products\n",
    "--------------------------------------------------------------\n",
    "**Author**: Alicia Canipe (acanipe@stsci.edu) | **Latest update**: March 24, 2021.\n",
    "\n",
    "## Table of contents\n",
    "1. [Introduction](#intro)\n",
    "   1. [Resources](#resources)   \n",
    "2. [Data in MAST](#mast)\n",
    "3. [Example data for this exercise](#example)\n",
    "4. [Data products: stage 3 (combined, rectified exposures)](#stage3)\n",
    "    1. [Imaging](#s3-imaging)\n",
    "        1. [Input](#s3-imaging-input)\n",
    "        2. [Output](#s3-imaging-output)\n",
    "    2. [Spectroscopy](#s3-spectroscopy)\n",
    "        1. [Input](#s3-spectroscopy-input)\n",
    "        2. [Output](#s3-spectroscopy-output)\n",
    "    3. [Aperture Masking Interferometry (AMI)](#s3-ami)\n",
    "        1. [Input](#s3-ami-input)\n",
    "        2. [Output](#s3-ami-output)\n",
    "    4. [Coronagraphy](#s3-coronagraphy)\n",
    "        1. [Input](#s3-coronagraphy-input)\n",
    "        2. [Output](#s3-coronagraphy-output)\n",
    "    5. [Time Series Observation (TSO)](#s3-tso)\n",
    "        1. [Input](#s3-tso-input)\n",
    "        2. [Output](#s3-tso-output)\n",
    "5. [Examining the products](#examine)\n",
    "    1. [Catalogs](#catalogs)\n",
    "    2. [Combined image](#comb-image)\n",
    "    3. [Combined spectrum](#comb-spec)\n",
    "6. [The end](#bye-bye)\n",
    "7. [Exercise](#exercise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.<font color='white'>-</font>Introduction <a class=\"anchor\" id=\"intro\"></a>\n",
    "------------------\n",
    "\n",
    "Welcome to the final module about JWST data products! In this module, we will learn more about the data products associated with Stage 3 in the JWST Calibration Pipeline (hereafter, the pipeline), the final stage of processing. You made it. \n",
    "\n",
    "### A.<font color='white'>-</font>Resources<a class=\"anchor\" id=\"resources\"></a>\n",
    "\n",
    "\n",
    "Visit the [webpage for JWebbinars](https://www.stsci.edu/jwst/science-execution/jwebbinars) to find resources for:\n",
    "* The Mikulski Archive for Space Telescopes (MAST) \n",
    "* JWST Documentation (JDox) for JWST data products\n",
    "* The most up-to-date information about JWST data products in the pipeline readthedocs\n",
    "* Pipeline roadmaps for when to recalibrate your data\n",
    "\n",
    "Before we begin, import the libraries used in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module with functions to get information about objects:\n",
    "import os\n",
    "\n",
    "# To get data from Box\n",
    "import requests\n",
    "\n",
    "# Numpy library:\n",
    "import numpy as np\n",
    "\n",
    "# Scipy tools\n",
    "from scipy.signal import medfilt\n",
    "\n",
    "# Astropy tools:\n",
    "from astropy.utils.data import download_file\n",
    "from astropy.stats import sigma_clip\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits, ascii\n",
    "\n",
    "# The JWST models:\n",
    "from jwst import datamodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And set up matplotlib for plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Use this version if you want interactive plots\n",
    "# %matplotlib notebook\n",
    "\n",
    "# Use this version for non-interactive plots (easier scrolling of the notebook)\n",
    "%matplotlib inline\n",
    "\n",
    "# These gymnastics are needed to make the sizes of the figures\n",
    "# be the same in both the inline and notebook versions\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches': None}\n",
    "\n",
    "mpl.rcParams['savefig.dpi'] = 80\n",
    "mpl.rcParams['figure.dpi'] = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, create some convenience functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url):\n",
    "    \"\"\"Download into the current working directory the\n",
    "    file from Box given the direct URL\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        URL to the file to be downloaded\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    download_filename : str\n",
    "        Name of the downloaded file\n",
    "    \"\"\"\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError(\"Wrong URL - {}\".format(url))\n",
    "    download_filename = response.headers['Content-Disposition'].split('\"')[1]\n",
    "    with open(download_filename, 'wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    return download_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image(data_2d, vmin, vmax, xpixel=None, ypixel=None, title=None):\n",
    "    ''' Function to generate a 2D image of the data, \n",
    "    with an option to highlight a specific pixel.\n",
    "    '''\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot()\n",
    "    plt.imshow(data_2d, origin='lower', cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    if xpixel and ypixel:\n",
    "        plt.plot(xpixel, ypixel, marker='o', color='red', label='Selected Pixel')\n",
    "\n",
    "    plt.xlabel('Pixel column')\n",
    "    plt.ylabel('Pixel row')\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(left=0.15)\n",
    "    plt.colorbar(label='MJy/sr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_with_cat(data_2d, catalog, flux_limit, vmin, vmax, title=None):\n",
    "    ''' Function to generate a 2D image of the data, \n",
    "    with sources overlaid.\n",
    "    '''\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot()\n",
    "    plt.imshow(data_2d, origin='lower', cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    for row in catalog:\n",
    "        if row['aper_total_flux'] > flux_limit:\n",
    "            plt.plot(row['xcentroid'], row['ycentroid'], marker='o', markersize='3', color='red')\n",
    "\n",
    "    plt.xlabel('Pixel column')\n",
    "    plt.ylabel('Pixel row')\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(left=0.15)\n",
    "    plt.colorbar(label='MJy/sr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectra(spec, median_filter=None, title=None):\n",
    "    ''' Function to generate the spectrum for a combined spectral product.\n",
    "    '''\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    ax = plt.subplot()\n",
    "    \n",
    "    if median_filter:\n",
    "        plt.plot(spec.spec_table['WAVELENGTH'], medfilt(spec.spec_table['FLUX'],median_filter)) \n",
    "        \n",
    "    else: \n",
    "        plt.plot(spec.spec_table['WAVELENGTH'], spec.spec_table['FLUX']) \n",
    "\n",
    "    \n",
    "    plt.xlabel('Wavelength (um)')\n",
    "    plt.ylabel('Flux')\n",
    "    \n",
    "    plt.subplots_adjust(left=0.15)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    else:\n",
    "        title='Final combined spectra from Stage 3'\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.<font color='white'>-</font>Data in MAST <a class=\"anchor\" id=\"mast\"></a>\n",
    "------------------\n",
    "\n",
    "The JWST Data Management System (DMS) produces many products for each JWST observation, including the science files generated by the pipeline. The exact type and number of products depends on the instrument, its configuration, and observing mode. Observers should consult the [MAST documentation for information about standard data products](https://jwst-docs.stsci.edu/obtaining-data/data-discovery#DataDiscovery-Dataproducttypes). \n",
    "\n",
    "Of the many different data products produced by the calibration pipeline, most observers will find the science data files in MAST to be sufficient for their analysis. However, other data products such as guide star data, associations, and engineering data are also available. \n",
    "\n",
    "Standard science data files include:\n",
    "\n",
    "* [uncalibrated raw data](https://jwst-pipeline.readthedocs.io/en/stable/jwst/data_products/science_products.html#uncalibrated-raw-data-uncal), identified by the suffix ```uncal```\n",
    "* [countrate data](https://jwst-pipeline.readthedocs.io/en/stable/jwst/data_products/science_products.html#countrate-data-rate-and-rateints) produced by applying the Stage 1 (detector-level) corrections in order to compute count rates from the original accumulating signal ramps, identified by the suffix ```rate``` or ```rateints```\n",
    "* [calibrated single exposures](https://jwst-pipeline.readthedocs.io/en/stable/jwst/data_products/science_products.html#calibrated-data-cal-and-calints), identified by the suffix ```cal```\n",
    "* [resampled and/or combined exposures](https://jwst-pipeline.readthedocs.io/en/stable/jwst/data_products/science_products.html#resampled-2-d-data-i2d-and-s2d), identified by the suffixes ```i2d``` or ```s2d```\n",
    "* [extracted spectroscopic 1D data](https://jwst-pipeline.readthedocs.io/en/stable/jwst/data_products/science_products.html#extracted-1-d-spectroscopic-data-x1d-and-x1dints), identified by the suffixes ```x1d``` or ```c1d```\n",
    "\n",
    "In addition, there are also [several other products depending on the observing mode](https://jwst-pipeline.readthedocs.io/en/stable/jwst/data_products/science_products.html#source-catalog-cat), such as source and photometry catalogs, stacked PSF data, and NIRISS AMI derived data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.<font color='white'>-</font>Example data for this exercise <a class=\"anchor\" id=\"example\"></a>\n",
    "------------------\n",
    "\n",
    "For this module, we will use calibrated NIRCam simulated imaging and wide field slitless spectroscopy (WFSS) exposures that are stored in Box. Let's grab the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For the catalog file:\n",
    "catalog_file_link = 'https://stsci.box.com/shared/static/oicjg5rdiqdyh7r7oolzveodv5bxpv1a.ecsv'\n",
    "output_catalog = download_file(catalog_file_link)\n",
    "\n",
    "# For the FITS files:\n",
    "fits_box_links = ['https://stsci.box.com/shared/static/ixfnu50ju78vs40dcec8i7w0u6kwtoli.fits', 'https://stsci.box.com/shared/static/6y3y6r6uoqwe90d5vhaaid8ntoiemicn.fits']\n",
    "for boxfile in fits_box_links:\n",
    "    fits_file = download_file(boxfile)\n",
    "    \n",
    "    \n",
    "combined_i2d_file = \"example_nircam_imaging_i2d.fits\"\n",
    "final_c1d_file = \"example_nircam_wfss_c1d.fits\"\n",
    "output_catalog = \"example_nircam_imaging_cat.ecsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.<font color='white'>-</font>Data products: stage 3 (combined, rectified exposures)<a class=\"anchor\" id=\"stage3\"></a>\n",
    "------------------\n",
    "\n",
    "Stage 3 processing includes routines that work with multiple associated exposures to produce some kind of combined (mosaicked), rectified (aligned in a common output frame) product. There are unique pipeline modules for imaging, spectroscopic, coronagraphic, AMI, and TSO observations, and each produces specific outputs for the particular observing mode. The exposure level products are updated at this stage to provide the highest quality data products that include the results of ensemble processing (e.g., updated WCS, matching backgrounds, and a second pass at outlier detection). These products are available in MAST, along with the unrectified 2D and rectified 2D products. More information can be found in the [JWST User Documentation](https://jwst-docs.stsci.edu/jwst-data-reduction-pipeline/algorithm-documentation/stages-of-processing). We also have a full list of data product types and the units of the data for each product [in the documentation](https://jwst-pipeline.readthedocs.io/en/latest/jwst/data_products/product_types.html#data-product-types). \n",
    "\n",
    "We'll start by going through the various inputs and outputs for the mode-specific pipeline modules, and finish by revisiting our simulated data used in the previous notebooks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.<font color='white'>-</font>Imaging<a class=\"anchor\" id=\"s3-imaging\"></a>\n",
    "\n",
    "Stage 3 processing for direct imaging observations combines the calibrated data from multiple exposures (e.g., dithers or mosaics) into a single, rectified, distortion corrected product. Before being combined, the exposures receive additional corrections for astrometric alignment, background matching, and outlier detection. Coronagraphic imaging and time series imaging have their own separate pipeline modules. \n",
    "\n",
    "### A.<font color='white'>-</font>Input<a class=\"anchor\" id=\"s3-imaging-input\"></a>\n",
    "\n",
    "The inputs to this stage are listed below.\n",
    "\n",
    "* **2D calibrated images**\n",
    "    * **Data model**: ImageModel\n",
    "    * **File suffix**: ```_cal```\n",
    "    * **Description**: The inputs to this pipeline are one or more Stage 2 calibrated (```_cal```) image products. An association file must be used as input in order to process and combine multiple images. If only a single ```_cal``` file is used as input, only the ```resample``` and ```source_catalog``` steps will be applied.\n",
    "    \n",
    "\n",
    "### B.<font color='white'>-</font>Output<a class=\"anchor\" id=\"s3-imaging-output\"></a>\n",
    "\n",
    "The outputs of this stage are listed below.\n",
    "\n",
    "* **CR-flagged exposures**\n",
    "    * **Data model**: ImageModel\n",
    "    * **File suffix**: ```_crf```\n",
    "    * **Description**: If the ```outlier_detection``` step is applied, a new version of each input calibrated exposure is created with a data quality array that is updated to flag pixels detected as outliers. These files use the ```_crf``` (CR-Flagged) file suffix and include the association candidate ID as a new field in the original product root file name.\n",
    "    \n",
    "* **Resampled and combined 2D image**\n",
    "    * **Data model**: DrizProductModel\n",
    "    * **File suffix**: ```_i2d```\n",
    "    * **Description**: The resampled 2D image that contains the combined, rectified association of exposures, which is the direct output of the ```resample``` step.  \n",
    "\n",
    "* **Source catalog**\n",
    "    * **Data model**: N/A\n",
    "    * **File suffix**: ```_cat```\n",
    "    * **Description**: The source catalog produced by the ```source_catalog``` step using the ```_i2d``` data product is saved as an ASCII file in ```ecsv``` format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.<font color='white'>-</font>Spectroscopy<a class=\"anchor\" id=\"s3-spectroscopy\"></a>\n",
    "\n",
    "Stage 3 processing for spectroscopic observations combines the calibrated data from multiple exposures (e.g., dithers or nods) into a single combined 2D or 3D spectral data product and a combined 1D spectrum. Before being combined, exposures may receive additional corrections for background matching and subtraction, and outlier rejection. Time series data will go through the separate time series pipeline module. \n",
    "\n",
    "### A.<font color='white'>-</font>Input<a class=\"anchor\" id=\"s3-spectroscopy-input\"></a>\n",
    "\n",
    "The inputs to this stage are listed below.\n",
    "\n",
    "* **2D calibrated data**\n",
    "    * **Data model**: ImageModel, IFUImageModel, SlitModel, or MultiSlitModel\n",
    "    * **File suffix**: ```_cal```\n",
    "    * **Description**: The inputs to this module should be in the form of an association file listing the exposures to be processed into combined data products. The individual exposures should be calibrated (```_cal```) products from Stage 2 processing. The member list for each product in the association file can also contain exposures of dedicated background targets, which are intended for use in the master_background step. These input exposures must be extracted 1D spectral products (```_x1d```) for the background target(s) produced by the Stage 2 pipeline. They must be listed in the association file with ```exptype``` values of ```background``` in order to be identified as background exposures.\n",
    "   \n",
    "\n",
    "### B.<font color='white'>-</font>Output<a class=\"anchor\" id=\"s3-spectroscopy-output\"></a>\n",
    "\n",
    "The outputs of this stage are listed below.\n",
    "\n",
    "* **Source-based calibrated data**\n",
    "    * **Data model**: MultiExposureModel\n",
    "    * **File suffix**: ```_cal```\n",
    "    * **Description**: For NIRSpec fixed-slit, NIRSpec MOS, and NIRCam and NIRISS WFSS, which have a defined set of slits or sources, data from the input calibrated exposures is reorganized so that all instances of data for a particular source/slit are contained in a single product (referred to as “source-based” products), rather than input exposure-based products. Source-based collections of data are saved in intermediate files, one per source/slit. The root names of the source-based data products contain the source ID as an identifier and use the same ```_cal``` suffix as the input calibrated exposure files. The reorganized sets of data are sent to subsequent steps to process and combine all the data for one source at a time. \n",
    "\n",
    "* **CR-flagged exposures**\n",
    "    * **Data model**: ImageModel\n",
    "    * **File suffix**: ```_crf```\n",
    "    * **Description**: If the ```outlier_detection``` step is applied, a new version of each input calibrated exposure is created with a data quality array that is updated to flag pixels detected as outliers. These files use the ```_crf``` (CR-Flagged) file suffix and include the association candidate ID as a new field in the original product root file name.\n",
    "    \n",
    "* **2D resampled and combined spectral data**\n",
    "    * **Data model**: DrizProductModel\n",
    "    * **File suffix**: ```_s2d```\n",
    "    * **Description**: When processing non-IFU modes, a resampled/rectified 2D product is created containing the rectified and combined data for a given slit/source, which is the direct output of the ```resample``` step.     \n",
    "    \n",
    "* **3D resampled and combined spectral data**\n",
    "    * **Data model**: IFUCubeModel\n",
    "    * **File suffix**: ```_s3d```\n",
    "    * **Description**: When processing IFU exposures, a resampled and combined 3D IFU cube product is created by the cube building step.\n",
    "\n",
    "* **1D extracted spectral data**\n",
    "    * **Data model**: MultiSpecModel\n",
    "    * **File suffix**: ```_x1d```\n",
    "    * **Description**: All inputs result in a 1D extracted spectral data product, saved as a ```_x1d``` file, which is normally the result of performing the 1D spectral extraction step on the combined ```_s2d``` or ```_s3d``` product. For NIRCam and NIRISS WFSS, and NIRISS SOSS, the 1D spectral extraction is performed on the individual unresampled 2D cutout images, which results in multiple 1D spectra per source in a ```_x1d``` product. Those spectra are combined using the subsequent 1D spectral combination step.\n",
    "    \n",
    "* **1D combined spectral data**\n",
    "    * **Data model**: CombinedSpecModel\n",
    "    * **File suffix**: ```_c1d```\n",
    "    * **Description**: For NIRCam and NIRISS WFSS, and NIRISS SOSS, the 1D spectral combination step combines multiple 1D spectra for a given source into a final spectrum.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.<font color='white'>-</font>Aperture Masking Interferometry (AMI)<a class=\"anchor\" id=\"s3-ami\"></a>\n",
    "\n",
    "Stage 3 processing for calibrated NIRISS AMI observations computes fringe parameters for individual exposures, averages the fringe results from multiple exposures, and, optionally, corrects science target fringe parameters using the fringe results from reference PSF targets.\n",
    "\n",
    "### A.<font color='white'>-</font>Input<a class=\"anchor\" id=\"s3-ami-input\"></a>\n",
    "\n",
    "The inputs to this stage are listed below.\n",
    "\n",
    "* **2D calibrated images**\n",
    "    * **Data model**: ImageModel\n",
    "    * **File suffix**: ```_cal```\n",
    "    * **Description**: Inputs need to be in the form of an association file that lists multiple science target exposures, and, optionally, reference PSF exposures. Individual exposures must be in the form of calibrated (```_cal```) data products from Stage 2 processing. \n",
    " \n",
    "\n",
    "### B.<font color='white'>-</font>Output<a class=\"anchor\" id=\"s3-ami-output\"></a>\n",
    "\n",
    "The outputs of this stage are listed below.\n",
    "\n",
    "* **Fringe parameter tables**\n",
    "    * **Data model**: AmiLgModel\n",
    "    * **File suffix**: ```_ami```\n",
    "    * **Description**: For every input exposure, fringe parameters and closure phases caculated by the ```ami_analyze``` step are saved to a FITS table containing the fringe parameters and closure phases.\n",
    "\n",
    "* (optional) **Averaged fringe parameters table**\n",
    "    * **Data model**: AmiLgModel\n",
    "    * **File suffix**: ```_amiavg``` or ```_psf-amiavg```\n",
    "    * **Description**: If multiple target or reference PSF exposures are used as input and the ```–save_averages``` parameter is set to True, the ```ami_average``` step will save averaged results for the target in an ```_amiavg``` product and for the reference PSF in a ```_psf-amiavg``` product. \n",
    "   \n",
    "* **Normalized fringe parameters table**\n",
    "    * **Data model**: AmiLgModel\n",
    "    * **File suffix**: ```_aminorm```\n",
    "    * **Description**: If reference PSF exposures are included in the input association, the averaged AMI results for the target will be normalized by the averaged AMI results for the reference PSF and will be saved to an ```_aminorm``` product file. This file has the same FITS table format as the ```_ami``` products. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4.<font color='white'>-</font>Coronagraphy<a class=\"anchor\" id=\"s3-coronagraphy\"></a>\n",
    "\n",
    "Stage 3 coronagraphic processing is applied to associations of calibrated NIRCam coronagraphic and MIRI Lyot and 4QPM exposures, and is used to produce PSF-subtracted, resampled, combined images of the source object.\n",
    "\n",
    "### A.<font color='white'>-</font>Input<a class=\"anchor\" id=\"s3-coronagraphy-input\"></a>\n",
    "\n",
    "The inputs to this stage are listed below.\n",
    "\n",
    "* **3D calibrated images**\n",
    "    * **Data model**: CubeModel\n",
    "    * **File suffix**: ```_calints```\n",
    "    * **Description**: The input to this stage must be in the form of an association file that lists one or more exposures of a science target and one or more reference PSF targets. The individual target and reference PSF exposures should be in the form of 3D calibrated (```_calints```) data products from Stage 2 processing. Each pipeline step will loop over the 3D stack of per-integration images contained in each exposure. \n",
    "   \n",
    "\n",
    "### B.<font color='white'>-</font>Output<a class=\"anchor\" id=\"s3-coronagraphy-output\"></a>\n",
    "\n",
    "The outputs of this stage are listed below.\n",
    "\n",
    "* **CR-flagged images**\n",
    "    * **Data model**: CubeModel\n",
    "    * **File suffix**: ```_crfints```\n",
    "    * **Description**: If the ```outlier_detection``` step is applied, a new version of each input calibrated exposure is created with a data quality array that is updated to flag pixels detected as outliers. These files use the ```_crfints``` (CR-Flagged per integration) file suffix and include the association candidate ID as a new field in the original product root file name.\n",
    "\n",
    "* **3D stacked PSF images**\n",
    "    * **Data model**: CubeModel\n",
    "    * **File suffix**: ```_psfstack```\n",
    "    * **Description**: The data from each input PSF reference exposure are concatenated into a single combined 3D stack for use by subsequent steps. The stacked PSF data are written to a ```_psfstack``` product. \n",
    "    \n",
    "* **4D aligned PSF images**\n",
    "    * **Data model**: QuadModel\n",
    "    * **File suffix**: ```_psfalign```\n",
    "    * **Description**: For each science target exposure, all of the reference PSF images in the ```_psfstack``` product are aligned to each science target integration and saved to a 4D ```_psfalign``` product. \n",
    "        \n",
    "* **3D PSF-subtracted images**\n",
    "    * **Data model**: CubeModel\n",
    "    * **File suffix**: ```_psfsub```\n",
    "    * **Description**: For each science target exposure, the ```klip``` step applies PSF fitting and subtraction for each integration, resulting in a 3D stack of PSF-subtracted images. \n",
    "    \n",
    "* **2D resampled image**\n",
    "    * **Data model**: DrizProductModel\n",
    "    * **File suffix**: ```_i2d```\n",
    "    * **Description**: The ```resample``` step is applied to the CR-flagged products to create a single resampled and combined product for the science target. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5.<font color='white'>-</font>Time Series Observation (TSO)<a class=\"anchor\" id=\"s3-tso\"></a>\n",
    "\n",
    "Stage 3 TSO processing is applied to associations of calibrated TSO exposures (e.g. NIRCam TS imaging, NIRCam TS grism, NIRISS SOSS, NIRSpec BrightObj, MIRI LRS Slitless) and is used to produce calibrated time-series photometry or spectra of the source object.\n",
    "\n",
    "\n",
    "\n",
    "### A.<font color='white'>-</font>Input<a class=\"anchor\" id=\"s3-tso-input\"></a>\n",
    "\n",
    "The inputs to this stage are listed below.\n",
    "\n",
    "* **3D calibrated images**\n",
    "    * **Data model**: CubeModel\n",
    "    * **File suffix**: ```_calints```\n",
    "    * **Description**: The input is in the form of an association file listing multiple exposures or exposure segments of a science target. Individual inputs should be in the form of 3D calibrated (```_calints```) products from Stage 2 (either imaging or spectroscopic) processing. These products contain 3D stacks of per-integration images, and each pipeline step will loop over all of the integrations in each input. Many TSO exposures may contain a large number of integrations that make their individual exposure products too large (in terms of file size on disk) to be able to handle conveniently. In these cases, the uncalibrated raw data (```_uncal```) for a given exposure are split into multiple “segmented” products, each of which is identified with a segment number (see [segmented products](https://jwst-pipeline.readthedocs.io/en/latest/jwst/data_products/file_naming.html#segmented-files)). The input association file includes all ```_calints``` exposure segments. The ```outlier_detection``` step processes a single segment at a time, creating one output ```_crfints``` product per segment. The remaining steps will process each segment and concatenate the results into a single output product that contains results for all exposures and segments listed in the association.\n",
    "\n",
    "### B.<font color='white'>-</font>Output<a class=\"anchor\" id=\"s3-tso-output\"></a>\n",
    "\n",
    "The outputs of this stage are listed below.\n",
    "\n",
    "* **CR-flagged images**\n",
    "    * **Data model**: CubeModel\n",
    "    * **File suffix**: ```_crfints```\n",
    "    * **Description**: If the ```outlier_detection``` step is applied, a new version of each input calibrated exposure is created with a data quality array that is updated to flag pixels detected as outliers. These files use the ```_crfints``` (CR-Flagged per integration) file suffix and include the association candidate ID as a new field in the original product root file name.\n",
    "\n",
    "* **Imaging photometry catalog**\n",
    "    * **Data model**: N/A\n",
    "    * **File suffix**: ```_phot```\n",
    "    * **Description**: For imaging TS observations, a source catalog containing photometry results from all of the ```_crfints``` products is produced, organized as a function of integration time stamps.\n",
    "       \n",
    "* **1D extracted spectral data**\n",
    "    * **Data model**: MultiSpecModel\n",
    "    * **File suffix**: ```_x1dints```\n",
    "    * **Description**: For spectroscopic TS observations, the 1D spectral extraction step is applied to all ```_crfints``` products to create a single ```_x1dints``` product containing 1D extracted spectral data for all integrations contained in the input exposures. \n",
    "       \n",
    "* **Spectroscopic white-light catalog**\n",
    "    * **Data model**: N/A\n",
    "    * **File suffix**: ```_whtlt```\n",
    "    * **Description**: For spectroscopic TS observations, the ```white_light``` step is applied to all of the 1D extracted spectral data in the ```_x1dints``` product to produce an ASCII catalog in ```ecsv``` format containing the wavelength-integrated white-light photometry of the source. The catalog lists the integrated white-light flux as a function of time, based on the integration time stamps.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.<font color='white'>-</font>Examining the products<a class=\"anchor\" id=\"examine\"></a>\n",
    "------------------\n",
    "\n",
    "Whew! That was a lot of information. Hopefully by now you're catching on to the pattern -- \n",
    "\n",
    "```uncal``` <span style=\"color:red\">(raw)</span>\n",
    "\n",
    "to\n",
    "\n",
    "```rate``` or ```rateints``` <span style=\"color:brown\">(detector corrections)</span>\n",
    "\n",
    "to \n",
    "\n",
    "```cal``` or ```calints``` <span style=\"color:blue\">(calibrated, unrectified individual products)</span>\n",
    "\n",
    "to \n",
    "\n",
    "```i2d``` or ```x1d``` <span style=\"color:green\">(combined, rectified products)</span>\n",
    "\n",
    "with specific data models for the different formats, and some other data products (e.g., catalogs) sprinkled in for good measure. Let's take a look at some catalogs and some final combined, rectified prodcuts for imaging and spectroscopy in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>With so many data products, how do I know which model to use?!</b> \n",
    "    \n",
    "When in doubt, you can always try to let the ```datamodels``` decide for you:\n",
    "\n",
    "```python\n",
    "with datamodels.open(\"myimage.fits\") as model:\n",
    "    ...\n",
    "````\n",
    "The ```datamodels.open()``` method checks if the ```DATAMODL``` FITS keyword has been set. If the keyword is not set, then ```datamodels.open()``` does its best to guess the best datamodel to use for you.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.<font color='white'>-</font>Catalogs<a class=\"anchor\" id=\"catalogs\"></a>\n",
    "\n",
    "Here, we'll focus on the catalog output from Stage 3 image processing, but other catalogs will have a similar ASCII format and file name (```.ecsv```). You can read more about the ```ecsv``` format [in the Astropy documentation here](https://docs.astropy.org/en/stable/io/ascii/write.html#ecsv-format). In short, it provides a convenient way to handle tables and associated metadata.\n",
    "\n",
    "We can open the table using Astropy's ```Table```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the catalog (use: image_catalog)\n",
    "image_catalog = Table.read(output_catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with astropy tables in notebooks is super convenient. There are a few additional options for displaying them:\n",
    "\n",
    "```python\n",
    "# Show the catalog in the Jupyter notebook\n",
    "image_catalog.show_in_notebook()\n",
    "\n",
    "# Show it in a separate browser\n",
    "image_catalog.show_in_browser() \n",
    "```\n",
    "\n",
    "This functionality isn't available in AWS, but you should be able to use it on your machine with local copies of notebooks and catalogs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's it look like?\n",
    "image_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# What's included in the information?\n",
    "image_catalog.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the columns and metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the columns\n",
    "image_catalog.colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the meta data\n",
    "image_catalog.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the data in one column: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the flux values (use: total_flux)\n",
    "total_flux = image_catalog['aper_total_flux']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our flux column, get the column name, unit, data type, and data\n",
    "print('\\nColumn description: ', total_flux.description)\n",
    "print('Column name: ', total_flux.name)\n",
    "print('Column units: ', total_flux.unit)\n",
    "print('Column data type: ', total_flux.dtype)\n",
    "print('Column data: ', total_flux.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RA, Dec values are [Skycoord objects](https://docs.astropy.org/en/stable/api/astropy.coordinates.SkyCoord.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show RA default\n",
    "image_catalog['sky_centroid'].ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Dec in deg\n",
    "image_catalog['sky_centroid'].dec.deg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.<font color='white'>-</font>Combined image<a class=\"anchor\" id=\"comb-image\"></a>\n",
    "\n",
    "Here, we'll take a look at the final combined imaging data product from Stage 3, the ```_i2d``` file. Let's use the imaging simulation from our previous modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the final combined 2D image (use: image)\n",
    "image = datamodels.ImageModel(combined_i2d_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the model structure\n",
    "image.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check out the meta data\n",
    "image.meta.instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the shape?\n",
    "image.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image of the final product\n",
    "create_image(image.data, vmin=0, vmax=50, title=\"Final combined NIRCam image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's overlay the catalog, as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, get a sigma-clipped mean of the flux to determine the scale for our image (use: clipped flux)\n",
    "clipped_flux = sigma_clip(total_flux, sigma=2, maxiters=5, cenfunc=np.nanmean)\n",
    "np.mean(clipped_flux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create our image with the catalog overlaid\n",
    "create_image_with_cat(image.data, image_catalog, flux_limit=1e-5, vmin=0, vmax=50, title=\"Final image w/ catalog overlaid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3.<font color='white'>-</font>Combined spectrum<a class=\"anchor\" id=\"comb-spec\"></a>\n",
    "\n",
    "Here, we'll take a look at the final combined 1D spectrum from Stage 3 spectroscopic processing (```_c1d```. Let's use the WFSS simulation from our previous modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the final combined 1D file (use: spectrum)\n",
    "spectrum = datamodels.CombinedSpecModel(final_c1d_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Look at the model structure\n",
    "spectrum.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Look at the metadata\n",
    "spectrum.meta.instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show me the table values \n",
    "spectrum.spec_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot it up!\n",
    "plot_spectra(spectrum, median_filter=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.<font color='white'>-</font>The end<a class=\"anchor\" id=\"bye-bye\"></a>\n",
    "------------------\n",
    "\n",
    "You made it! That's the end of our JWST data products JWebbinar. We hope you have a better idea of what to expect from your JWST observations, and feel more comfortable with the format and structure. As always, if you have any questions or concerns, you can find us through the [JWST Help Desk](https://stsci.service-now.com/jwst). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.<font color='white'>-</font>Exercise<a class=\"anchor\" id=\"exercise\"></a>\n",
    "------------------\n",
    "\n",
    "Now you try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many sources are in the source catalog? \n",
    "len(image_catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many sources are identified by the pipeline as stars? \n",
    "np.sum(image_catalog['is_star']==False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where can you find information about the aperture corrections used for the catalog?\n",
    "image_catalog.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where do I find the spectral order for my combined spectrum?\n",
    "spectrum.spectral_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Where is the WCS information for the CombinedSpec model? \n",
    "spectrum.meta.wcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# What columns are in the spec_table? \n",
    "astrotab = Table(spectrum.spec_table).colnames\n",
    "astrotab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
