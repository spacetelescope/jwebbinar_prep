{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e959a152",
   "metadata": {},
   "source": [
    "# How to run the pipeline on a set of MIRI imager data with defaults and update a few parameters\n",
    "\n",
    "This example notebook will demonstrate how to process a MIRI imager data set through the stage one, two and three imager pipelines. \n",
    "\n",
    "The pipeline documentation can be found here: https://jwst-pipeline.readthedocs.io/en/latest/\n",
    "\n",
    "**The pipeline code and install directions are available on GitHub: https://github.com/spacetelescope/jwst**\n",
    "\n",
    "The steps in this notebook are:\n",
    "\n",
    "\n",
    "  1)  Read in list of uncalibrated data (uncal.fits) files.\n",
    "\n",
    "  2)  Process through calwebb_detector1.\n",
    "\n",
    "  3)  Process ramp fit (rate.fits) files through calwebb_image2.\n",
    "\n",
    "  4)  Create an assocation file for the calibrated files (cal.fits).\n",
    "\n",
    "  5)  Run the calibrated files through calwebb_image3 using the association file.\n",
    "\n",
    "  6)  Look at the output catalogs and compare sources on image.\n",
    "    \n",
    "Setup needed before getting started.\n",
    "\n",
    "* Place notebook and data into the directory where you wish to process your data.\n",
    "\n",
    "* Install pipeline (and pip install any missing modules you encounter when you try to run).\n",
    "\n",
    "\n",
    "There will also be a set of useful plots and image displays throughout the notebook that will help examine data quality as you proceed.  \n",
    "\n",
    "\n",
    "This notebook was written in October 2023, and was meant to work with pipeline version 1.12.0. Future versions of the pipeline should work, but backward compatibility of notebooks is not guaranteed with all python package updates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb174ce",
   "metadata": {},
   "source": [
    "## Information on Running the pipeline\n",
    "\n",
    "This notebook utilizes the .call() method of running the notebook in python. With this method, the pipeline will retrieve and use any parameter reference file that applies to your data. These files will set certain parts of the code to run or be skipped, or select any parameters that the instrument teams have put as preferred defaults for most science cases. If you run with this method and do not set any custom parameters, you will replicate what you would get from the automated pipeline and populated in MAST. These parameter reference files can be found in CRDS as well as reference files like flats and darks. \n",
    "\n",
    "If you wish to customize the parameters, you can read the documentation in the ReadTheDocs link posted above. Each step in the pipeline has a section in the documentation that explains the parameters relevant to that step.  To set the parameters in your code as you re-run data, a configuration dictionary is set up (and shown in the notebook as examples), then that custom configuration overrides the default values that would have come from the parameter reference files. Only the parameters listed in your custom dictionary are overriden, while the rest remain set to the default values.\n",
    "\n",
    "Most parameters that would need customization come in the stage three pipeline, but the jump step in the first pipeline stage, calwebb_detector1, also has a more extensive set of customizable parameters, and reading the documentation for this step could prove useful. (More details at the calwebb_detector1 stage in this notebook.)\n",
    "\n",
    "In order to run the pipeline and retrieve the necessary reference files from CRDS, there are a couple of CRDS variables that need to be set. CRDS_PATH tells the pipeline where to save and retrieve reference files. This should be set to a local directory where new reference files will be downloaded, and frequently used reference files can be retrieved and used without needing to pull large files across your internet connection. The other path that needs to be set is the CRDS_SERVER_URL, to know where to look to retrieve any new reference files. That path should be set to https://jwst-crds-stsci.edu. In this notebook, these are set using the os.environ statements below.\n",
    "\n",
    "NOTE: you should store only CRDS reference files in your CRDS cache directory. This is in case you need to delete and redo your CRDS cache area at any point, and you don't want to chance erasing anything that should not be deleted.\n",
    "\n",
    "os.environ['CRDS_PATH'] = '/local_crds_path/crds_cache/'\n",
    "\n",
    "os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds-stsci.edu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f32fe1",
   "metadata": {},
   "source": [
    "### Using datamodels\n",
    "\n",
    "This notebook will show how to use datamodels in working with your data. \n",
    "The basic steps involve reading a file into a datamodel type and then opening the individual named extensions as needed.\n",
    "\n",
    "Header data is stored in the .meta extension.\n",
    "\n",
    "Science data is stored in the .data extension.\n",
    "\n",
    "Data quality flags can be accessed with .groupdq (in RampModel data files that allow accessing dq flags of each group in the data) or .dq (in ImageModel data files after calwebb_detector1 is run).\n",
    "\n",
    "For more in-depth information on datamodels and how to use them: https://stdatamodels.readthedocs.io/en/latest/jwst/datamodels/index.html#data-models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858095b7",
   "metadata": {},
   "source": [
    "### Import statements\n",
    "Import modules that will be needed to read in data, run the pipeline and display any plots or visualizations.\n",
    "\n",
    "Packages to be sure are installed:\n",
    "* jwst\n",
    "* jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b36c09e",
   "metadata": {},
   "source": [
    "### Set CRDS Path info\n",
    "\n",
    "The CRDS path information needs to be set before importing any crds or jwst packages. The jwst installation instructions here: https://jwst-pipeline.readthedocs.io/en/latest/getting_started/quickstart.html show how to set up the CRDS information in a setup file (such as bash.profile or other setup file), but if the paths are not set in a setup file, they can be set in a notebook using os.environ as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918b0a4c-ddb5-4a1c-81aa-a474f87f0a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes for the Science Platform environment\n",
    "# Preparing cached data\n",
    "import os\n",
    "import glob\n",
    "\n",
    "preloaded_fits_dir = \"/home/shared/preloaded-fits/jwebbinar_31/miri/\"\n",
    "for filename in glob.glob(os.path.join(preloaded_fits_dir, \"*.fits\")):\n",
    "    basename = os.path.basename(filename)\n",
    "    if not os.path.exists(basename):\n",
    "        os.symlink(filename, basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550637e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CRDS path info\n",
    "import os\n",
    "\n",
    "os.environ['CRDS_PATH'] = os.environ['HOME']+'/crds_cache/' \n",
    "os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds-stsci.edu'\n",
    "\n",
    "print('CRDS cache location: {}'.format(os.environ['CRDS_PATH']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5688626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import jwst pipeline modules\n",
    "import jwst\n",
    "from jwst.pipeline import Detector1Pipeline, Image2Pipeline, Image3Pipeline # pipeline modules\n",
    "from jwst import datamodels\n",
    "from jwst.datamodels import RampModel, ImageModel, dqflags # Data models and dq values\n",
    "\n",
    "# Needed for associations\n",
    "from jwst import associations\n",
    "from jwst.associations.lib.rules_level3_base import DMS_Level3_Base\n",
    "from jwst.associations import asn_from_list\n",
    "\n",
    "# Other modules/functions to work with and examine data\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "from astropy.io import ascii, fits\n",
    "from astropy.visualization import simple_norm\n",
    "from astropy.modeling import models, fitting\n",
    "\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from astropy.convolution import Gaussian1DKernel, convolve\n",
    "from astropy.wcs import WCS\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import table\n",
    "#from astropy.table import Table\n",
    "\n",
    "from tweakwcs import JWSTgWCS\n",
    "\n",
    "# Box download imports \n",
    "from astropy.utils.data import download_file\n",
    "from pathlib import Path\n",
    "from shutil import move\n",
    "from os.path import splitext\n",
    "\n",
    "import crds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d276558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the version of the JWST pipeline.\n",
    "\n",
    "print(jwst.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e0df1e",
   "metadata": {},
   "source": [
    "### Load helper script for overlaying a catalog over the image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08885d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper script to plot an image and overlay catalog sources\n",
    "\n",
    "def overlay_catalog(\n",
    "    data_2d,\n",
    "    catalog,\n",
    "    flux_limit=0,\n",
    "    vmin=0,\n",
    "    vmax=10,\n",
    "    title=None,\n",
    "    units=\"MJy/str\",\n",
    "    dmap=\"binary\",\n",
    "):\n",
    "    \"\"\"Function to generate a 2D image of the data,\n",
    "    with sources overlaid.\n",
    "\n",
    "    data_2d : numpy.ndarray\n",
    "        2D image to be displayed\n",
    "\n",
    "    catalog : astropy.table.Table\n",
    "        Table of sources\n",
    "\n",
    "    flux_limit : float\n",
    "        Minimum signal threshold to overplot sources from catalog.\n",
    "        Sources below this limit will not be shown on the image.\n",
    "\n",
    "    vmin : float\n",
    "        Minimum signal value to use for scaling\n",
    "\n",
    "    vmax : float\n",
    "        Maximum signal value to use for scaling\n",
    "\n",
    "    title : str\n",
    "        String to use for the plot title\n",
    "\n",
    "    units : str\n",
    "        Units of the data. Used for the annotation in the\n",
    "        color bar\n",
    "    \"\"\"\n",
    "    norm = ImageNormalize(\n",
    "        data_2d, interval=ManualInterval(vmin=vmin, vmax=vmax), stretch=SqrtStretch()\n",
    "    )\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    im = ax.imshow(data_2d, origin=\"lower\", norm=norm, cmap=plt.get_cmap(dmap))\n",
    "\n",
    "    for row in catalog:\n",
    "        if row[\"aper_total_flux\"].value > flux_limit:\n",
    "            plt.plot(\n",
    "                row[\"xcentroid\"],\n",
    "                row[\"ycentroid\"],\n",
    "                marker=\"o\",\n",
    "                markersize=\"3\",\n",
    "                color=\"red\",\n",
    "            )\n",
    "\n",
    "    plt.xlabel(\"X pixel\")\n",
    "    plt.ylabel(\"Y pixel\")\n",
    "\n",
    "    fig.colorbar(im, label=units)\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(left=0.15)\n",
    "\n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714e13cd",
   "metadata": {},
   "source": [
    "### Read in data\n",
    "\n",
    "For this notebook, the data is stored in Box and will be loaded into the working directory.\n",
    "You can also just put the notebook and data into a single directory, or include path information as you work with the data. \n",
    "\n",
    "The data provided here as an example come from PID 1040, and consist of five dither positions that make up a single tile of a larger LMC mosaic. The data is taken in filter F770W, and each exposure is six frames and a single integration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceb6908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in dataset from Box\n",
    "\n",
    "def get_box_files(file_list):\n",
    "    for box_url,file_name in file_list:\n",
    "        if 'https' not in box_url:\n",
    "            box_url = 'https://stsci.box.com/shared/static/' + box_url\n",
    "        downloaded_file = download_file(box_url, timeout=600)\n",
    "        print(downloaded_file)\n",
    "        if Path(file_name).suffix == '':\n",
    "            ext = splitext(box_url)[1]\n",
    "            file_name += ext\n",
    "        print(file_name)\n",
    "        copy(downloaded_file, file_name)\n",
    "\n",
    "\n",
    "# F770W data of PID 1040 (LMC), one tile of full mosaic, taken in May 2022   \n",
    "file_urls = ['https://stsci.box.com/shared/static/yk2kfwxr1dv7mcc84zvi02t7mq8e5wc7.fits',\n",
    "             'https://stsci.box.com/shared/static/icedk709owq6op5mttv4y8k0bce58wu7.fits',\n",
    "             'https://stsci.box.com/shared/static/kq4h4pb95yse3k1ryb0d1vcs69ay4679.fits',\n",
    "             'https://stsci.box.com/shared/static/z1wbjh0y3dzuh2i5heejo0sehwqu2p2w.fits',\n",
    "             'https://stsci.box.com/shared/static/q01wh0evq7w7klqy566cbm1qlpuys7h7.fits'] \n",
    "\n",
    "uncalfiles = ['jw01040001005_03103_00001_mirimage_uncal.fits',\n",
    "              'jw01040001005_03103_00002_mirimage_uncal.fits',\n",
    "              'jw01040001005_03103_00003_mirimage_uncal.fits',\n",
    "              'jw01040001005_03103_00004_mirimage_uncal.fits',\n",
    "              'jw01040001005_03103_00005_mirimage_uncal.fits']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66e8437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run commands to load the data from box into current directory\n",
    "\n",
    "# box_download_list = [(url,name) for url,name in zip(file_urls,uncalfiles)]\n",
    "\n",
    "\n",
    "# get_box_files(box_download_list)\n",
    "\n",
    "# print(uncalfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4aa02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To just gather all uncalfiles in a specific folder: Do not do this if you have multiple datasets in a single folder\n",
    "\n",
    "#uncalfiles = glob.glob('*uncal.fits')\n",
    "#print(uncalfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900b6e3c-670e-4b85-9419-55f5d03d5238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If files area already in the directory with the data, and you only need the list of files for processing, uncomment these lines.\n",
    "\n",
    "uncalfiles = ['jw01040001005_03103_00001_mirimage_uncal.fits',\n",
    "             'jw01040001005_03103_00002_mirimage_uncal.fits',\n",
    "             'jw01040001005_03103_00003_mirimage_uncal.fits',\n",
    "             'jw01040001005_03103_00004_mirimage_uncal.fits',\n",
    "             'jw01040001005_03103_00005_mirimage_uncal.fits']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6406f6b0",
   "metadata": {},
   "source": [
    "### Look at your data and header parameters\n",
    "\n",
    "Read your data files into a RampModel data model to examine some header parameters.\n",
    "Read a sample data file into a model to display the last frame in the ramp to look at the scene in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac60d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at some header parameters from your data\n",
    "\n",
    "print('File name, Instrument, Subarray,  Filter,  Nints,  Ngroups')\n",
    "\n",
    "for file in uncalfiles: \n",
    "\n",
    "    imfile = RampModel(file) # Read files into datamodel\n",
    "\n",
    "    header = imfile.meta # Read the meta data into a variable called 'header'\n",
    "    \n",
    "    # Read in the header keywords\n",
    "    name = header.filename\n",
    "    inst = header.instrument.name\n",
    "    subarray = header.subarray.name\n",
    "    filt = header.instrument.filter\n",
    "    nints = header.exposure.nints\n",
    "    ngroups = header.exposure.ngroups\n",
    "\n",
    "    print(name, inst, subarray, filt, nints, ngroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77155fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to find a specific header value to view, and you know the FITS header keyword, you \n",
    "# can use this code to find the datamodel equivalent of the keyword.\n",
    "\n",
    "imfile.find_fits_keyword('DATE-OBS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7660fd-ac4c-46b7-8841-777fdbb6526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up sample file name for image viewing and up the ramp pixel plotting\n",
    "\n",
    "scifile = uncalfiles[0]\n",
    "print(scifile)\n",
    "\n",
    "# Split filename to get the base section of the name without the specific stage of processing.\n",
    "samplefile, remainder = scifile.split('_uncal.')\n",
    "print(samplefile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56117d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sample data file into a datamodel\n",
    "uncal_im = RampModel(samplefile+'_uncal.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d48336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the last frame of one of the data files to visualize the field of view\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "\n",
    "# Set up image\n",
    "cax = ax.imshow(uncal_im.data[0, -1, :, :], cmap='Greys', origin='lower', vmin=2500,vmax=4500)\n",
    "\n",
    "# Set up colorbar\n",
    "cb = fig.colorbar(cax)\n",
    "cb.ax.set_ylabel('counts',fontsize=14)\n",
    "\n",
    "#Set labels \n",
    "ax.set_xlabel('X',fontsize=16)\n",
    "ax.set_ylabel('Y',fontsize=16)\n",
    "ax.set_title(scifile, fontsize=16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c042ca7-a343-4872-b19d-07cd2d1fd8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a pixel up the ramp \n",
    "\n",
    "xpos = 590\n",
    "ypos = 289\n",
    "\n",
    "integration = 0  # This is single integration data, but this works with multi integration data to look at a single int out of the exposure\n",
    "\n",
    "plt.xlabel('Frame number')\n",
    "plt.ylabel('Pixel value in counts')\n",
    "\n",
    "plt.plot(uncal_im.data[integration, :, ypos, xpos])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b76f9b9",
   "metadata": {},
   "source": [
    "## Run calwebb_detector1 on your data\n",
    "\n",
    "Documentation link for calwebb_detector1: https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_detector1.html\n",
    "\n",
    "Set a few parameters for the jump step (most steps are fine to run with defaults).\n",
    "Loop through and run all files through calwebb_detector1 to get 'rate.fits' files that contain slope fit images.\n",
    "\n",
    "When setting up the pipeline stage to run, using the .call() method requires setting up dictionaries for each of the steps that will have parameters set that are different from the defaults.\n",
    "\n",
    "If you wish to track what pixels are flagged as jumps, you can set the jump step parameter 'save_results' to True and examine the output '*jump.fits' files.\n",
    "\n",
    "#### The detector1 pipeline will take the longest amount of runtime in this notebook. This example uses a small dataset, but if you have large data (either in large numbers of frames/integrations or number of exposures), this can take awhile to run, so be prepared for that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ebb4df-a353-478f-b1eb-47fae12b1210",
   "metadata": {},
   "source": [
    "The jump step has the largest number of adjustable parameters in calwebb_detector1. If you choose to turn on shower or snowball correction code (showers for MIRI, snowballs for NIR), then it would be a good idea to see what the adjustable options are. There are default values defined in the parameter reference files, but those may not be ideal for specific modes or science cases, so check the full list of parameters if your results seem less than optimal. And keep in mind there are different parameters for snowball and shower code, so be sure to read the documentation. https://jwst-pipeline.readthedocs.io/en/latest/jwst/jump/arguments.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4a949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a few Jump step parameters, for versions 1.10.0 and later (build version 9.2)\n",
    "# find_showers turns the cr shower code on for MIRI. Set to False to skip this code. (Default is currently False.)\n",
    "# Use mostly code defaults for the rest of the parameters.\n",
    "\n",
    "rej_thresh = 5\n",
    "\n",
    "expand_large_events = False  # This parameter is used for NIR instruments\n",
    "find_showers = True  # This parameter is used for MIRI only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3693f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a few parameters and run each file through the Detector1 Pipeline\n",
    "\n",
    "for file in uncalfiles:\n",
    "    pipe = Detector1Pipeline()\n",
    "\n",
    "    base, remainder = file.split('_uncal.')\n",
    "    print(base)\n",
    "    outname=base\n",
    "    \n",
    "    # Set up dictionaries for step parameters\n",
    "    cfg = dict()\n",
    "    cfg['jump'] = {} # Set up dictionary for the various jump paramters\n",
    "    cfg['jump']['save_results'] = True # The jump output file is useful if you want to track which frames have jumps flagged\n",
    "    cfg['jump']['rejection_threshold'] = rej_thresh\n",
    "    cfg['jump']['expand_large_events'] = expand_large_events\n",
    "    cfg['jump']['find_showers'] = find_showers\n",
    "\n",
    "\n",
    "    pipe.call(file, steps=cfg, save_results=True, output_file =  base + '.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33cdf56",
   "metadata": {},
   "source": [
    "### Look at output rate image\n",
    "\n",
    "Plot one of the output rate images to see what the image looks like. The code here will also mark any pixels with a DQ value of DO_NOT_USE in blue. These blue pixels are considered bad in some way and will not contribute to the final combined image. You can see an image of an example flat field mask here: https://jwst-docs.stsci.edu/jwst-mid-infrared-instrument/miri-instrument-features-and-caveats. You will notice some of the same shorted columns and bad pixels that are flagged blue in our example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f444490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and look at a single rate image\n",
    "\n",
    "# Read the rate file into an ImageModel datamodel\n",
    "ratefiles = [ele.replace('uncal', 'rate') for ele in uncalfiles]\n",
    "rate_im = ImageModel(samplefile+'_rate.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df34178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the averaged slope image, and plot the DO_NOT_USE dq flagged pixels in blue\n",
    "\n",
    "\n",
    "# mask out DO_NOT_USE values of 1\n",
    "masked_rate_im = np.ma.masked_where((rate_im.dq & dqflags.pixel['DO_NOT_USE'] > 0), rate_im.data)\n",
    "\n",
    "cmap = matplotlib.colormaps[\"Greys\"].copy()  # Can be any colormap that you want after the cm\n",
    "cmap.set_bad(color='blue') # color to mark all DO_NOT_USE pixels\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "\n",
    "# Set up image\n",
    "cax = ax.imshow(masked_rate_im, cmap=cmap, origin='lower', vmin=10,vmax=25.0)\n",
    "\n",
    "# Set up colorbar\n",
    "cb = fig.colorbar(cax)\n",
    "cb.ax.set_ylabel('counts/sec',fontsize=14)\n",
    "\n",
    "#Set labels \n",
    "ax.set_xlabel('X',fontsize=16)\n",
    "ax.set_ylabel('Y',fontsize=16)\n",
    "ax.set_title(ratefiles[0], fontsize=16)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c45f91-24aa-41aa-bafe-f9c54c714b61",
   "metadata": {},
   "source": [
    "### Look at a few specific ramps and whether any jumps were flagged\n",
    "\n",
    "Read in the output jump.fits file (output specifically in the jump step), and choose a few pixels in the image to plot up the ramp and look for jumps. The code below plots the selected pixels up the ramp and places a black dot to show where pixels were flagged up the ramp as jumps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202f0cda-e1d9-4694-a7e1-abe1901d0da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load jump output image and examine the same pixel up the ramp to see if any jumps were flagged.\n",
    "\n",
    "# Read the jump file into a RampModel datamodel\n",
    "jumpfile = samplefile+'_jump.fits'\n",
    "jumpim = RampModel(jumpfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f10483d-1aef-4e51-b6a3-400b1ab0826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a set of pixels to plot up the ramp and check for jumps\n",
    "\n",
    "xvals = [590, 715, 942, 574]\n",
    "yvals = [289, 278, 154, 607]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b42f1-e97d-4212-bc0c-a34c59be0175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle through pixel values and plot ramp and list dq values\n",
    "# This is plotted for a single integration of a cube \n",
    "\n",
    "# The black dot is used to represent a pixel (in a single group) that has been flagged as a jump\n",
    "# The value for a jump detection in the dq array is 4, but you can search for it with the name 'JUMP_DET' rather than the value.\n",
    "\n",
    "nframes = jumpim.meta.exposure.ngroups\n",
    "frames = np.arange(nframes)\n",
    "\n",
    "# set up titles for plot\n",
    "plt.title(jumpfile)\n",
    "plt.xlabel('Frame number')\n",
    "plt.ylabel('value up the ramp in counts')\n",
    "\n",
    "i=0\n",
    "# Loop through x,y values\n",
    "for x, y in zip(xvals, yvals):\n",
    "    # get locations of flagged pixels within the ramps\n",
    "    # The groupdq extension is the one that tracks all flagged pixels up the ramps.\n",
    "    jumps = jumpim.groupdq[integration, :, y, x] & dqflags.pixel['JUMP_DET'] > 0\n",
    "    \n",
    "    ramp = jumpim.data[integration, :, y, x]\n",
    "\n",
    "    # plot ramps of selected pixels and flagged jumps\n",
    "    plt.plot(ramp, label='ramp '+str(i) )  # Plot ramps\n",
    "    plt.plot(frames[jumps], ramp[jumps], color='k', marker='o', linestyle='None') # Plot any jumps up the ramp\n",
    "    i=i+1\n",
    "    \n",
    "    # Print dq values for each group up the ramp for each pixel; jumps will include a value of 4\n",
    "    print(jumpim.groupdq[integration, :, y, x])\n",
    "    \n",
    "plt.legend()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4a92b3",
   "metadata": {},
   "source": [
    "## Run calwebb_image2\n",
    "\n",
    "Documentation link for calwebb_image2: https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_image2.html\n",
    "\n",
    "Run the output of detector1 (rate files) through calwebb_detector2 to obtain a set of calibrated files (cal files). Use default parameters here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1e6eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Calwebb_image2 on output files from detector1    \n",
    "    \n",
    "print('There are ', len(ratefiles), ' images.')\n",
    "    \n",
    "callist = []\n",
    "\n",
    "# cycle through files\n",
    "for im in ratefiles:\n",
    "\n",
    "    calfile = Image2Pipeline.call(im, save_results=True)\n",
    "\n",
    "    callist.append(calfile)\n",
    "\n",
    "print(callist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d71415d-caf5-44ca-ac10-caa36e31dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot rate and cal images near each other to view any differences\n",
    "# Read the cal image into an ImageModel datamodel\n",
    "cal_im = ImageModel(samplefile+'_cal.fits')\n",
    "\n",
    "# Set up two plots side by side\n",
    "fig, ax = plt.subplots(2, 1,figsize=[15,15])\n",
    "cmap='Greys'\n",
    "\n",
    "\n",
    "ax[0].set_title('Rate file')\n",
    "ax[1].set_title('Cal file')\n",
    "\n",
    "cset1 = ax[0].imshow(rate_im.data[:,:],cmap=cmap, origin='lower', vmin=10, vmax=24)\n",
    "ax[0].set_xlabel('X',fontsize=14)\n",
    "ax[0].set_ylabel('Y',fontsize=14)\n",
    "cb1 = fig.colorbar(cset1, ax=ax[0])\n",
    "cb1.ax.set_ylabel('counts/sec',fontsize=14)\n",
    "\n",
    "\n",
    "cset2 = ax[1].imshow(cal_im.data[:,:],cmap=cmap, origin='lower', vmin=3, vmax=6)\n",
    "ax[1].set_xlabel('X',fontsize=14)\n",
    "ax[1].set_ylabel('Y',fontsize=14)\n",
    "cb2 = fig.colorbar(cset2, ax=ax[1])\n",
    "cb2.ax.set_ylabel('MJy/str',fontsize=14)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8561ef0",
   "metadata": {},
   "source": [
    "### Run Calwebb_image3 on cal.fits files from Calwebb_image2\n",
    "\n",
    "First create an association file for the calibrated files if you do not already have an association file, and then use that file to process the set through calwebb_image3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36314289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use asn_from_list to create association table\n",
    "miri_asn_name = 'miri_F770W_pid1040_combined_scaled' # name of output asn file\n",
    "\n",
    "calfiles = glob.glob('jw01040*_cal.fits') # get a list of calibrated files\n",
    "\n",
    "# Create association file\n",
    "asn = asn_from_list.asn_from_list(calfiles, rule=DMS_Level3_Base, product_name=miri_asn_name)\n",
    "\n",
    "# dump association table to a .json file for use in image3\n",
    "\n",
    "miri_asn_file = miri_asn_name+'.json'\n",
    "with open(miri_asn_file, 'w') as outfile:\n",
    "    outfile.write(asn.dump()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353d8cc1-bd1e-48a9-b2ec-09ca5a993480",
   "metadata": {},
   "source": [
    "### Set up parameters for calwebb_image3\n",
    "\n",
    "Set up a dictionary for the parameters you wish to change. The parameters set here are an example set of parameters.\n",
    "\n",
    "To learm more about the parameters that can be set for each step in the pipeline, check the 'Step Arguments' section of the pipeline documentation for each step in calwebb_image3.\n",
    "\n",
    "Pipeline module for calwebb_image3 documentation: https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_image3.html\n",
    "\n",
    "Click on the step you wish to explore, and then the Step Arguments.\n",
    "\n",
    "A few parameters that a user might want to spend some time testing are resample step parameters kernel and weight_type, and outlier_detection step scale parameters. The scale values demonstrated in this notebook are twice the default values, and have been shown to improve the combined output image for some science data. If your photometry is off, try testing these parameters.\n",
    "\n",
    "The tweakreg parameters are mostly needed for image alignment. If your images don't seem well aligned, check those parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be8ede3-4ee6-4b8b-879f-7fba1840ad90",
   "metadata": {},
   "source": [
    "Some images can have bad WCS values due to arge pointing errors. This can show up between different dithers, and might need adjustments before they will correctly align with the other images in the association. If your mosaic shows problems like double point sources or evidence that one image is misaligned from the others, you can examine them to figure out what corrections would need to be applied to the mis-aligned image before it could be combined into a mosaic.\n",
    "\n",
    "Some tools exist to help with this issue. \n",
    "Adjust_wcs tool: https://jwst-pipeline.readthedocs.io/en/latest/jwst/tweakreg/utils.html - This allows you to provide offset/rotation/scale values to fix the WCS header of the cal fits files. You can set parameters here to adjust the x/y offset, rotation or scale values to bring the outlier image back into better alignment with the other images.\n",
    "\n",
    "The JHAT tools: https://github.com/arminrest/jhat have also been developed in order to help users fix bad wcs issues.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b700d927-6f97-4e36-8f9d-e8d72f38be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set desired parameters for calwebb_image3 steps\n",
    "\n",
    "# This section of parameters are for aligning to an external catalog, in this case GAIADR3.\n",
    "# parameters with abs_* names are used to refer to the absolute catalog parameters (gaia or other external catalog)\n",
    "abs_refcat = 'GAIADR3'   #String indicating what astrometric catalog should be used. Currently supported options: ‘GAIADR1’, ‘GAIADR2’, ‘GAIADR3’, a path to an existing reference catalog, None, or ‘’.\n",
    "abs_minobj = 15  # number of objects that must match to GAIA catalog; not all fields will have many Gaia sources for comparison\n",
    "save_abs_catalog = True # Save out the gaia catalog that matches to your dataset \n",
    "\n",
    "# You can also set parameters to match between files in your own dataset\n",
    "minobj = 25 # Number of stars that must match between your individual dithers to be considered a match\n",
    "\n",
    "# These are example parameters to demonstrate how to change values, but the values have been good options in specific science cases.\n",
    "# A gaussian kernel might be better for PSF centroiding than other options\n",
    "# Doubling the scale used from the default was helpful in the absolute flux calibration work\n",
    "resamp_kernel = 'gaussian'\n",
    "scale = '1.0 0.8'\n",
    "weight_type = 'exptime'\n",
    "#pix_scale = '0.06'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bf9ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run calwebb_image3 (or Image3Pipeline) on calibrated data using association table.\n",
    "\n",
    "# Set up the configuration to change any parameters\n",
    "cfg = dict() \n",
    "\n",
    "cfg['tweakreg'] = {} # set up empty dictionary for multiple parameters to be set per step\n",
    "cfg['tweakreg']['abs_refcat'] = abs_refcat\n",
    "cfg['tweakreg']['abs_minobj'] = abs_minobj\n",
    "cfg['tweakreg']['save_abs_catalog'] = save_abs_catalog \n",
    "cfg['tweakreg']['minobj'] = minobj\n",
    "cfg['tweakreg']['save_catalogs'] = True\n",
    "\n",
    "#cfg['skymatch'] = {'skip' : True}  # Syntax if you wish to skip a step within a pipeline module\n",
    "\n",
    "cfg['resample']={}  # set up empty dictionary for multiple parameters to be set per step\n",
    "cfg['resample']['kernel'] = resamp_kernel\n",
    "cfg['resample']['weight_type'] = weight_type\n",
    "#cfg['resample']['pixel_scale'] = pix_scale\n",
    "\n",
    "cfg['outlier_detection'] = {'scale' : scale}  # Can set single parameters with this syntax\n",
    "                     \n",
    "output = Image3Pipeline.call(miri_asn_file, steps=cfg, save_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0ab69f",
   "metadata": {},
   "source": [
    "#### Look at the output combined mosaic and overlay the source catalog to see what sources were found\n",
    "\n",
    "You will notice that the Four Quadrant phase mask (4QPM) regions of the image are visible in previous stages of the pipeline (rate files, cal files, etc), but are not part of the combined mosaic. While you can see those regions in earlier stages of processing, they should not be used, as there are extra optical elements in place, and data taken for the imager is not valid in those regions. The corongraph regions need to be taken in the correct subarray with the appropriate coronagraphic filter in place for it to be valid data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa24b1bc-6f2c-4696-8db9-7484eced33bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a single definition of vmin and vmax to use in the image displays, so all mosaics will be plotted with the same color scale\n",
    "display_vals = [4.0,7.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d84054e-8703-4188-9a89-edf667b054eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the final i2d image (combined mosaic)\n",
    "\n",
    "# Read your mosaic image into an ImageModel datamodel\n",
    "miri_mosaic_file =  miri_asn_name + '_i2d.fits'\n",
    "miri_mosaic = ImageModel(miri_mosaic_file)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "\n",
    "# Set up image\n",
    "cax = ax.imshow(miri_mosaic.data, cmap='Greys', origin='lower', vmin=display_vals[0],vmax=display_vals[1])\n",
    "\n",
    "# Set up colorbar\n",
    "cb = fig.colorbar(cax)\n",
    "cb.ax.set_ylabel('MJy/str',fontsize=14)\n",
    "\n",
    "#Set labels \n",
    "ax.set_xlabel('X',fontsize=16)\n",
    "ax.set_ylabel('Y',fontsize=16)\n",
    "ax.set_title('Final MIRI mosaic', fontsize=16)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86327a1-727b-4aaa-b763-a958b318c120",
   "metadata": {},
   "source": [
    "Keep in mind that the source finding algorithm finds peaks with a star-like profile, but not all the sources it finds will be real. MIRI imaging mosaics tend to have false positives near image edges, so examine the catalog against the image carefully to decide whether the individual sources are real or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad79e1e-d011-44c0-8be4-50883cc8da60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at catalog table that shows all columns, but subset of rows\n",
    "\n",
    "# Get catalog output from source_catalog step of calwebb_image3\n",
    "miri_catalog_file = miri_asn_name + '_cat.ecsv'\n",
    "\n",
    "# Read in catalog from source_catalog step\n",
    "print('Source catalog output file ', miri_catalog_file)\n",
    "\n",
    "cat_data = table.Table.read(miri_catalog_file, format='ascii', comment='#')\n",
    "\n",
    "miri_x = cat_data['xcentroid']\n",
    "miri_y = cat_data['ycentroid']\n",
    "cat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b90c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at mosaic data and sources found with source_catalog\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "\n",
    "# Set up image\n",
    "cax = ax.imshow(miri_mosaic.data, cmap=cmap, origin='lower', vmin=display_vals[0],vmax=display_vals[1])\n",
    "ax.scatter(miri_x, miri_y,lw=1, s=10,color='red') # overplot source positions\n",
    "\n",
    "# Set up colorbar\n",
    "cb = fig.colorbar(cax)\n",
    "cb.ax.set_ylabel('MJy/str',fontsize=14)\n",
    "\n",
    "#Set labels \n",
    "ax.set_xlabel('X',fontsize=16)\n",
    "ax.set_ylabel('Y',fontsize=16)\n",
    "ax.set_title('Final MIRI mosaic', fontsize=16)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97283abf-a907-4a78-b80e-abc0de9946ac",
   "metadata": {},
   "source": [
    "### Explore Gaia catalog (ouput from tweakreg step) and see how well the Gaia catalog and JWST data line up\n",
    "\n",
    "Read in the gaia catalog that was output from the tweakreg step (if using gaiadr3, the catalog name should be fit_gaiadr3_ref.ecsv), and convert the RA, Dec coordinates to pixel positions, then overplot those on the image.\n",
    "\n",
    "You can also get the pixel positions from the full image3 pipeline and plot those positions with Gaia to see what sources match and what sources were only found with either Gaia or the JWST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4681adb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in gaia catalog and plot gaia sources on image\n",
    "\n",
    "# Get Gaia catalog (or other external output catalog) from tweakreg\n",
    "gaia_cat_name = glob.glob('*gaiadr3*')\n",
    "print('Gaia catalog name ', gaia_cat_name)\n",
    "\n",
    "# Glob creates a matching list. Choose first element of list to display\n",
    "gaia_cat = table.Table.read(gaia_cat_name[0], format='ascii', comment='#', delimiter=' ')\n",
    "\n",
    "gaia_cat # display catalog\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b09b278-3776-40f8-9932-f36bee5b79a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaia catalog has RA and DEC positions, so convert those to x,y detector coordinates\n",
    "\n",
    "world_to_detector = miri_mosaic.meta.wcs.get_transform('world', 'detector')\n",
    "xgaia,ygaia = world_to_detector(gaia_cat['RA'], gaia_cat['DEC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d981e3e-6fda-4ecb-9f42-e44b8e8ed88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Gaia sources on the output combined mosaic\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "\n",
    "# Set up image\n",
    "cax = ax.imshow(miri_mosaic.data, cmap=cmap, origin='lower', vmin=display_vals[0],vmax=display_vals[1])\n",
    "ax.scatter(xgaia, ygaia,lw=1, s=10,color='red') # overplot source positions\n",
    "\n",
    "# Set up colorbar\n",
    "cb = fig.colorbar(cax)\n",
    "cb.ax.set_ylabel('MJy/str',fontsize=14)\n",
    "\n",
    "#Set labels \n",
    "ax.set_xlabel('X',fontsize=16)\n",
    "ax.set_ylabel('Y',fontsize=16)\n",
    "ax.set_title('Final MIRI mosaic', fontsize=16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f511c355-a41b-47ec-b8ad-276583feb738",
   "metadata": {},
   "source": [
    "#### Plot Gaia catalog against Source catalog output to see how well sources match position on stars\n",
    "\n",
    "Plot a zoomed in portion of mosaic so you can see whether the two catalogs match position or whether there is any evidence of source positions being mis-aligned in your image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66176419-1870-4f61-afbe-f13c679552a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show zoomed in region to see if stars look like point sources and aren't smeared out or doubled\n",
    "\n",
    "xmin = 725\n",
    "xmax = 825\n",
    "ymin = 550\n",
    "ymax = 650\n",
    "\n",
    "gaiazoom = np.where((xgaia > xmin) & (xgaia < xmax) & (ygaia > ymin) & (ygaia < ymax))\n",
    "print(gaiazoom)\n",
    "subx = xgaia[gaiazoom] - xmin\n",
    "suby = ygaia[gaiazoom] - ymin\n",
    "\n",
    "mirizoom = np.where((miri_x > xmin) & (miri_x < xmax) & (miri_y > ymin) & (miri_y < ymax))\n",
    "print(gaiazoom)\n",
    "subxmiri = miri_x[mirizoom] - xmin\n",
    "subymiri = miri_y[mirizoom] - ymin\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.xlabel('X coordinate of subimage')\n",
    "plt.ylabel('Y coordinate of subimage')\n",
    "\n",
    "plt.imshow(miri_mosaic.data[ymin:ymax,xmin:xmax], origin='lower', cmap='Greys', vmin=display_vals[0],vmax=display_vals[1])\n",
    "\n",
    "plt.scatter(subx, suby,lw=1, s=15,color='red')\n",
    "plt.scatter(subxmiri, subymiri,lw=1, s=5,color='yellow')\n",
    "#plt.colorbar()\n",
    "\n",
    "print('Gaia sources are marked in red, MIRI sources from the pipeline in yellow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413d1bae-c393-42d4-98c5-7fbafd3cc805",
   "metadata": {},
   "source": [
    "If you see several stars with red dots overlaid with yellow dots, then your output catalog aligns well with Gaia. If you see mis-alignment or doubled stars in your images, then you should try to correct the wcs and re-run calwebb_image3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9f5a56-9fc6-469a-8856-d994ddf27683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass",
   "language": "python",
   "name": "masterclass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
