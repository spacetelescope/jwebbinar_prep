{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "763e51fb",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src='./logo.png' alt=\"logo\" class=\"bg-primary\" align=\"right\" style=\"width: 150px; height: 150px;\"/>\n",
    "</figure>\n",
    "\n",
    "<a id='top'></a>\n",
    "# NIRSpec IFU Pipeline Processing for extended sources: ERO 2729 - Tarantula Nebula\n",
    "<hr style=\"border:3px solid black\"  width=80% align=\"left\">\n",
    "\n",
    "\n",
    "## About this Notebook <a id='about'></a>\n",
    "<hr style=\"border:1px solid gray\" width=80% align=\"left\">\n",
    "\n",
    "**Authors**: Peter Zeidler (zeidler@stsci.edu) based on the work by Kayli Glidic (kglidic@stsci.edu), Maria Pena-Guerrero (pena@stsci.edu), Leonardo Ubeda (lubeda@stsci.edu)\n",
    "\n",
    "**Update On**: 2023-11-28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0d06b8",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [1. Introduction](#intro)\n",
    "* [2. Import Library](#imports)\n",
    "* [3. Convenience Functions](#func)\n",
    "* [4. Directory Set-Up](#dir_setup)\n",
    "* [5. Download the data](#data)\n",
    "* [6. Products Found In MAST](#mast_products)\n",
    "    * [6.1 Stage 1 Products Found In MAST](#level1_mast)\n",
    "    * [6.2 Stage 2 Products Found In MAST](#level2_mast)\n",
    "    * [6.3 Stage 3 Products Found In MAST](#level3_mast)\n",
    "* [7. Re-processing the Data](#reprocessing)\n",
    "    * [7.1 Stage 1 Rerun & Products](#level1_rerun)\n",
    "    * [7.2 Stage 2 Rerun & Products](#level2_rerun)\n",
    "    * [7.3 Stage 3 Rerun & Products](#level3_rerun)\n",
    "        * [7.3.1 New Outlier Detection Algorithm](#outlier_detection_new)\n",
    "* [Conclusion](#conclusion)\n",
    "\n",
    "## 1. Introduction <a id='intro'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "End-to-end calibration of JWST data is divided into 3 main stages of processing. This notebook explores how to run the JWST calibration pipeline stages 1-3 for NIRSpec IFU spectroscopic data.\n",
    "   <figure>\n",
    "       <img src='./nirspec_ifu_extended_source/Tarantula.png' title=\"Figure 1: Tarantula Nebula\" alt=\"Tarantula\" class=\"bg-primary\" align=\"right\" style=\"width: 400px; height: 350px;\"/>\n",
    "   </figure>\n",
    "\n",
    ">* **`STAGE 1`** ([calwebb_detector1](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_detector1.html#calwebb-detector1)): consists of detector-level corrections, performed on a group-by-group basis, followed by ramp fitting.\n",
    "    * **Input**: Raw exposure (`uncal.fits`) containing original data from all detector readouts (ncols x nrows x ngroups x nintegrations).\n",
    "    * **Output**: Corrected countrate (slope) image (`rate.fits`) \n",
    ">* **`STAGE 2`** ([calwebb_spec2](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_spec2.html#calwebb-spec2)): consists of additional instrument-level and observing mode corrections and calibrations.\n",
    "    * **Input**: A single corrected countrate (slope) image (`rate.fits`) or an ASN file listing multiple inputs.\n",
    "    * **Output**: A fully calibrated unrectified exposure (`cal.fits`). For NIRSpec IFU data, the `cube_build` step returns a 3-D IFU spectroscopic cube (`s3d.fits`). The `extract_1d` step  returns 1-D extracted spectral data products (`x1d.fits`)\n",
    ">* **`STAGE 3`** ([calwebb_spec3](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_spec3.html#calwebb-spec3)): consists of additional corrections (e.g. `outlier_detection`) and routines for combining calibrated data from multiple exposures (e.g. dither/nod pattern) into a single combined 2-D or 3-D spectral product and a combined 1-D spectrum. \n",
    "    * **Input**: An ASN file that lists multiple calibrated exposures (`cal.fits`).\n",
    "    * **Output**: For NIRSpec IFU data, a resampled and combined 3-D IFU cube (`s3d.fits`) and a 1-D extracted spectrum (`x1d.fits`)\n",
    "\n",
    "Here, we will focus on the mechanics of processing \"real\" example data ([Tarantula Nebula](#Tarantula)) from Early Release Observations (ERO) Proposal ID 2729, including how to use associations for multi-exposure combination and how to interact and work with data models for each product. Our objective is to examine the automated products found in MAST and compare them to products generated with the most up-to-date version of the JWST calibration pipeline.\n",
    "\n",
    "Most processing runs shown here use the default reference files from the Calibration Reference Data System (CRDS). Please note that pipeline software development is a continuous process, so results in some cases may be slightly different if using a subsequent version. There are also a few known issues with some of the pipeline steps in this build that we expect to be fixed in the near future. Until then, at various steps, we provide users with the current processing recommendations when running the pipeline manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcee7ed7",
   "metadata": {},
   "source": [
    "## 2. Import Library <a id='imports'></a>\n",
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5b543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "\n",
    "#--------------------------------------JWST Calibration Pipeline Imports-------------------------------------------\n",
    "\n",
    "import jwst\n",
    "import crds\n",
    "from jwst import datamodels\n",
    "from jwst.pipeline import Detector1Pipeline   #calwebb_detector1\n",
    "from jwst.pipeline import Spec2Pipeline       #calwebb_spec2\n",
    "from jwst.pipeline import Spec3Pipeline       #calwebb_spec3\n",
    "from jwst.extract_1d import Extract1dStep     #Extract1D Individual Step\n",
    "\n",
    "print(\"===============================================================================\")\n",
    "print(\"These are the installed pipeline and current operational CRDS context versions:\")\n",
    "print(\" \")\n",
    "print(\"JWST Calibration Pipeline Version={}\".format(jwst.__version__))\n",
    "print(\"Current Operational CRDS Context = {}\".format(crds.get_default_context()))\n",
    "print(\"===============================================================================\")\n",
    "\n",
    "#----------------------------------------------General Imports-----------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #Set to 'default' to turn warnings back on\n",
    "\n",
    "#--------------------------------------------File Operation Imports------------------------------------------------\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import asdf\n",
    "import json\n",
    "import shutil\n",
    "from IPython.display import JSON\n",
    "\n",
    "#--------------------------------------------Astropy/Astroquery Imports--------------------------------------------\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy import wcs\n",
    "from astropy.wcs import WCS\n",
    "from astropy.visualization import ImageNormalize, ManualInterval, LogStretch, LinearStretch, AsinhStretch, SqrtStretch\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "import astroquery\n",
    "from astroquery.mast import Mast\n",
    "from astroquery.mast import Observations\n",
    "\n",
    "#------------------------------------------------Plotting Imports--------------------------------------------------\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Circle\n",
    "import matplotlib.gridspec as grd\n",
    "from matplotlib import cm\n",
    "\n",
    "# Use this version for non-interactive plots (easier scrolling of the notebook)\n",
    "%matplotlib inline\n",
    "# Use this version (outside of Jupyter Lab) if you want interactive plots\n",
    "#%matplotlib notebook\n",
    "\n",
    "# These gymnastics are needed to make the sizes of the figures\n",
    "# be the same in both the inline and notebook versions\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches': None}\n",
    "mpl.rcParams['savefig.dpi'] = 80\n",
    "mpl.rcParams['figure.dpi'] = 80\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17178e7",
   "metadata": {},
   "source": [
    "## 3. Convenience Functions <a id='func'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "A few function that will be used throughout the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb4f2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(data_2d, vmin, vmax, xsize=15, ysize=15, title=None, zoom_in=None, aspect=1, scale='log', units='DN/s', cmap='jet'):\n",
    "    \"\"\"\n",
    "    Function to generate a 2-D, log-scaled image of the data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_2d : numpy.ndarray\n",
    "        2-D image to be displayed\n",
    "    vmin : float\n",
    "        Minimum signal value to use for scaling\n",
    "    vmax : float\n",
    "        Maximum signal value to use for scaling\n",
    "    xsize, ysize: int\n",
    "        Figure Size\n",
    "    title : str\n",
    "        String to use for the plot title\n",
    "    zoom_in: list \n",
    "        Zoomed in Region of interest [xstart,xstop,ystart,ystop]\n",
    "    aspect: int\n",
    "        Aspect ratio of the axes\n",
    "    scale : str\n",
    "        Specify scaling of the image. Can be 'log' or 'linear' or 'Asinh'\n",
    "    units : str\n",
    "        Units of the data. Used for the annotation in the color bar. Defualt is DN/s for countrate images\n",
    "    cmap: str\n",
    "        Color Map for plot\n",
    "    \"\"\"\n",
    "    #-----------------------------------------Scaling Information----------------------------------------\n",
    "    \n",
    "    if scale == 'log':\n",
    "        norm = ImageNormalize(data_2d, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                              stretch=LogStretch())\n",
    "    elif scale == 'linear':\n",
    "        norm = ImageNormalize(data_2d, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                              stretch=LinearStretch())\n",
    "    elif scale == 'Asinh':\n",
    "        norm = ImageNormalize(data_2d, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                              stretch=AsinhStretch())\n",
    "    \n",
    "    #--------------------------------------------Set Up Figure-------------------------------------------\n",
    "\n",
    "    fig = plt.figure(figsize=(xsize, ysize))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    \n",
    "    im = ax.imshow(data_2d, origin='lower', norm=norm, aspect=aspect, cmap=cmap)\n",
    "\n",
    "    fig.colorbar(im, label=units)\n",
    "    plt.xlabel('Pixel column')\n",
    "    plt.ylabel('Pixel row')\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "    #Zoom in on a portion of the image? \n",
    "    if zoom_in:\n",
    "        #inset axis \n",
    "        axins = ax.inset_axes([0.5, 0.6, 0.5, 0.3])\n",
    "        \n",
    "        axins.imshow(data_2d, origin=\"lower\", norm=norm, aspect=aspect, cmap=cmap)\n",
    "        \n",
    "        # subregion of the original image\n",
    "        axins.set_xlim(zoom_in[0], zoom_in[1])\n",
    "        axins.set_ylim(zoom_in[2], zoom_in[3])\n",
    "        axins.set_xticklabels([])\n",
    "        axins.set_yticklabels([])\n",
    "        ax.indicate_inset_zoom(axins, color=\"black\",edgecolor=\"black\", linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b1838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ifu_cubeslices(s3d_file_list, wavelength_slices=[], spaxel_locs=[], y_scale=None, cmap='jet', vmin_vmax = [[[0,15e1]]], save_figure=False, title=None, title_font = 30):\n",
    "    \"\"\"\n",
    "    Function to that takes a 3-D IFU data cube and generates: \n",
    "    \n",
    "    > 2-D cube slices based on wavelength (microns)\n",
    "    > Associated 1-D spectrum for a designated spaxel (spatial pixel) in the data cube\n",
    "    > Corresponding 3-D weight image giving the relative weights of the output spaxels\n",
    "    \n",
    "    Note: This function can accomidate multiple detectors plotted side-by-side. \n",
    "    The general format would follow [[detector 1 info], [detector 2 info]].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s3d_file_list: list of str\n",
    "        3-D IFU data cube fits file list \n",
    "    wavelength_slices: tuple\n",
    "        List of wavelength values (microns) at which to create 2-D slices. \n",
    "    spaxel_locs: tuple\n",
    "        List of spaxel locations in which to plot the associated 1-D spectrum. (One spaxel location per slice)\n",
    "    y_scale: tuple\n",
    "        Y-axis limits for the associated 1-D spectrum of the spaxel. Default is to use the ymin and ymax of the data. \n",
    "    cmap: str\n",
    "        Color Map \n",
    "    vmin_vmax: tuple\n",
    "        Minimum & Maximum signal value to use for scaling (e.g., [[[vmin,vmax],[vmin,vmax]], [[vmin,vmax], [vmin,vmax]]])\n",
    "    title: str\n",
    "        Figure Title. Default is None. \n",
    "    title_font:int\n",
    "        Title Font Size\n",
    "    save_figure: bool\n",
    "        Save figure?         \n",
    "    \"\"\"\n",
    "    \n",
    "    #---------------------------------------------- Set-up Figure -------------------------------------------------\n",
    "\n",
    "    #Plot Slices From the Cube\n",
    "    fig = plt.figure(figsize=(8*np.array(wavelength_slices).size,18))\n",
    "    gs = grd.GridSpec(3, np.array(wavelength_slices).size, height_ratios=[1]*3, width_ratios=[1]*np.array(wavelength_slices).size, hspace=0.4,wspace=0.7)\n",
    "\n",
    "    total_num_plots=3*np.array(wavelength_slices).size\n",
    "    \n",
    "    plot_count = 0\n",
    "    #---------------------------------------------Open Files------------------------------------------------------\n",
    "    \n",
    "    for s3d_file in s3d_file_list:\n",
    "        \n",
    "        root=s3d_file[:-9] #Root file name \n",
    "        print(s3d_file)\n",
    "        s3d = fits.open(s3d_file) #3-D IFU data cube fits file \n",
    "        x1d3 = datamodels.open(root+'_x1d.fits') #1-D Extracted Spectrum            \n",
    "    \n",
    "        #--------------------------------Wavelength & Surface Brightness/Flux Arrays------------------------------\n",
    "    \n",
    "        x1d3wave = x1d3.spec[0].spec_table.WAVELENGTH\n",
    "            \n",
    "        #--------------------------------------Data & Header Information------------------------------------------\n",
    "\n",
    "    \n",
    "        #SCI Extension: [Type:ImageHDU  Cards:92   Dimensions:(57, 61, 973)   Format:float32]\n",
    "        cube = s3d[1].data #Science data\n",
    "        wcs = WCS(s3d[1].header) #World Coordinate System (WCS) Transformation keywords \n",
    "        wmap = s3d[4].data #3-D weight image giving the relative weights of the output spaxels.\n",
    "        cdelt1 = s3d[1].header['CDELT1']*3600. #Axis 1 coordinate increment at reference point \n",
    "        cdelt2 = s3d[1].header['CDELT2']*3600. #Axis 2 coordinate increment at reference point \n",
    "        cdelt3 = s3d[1].header['CDELT3'] #Axis 3 coordinate increment at reference point \n",
    "        crval3 = s3d[1].header['CRVAL3'] #third axis value at the reference pixel  \n",
    "\n",
    "        #Wavelength range of the grating/filter combination\n",
    "        wavstart = s3d[1].header['WAVSTART']\n",
    "        wavend = s3d[1].header['WAVEND']\n",
    "        s3d.close()\n",
    "    \n",
    "        #---------------------------------------------------Plots-------------------------------------------------\n",
    "        \n",
    "        cmap_custom = cm.colors.LinearSegmentedColormap.from_list(\"\", [\"darkred\",\"darkturquoise\",\"blue\"])\n",
    "        colors = cmap_custom(np.linspace(0, 1, np.array(wavelength_slices).size))\n",
    "\n",
    "        #To Account for if NRS1 & NRS2 are both being plotted Side-by-side\n",
    "        if len(wavelength_slices) != 1:\n",
    "            if 'nrs1' in s3d_file:\n",
    "                wavelengths = wavelength_slices[0]\n",
    "                spaxel_loc = spaxel_locs[0]\n",
    "                vmin_vmax_vals = vmin_vmax[0]\n",
    "                \n",
    "                if y_scale:\n",
    "                    y_scales = y_scale[0]\n",
    "\n",
    "            elif 'nrs2' in s3d_file:\n",
    "                wavelengths = wavelength_slices[1]\n",
    "                spaxel_loc = spaxel_locs[1]\n",
    "                vmin_vmax_vals = vmin_vmax[1]\n",
    "                if y_scale:\n",
    "                    y_scales = y_scale[1]\n",
    "\n",
    "        else:\n",
    "            wavelengths = wavelength_slices[0]\n",
    "            spaxel_loc = spaxel_locs[0]\n",
    "            vmin_vmax_vals = vmin_vmax[0]\n",
    "            if y_scale:\n",
    "                    y_scales = y_scale[0]\n",
    "\n",
    "            \n",
    "        #Loop through each wavelength slices\n",
    "        for i, wave_slice in enumerate(wavelengths):\n",
    "\n",
    "            if float(wavstart)<=wave_slice*10**-6<=float(wavend):\n",
    "                \n",
    "                #--------------------------------------------2-D Cube Slice------------------------------------------------\n",
    "            \n",
    "                #Min & Max Image Values & Scaling\n",
    "                if len(vmin_vmax_vals) != 1:\n",
    "                    vmax_val = vmin_vmax_vals[i][1]\n",
    "                    vmin_val = vmin_vmax_vals[i][0]\n",
    "                else:\n",
    "                    vmax_val = vmin_vmax_vals[0][1]\n",
    "                    vmin_val = vmin_vmax_vals[0][0]\n",
    "\n",
    "                slicewave = wave_slice\n",
    "                nslice = int((slicewave - crval3)/cdelt3) #the slice of the cube we want to plot\n",
    "                ax1 = plt.subplot(gs[0+plot_count], projection=wcs, slices=('x', 'y', nslice)) #set up the subplot space\n",
    "                #ax1 = plt.subplot(3,len(wavelength_slices), 0+plot_count, projection=wcs, slices=('x', 'y', nslice)) #set up the subplot space\n",
    "\n",
    "                slice_mean = np.nanmean(cube[(nslice-2):(nslice+2), :, :], axis=0) #Mean of the slice looking in the range (nslice-2):(nslice+2)\n",
    "                slice_norm=ImageNormalize(slice_mean, vmin=vmin_val, vmax=vmax_val, stretch=AsinhStretch()) #normalize &stretch \n",
    "                slice_image= ax1.imshow(slice_mean, norm=slice_norm, origin='lower', aspect='auto',cmap=cmap) #plot slice\n",
    "\n",
    "                cb_image = fig.colorbar(slice_image, fraction=0.046, pad=0.04)\n",
    "                cb_image.set_label('MJy/sr', labelpad=-1, fontsize = 22)\n",
    "                cb_image.ax.tick_params(labelsize=20)\n",
    "                cb_image.ax.yaxis.get_offset_text().set_fontsize(20)\n",
    "                \n",
    "                ax1.set_xlabel('RA', fontsize =22)\n",
    "                ax1.set_ylabel('DEC', labelpad=-1, fontsize=22)\n",
    "                #ax1.grid(color='white', ls='solid')\n",
    "                ax1.set_title('Detector {} \\n Grating/Filter: {}/{} \\n {} microns'.format(s3d[0].header['DETECTOR'],s3d[0].header['GRATING'], s3d[0].header['FILTER'], str(slicewave)), fontsize =25)\n",
    "                ax1.tick_params(axis='both', which='major', labelsize=20)\n",
    "                ax1.coords[0].set_ticklabel(rotation=13, ha='right', pad=24)\n",
    "\n",
    "               \n",
    "                #------------------------------------------Spaxel 1-D Spectrum---------------------------------------------\n",
    "                \n",
    "                #Zoom in on a Spaxel: Spectrum\n",
    "                loc = [spaxel_loc[i][0],spaxel_loc[i][1]]\n",
    "                x1d3flux_loc = cube[:, loc[1], loc[0]]\n",
    "                #ax2 = plt.subplot(3,len(wavelength_slices), int(total_num_plots/3)+plot_count)\n",
    "                ax2 = plt.subplot(gs[int(total_num_plots/3)+plot_count])\n",
    "\n",
    "                #Spaxel Box Highlight \n",
    "                spaxel_rect = plt.Rectangle((loc[0]-.5, loc[1]-.5), 1,1, fill=False, color='black', linewidth=2)\n",
    "                ax1.add_patch(spaxel_rect)\n",
    "                \n",
    "                ax2.plot(x1d3wave, x1d3flux_loc, linewidth=1, color=colors[i])\n",
    "                ax2.grid(linewidth=2)\n",
    "                ax2.set_xlabel('$\\u03BB [\\u03BC$m]',fontsize=22)\n",
    "                ax2.set_ylabel(\"Surface Brightness \\n (MJy/sr)\",fontsize=22)\n",
    "                ax2.set_title('Spaxel at (x, y)='+repr(loc), fontsize=25)\n",
    "                ax2.tick_params(axis='both', which='major', labelsize=20)\n",
    "                ax2.yaxis.get_offset_text().set_fontsize(15)\n",
    "                \n",
    "                #Scale Information\n",
    "                if y_scale:\n",
    "                    ymin, ymax = y_scales[i][0], y_scales[i][1]\n",
    "                else:\n",
    "                    ymin, ymax = ax2.set_ylim()\n",
    "                \n",
    "                ax2.set_ylim(ymin, ymax)\n",
    "                ax2.xaxis.set_tick_params(labelsize=20)\n",
    "                ax2.yaxis.set_tick_params(labelsize=20)\n",
    "                ax2.set_aspect(0.5/ax2.get_data_ratio())\n",
    "                \n",
    "                #-----------------------------------------------Weight Map-------------------------------------------------\n",
    "                \n",
    "                #Corresponding Weight Map (wmap) for Cube Slice\n",
    "                ax3 = plt.subplot(gs[int(total_num_plots)-np.array(wavelength_slices).size+plot_count], projection=wcs, slices=('x', 'y', nslice)) #set up the subplot space\n",
    "                #ax3 = plt.subplot(3, len(wavelength_slices), int(total_num_plots)-len(wavelength_slices)+plot_count, projection=wcs, slices=('x', 'y', nslice)) #set up the subplot space\n",
    "                \n",
    "                slice_mean_wmap = np.nanmean(wmap[(nslice-2):(nslice+2), :, :], axis=0) #Mean of the wmap slice looking in the range (nslice-2):(nslice+2)\n",
    "                slice_norm_wmap=ImageNormalize(slice_mean_wmap, stretch=AsinhStretch()) #normalize &stretch\n",
    "                slice_wmap = ax3.imshow(slice_mean_wmap, norm=slice_norm_wmap, origin='lower',aspect='auto', cmap=cmap) #plot slice\n",
    "\n",
    "                cb_wmap = fig.colorbar(slice_wmap, fraction=0.046, pad=0.04)\n",
    "                cb_wmap.set_label('Weight', labelpad=-1, fontsize = 22)\n",
    "                cb_wmap.ax.tick_params(labelsize=20)\n",
    "                cb_wmap.ax.yaxis.get_offset_text().set_fontsize(20)\n",
    "                \n",
    "                ax3.set_xlabel('RA', fontsize=22)\n",
    "                ax3.set_ylabel('DEC', labelpad=-1, fontsize=22)\n",
    "                #ax3.grid(color='gray', ls='solid')\n",
    "                ax3.set_title(str(slicewave)+' microns: Weight Map', fontsize=25)\n",
    "                ax3.tick_params(axis='both', which='major', labelsize=20)\n",
    "                ax3.coords[0].set_ticklabel(rotation=13, ha='right', pad=24)\n",
    "\n",
    "                plot_count += 1\n",
    "                    \n",
    "            else:\n",
    "                None\n",
    "    \n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=title_font)\n",
    "        plt.subplots_adjust(top=0.8) \n",
    "    \n",
    "    # fig.tight_layout(rect=[0, 0, 0.98, 0.98])\n",
    "\n",
    "    if save_figure == True:\n",
    "        fig.savefig(root+\".png\",dpi=24, bbox_inches=\"tight\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347a9a54",
   "metadata": {},
   "source": [
    "## 4. Directory Set-Up and defining some base parameters <a id='dir_setup'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Warning:</b> Note: For this JWebbinar we pre-computed **all but one** products for [calwebb_detector1](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_detector1.html#calwebb-detector1) and [calwebb_spec2](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipelin/calwebb_spec2.html#calwebb-spec2) to save time. Those will be copied into the output folder. If `jwebbinar = False` **ALL** products are created, which can take a significant amount of time. For [calwebb_spec3](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_spec3.html#calwebb-spec3) this is not possible since all products are needed to create the final datacube. Here we only reduce the G235H/F170LP grating. The G140H/F100LP and G395H/F290LP gratings are also pre-computed and compied into the output folder for `jwebbinar = True`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3b8450-0e55-462e-9705-f99d0633f133",
   "metadata": {},
   "outputs": [],
   "source": [
    "jwebbinar = True\n",
    "\n",
    "if not jwebbinar:\n",
    "    print('')\n",
    "    print('JWebbinar is deactivated: ALL OBSERATIONS WILL BE REDUCED!!!')\n",
    "\n",
    "hub_root = \"/home/shared/preloaded-fits/jwebbinar-28\"\n",
    "user_root = \"/home/jovyan/jwebbinar_prep/jwebbinar28\"\n",
    "\n",
    "# basedir = os.path.join(os.getcwd(),'nirspec_ifu_extended_source')\n",
    "basedir_in = os.path.join(hub_root,'nirspec_ifu_extended_source')\n",
    "basedir_out = os.path.join(user_root,'nirspec_ifu_extended_jwebbinar28')\n",
    "output_dir = os.path.join(basedir_out,'run_folder')\n",
    "mast_products_dir = os.path.join(basedir_in,'mast_products')\n",
    "pre_computed_run_dir = os.path.join(basedir_in,'pre_computed_run')\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "if not os.path.exists(mast_products_dir):\n",
    "    os.makedirs(mast_products_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7417b52c-72ca-4360-9340-f1b2657f1c0a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Warning:</b> Note: To allow everyone to get the same results we fixed the used PMAP to `jwst_1146.pmap`. To save download time we also provide the CRDS cache and to not overwrite any of your systems settings we saved the cache in  \"../crds_cache\". The following commands\n",
    "`os.environ['CRDS_PATH'] = \"./crds_cache\"`, and\n",
    "`os.environ['CRDS_CONTEXT'] = 'jwst_1146.pmap'`\n",
    "overwrite the system settings for **THIS NOTEBOOK ONLY**. To run the notebook with the latest reference files these two lines should be commented out\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65533a2c-5243-43fa-9f7c-c3d446e61f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('')\n",
    "print(\"Setting up the CRDS-cache and pmap\")\n",
    "\n",
    "'''\n",
    "The following should be uncommented to used the already cached files to save \n",
    "download time. Set if different to default set in bash_rc file. The CRDS_CONTEXT\n",
    "ensures that everybody uses the same pmap for this exercise.\n",
    "This MUST commented out to ensure that the latest reference files in CRDS\n",
    "will be used\n",
    "'''\n",
    "\n",
    "os.environ['CRDS_PATH'] = \"/home/jovyan/crds_cache\" \n",
    "os.environ['CRDS_CONTEXT'] = 'jwst_1146.pmap' ### \n",
    "\n",
    "print('CRDS-cache is set to:', os.getenv('CRDS_PATH'))\n",
    "print(\"Current activated CRDS Context = {}\".format(os.getenv('CRDS_CONTEXT')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad6ed15",
   "metadata": {},
   "source": [
    "## 5. Download the Data <a id='data'></a>\n",
    "\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "| Target: Tarantula Nebula |       |   |   |   |\n",
    "|:-----------:|:-------:|:---:|---|---|\n",
    "| Proposal ID | 02729 |   |   |   |\n",
    "| [GRATING/FILTER](https://jwst-docs.stsci.edu/jwst-near-infrared-spectrograph/nirspec-observing-modes/nirspec-ifu-spectroscopy) | G140H/F100LP | λ: 0.97–1.89 μm (a medium resolution, R ~ 1000) |   |   |\n",
    "|                | G235H/F170LP | λ: 1.66–3.17 μm (a high resolution, R ~ 2700) |   |   |\n",
    "|                | G395H/F290LP | λ: 2.87–5.27 μm (a high resolution, R ~ 2700) |   |   |\n",
    "|   DURATION  | 87.533 [s] | Total duration of one exposure |   |   |   |\n",
    "|   READPATT  | NRSIRS2RAPID | Readout Pattern |   |   |   |\n",
    "|   PATTTYPE  | CYCLING | Primary dither pattern type |   |   |\n",
    "|   PATTSIZE  | LARGE | Primary dither pattern size (1.0\" extent) |   |   |\n",
    "|   NUMDTHPT  | 8 | Total number of points in pattern |   |   | \n",
    "|   SRCTYAPT  | UNKNOWN | Source Type selected in APT |   |   | \n",
    "\n",
    "> **Note:** The presence of a physical gap between detectors affects high-resolution IFU observations because the spectra are long enough to span both NIRSpec detectors. When using the grating-filter combination G140H/F070LP, PRISM/CLEAR, or the M-gratings, the resulting spectra do not have any gaps because the spectra do not extend beyond NRS1. [More Info ...](https://jwst-docs.stsci.edu/jwst-near-infrared-spectrograph/nirspec-operations/nirspec-ifu-operations/nirspec-ifu-wavelength-ranges-and-gaps#NIRSpecIFUWavelengthRangesandGaps-Wavelengthgaps)\n",
    "\n",
    "MAST products have already been pre-downloaded and stored in a provided demo directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30347914",
   "metadata": {},
   "source": [
    "## 6. Products Found In MAST <a id='mast_products'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "Here we show and plot the products as they are provided in MAST. This will also demonstrate why in most science cases reprocessing the data is needed.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Tip:</b> To optimally use your science data some parameters need to be uniquly tweaked specifically for your observations. No parameter setting wil be sufficient for **all** data.\n",
    "    \n",
    "</div> \n",
    "\n",
    "> In [APT](https://jwst-docs.stsci.edu/jwst-astronomers-proposal-tool-overview), the observer has three options for source type (`SRCTYAPT` keyword): `POINT`, `EXTENDED`, or `UNKNOWN`. In stage 2, the `srctype` step will first check if the `SRCTYAPT` keyword is present and populated. If `SRCTYAPT` is not present or is set to `UNKNOWN`, the step determines a suitable value based on the observing mode, command line input, and other characteristics of the exposure. If the exposure is identified as a background exposure (`BKGDTARG = True`), the exposures default to a source type of `EXTENDED`. Exposures that are part of a nodded pattern (identified by keyword `PATTYPE`), which are assumed to only be used with point-like targets, default to a source type of `POINT`. [More Info ...](https://jwst-pipeline.readthedocs.io/en/latest/jwst/srctype/description.html#single-source-observations)\n",
    "\n",
    "For dithered NIRSpec IFU data like ours, which do not meet any of the above conditions, will default to source type `EXTENDED`. <mark> Therefore, the products found in MAST for target Tarantula Nebula (PID 2729) have been processed as an `EXTENDED` source </mark>. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc34c69",
   "metadata": {},
   "source": [
    "### 6.1 Stage 1 Products Found In MAST  <a id='level1_mast'></a>\n",
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a64f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 1 slope products -- level 2a images\n",
    "\n",
    "#Plot 4th (out of 8) dither position (spectra fall on both NRS1 & NRS2) for GRATING/FILTER G235H/F170LP combination  \n",
    "\n",
    "file = glob.glob(os.path.join(mast_products_dir, '*02103*00004_nrs1_rate.fits'))[0]\n",
    "print('rate file: ',file)\n",
    "ratefile_open = datamodels.open(file)\n",
    "ratefile_sci = ratefile_open.data #get the pixel data (the SCI extension of the fits file)\n",
    "ratefile_dq = ratefile_open.dq #data quality map data (DQ extension)\n",
    "             \n",
    "#Plot the slope image and small section of the countrate image & corresponding section of the DQ map\n",
    "show_image(ratefile_sci, 0,10, units='DN/s',zoom_in=[650,700, 1250,1300], ysize=20, xsize=20,\n",
    "           title='Countrate Image \\n Detector: {} \\n 8-Cycle Dither Position Index: {} \\n GRATING/FILTER: {}/{}'.format(ratefile_open.meta.instrument.detector,\n",
    "                                                                                                                        ratefile_open.meta.dither.position_number, \n",
    "                                                                                                                        ratefile_open.meta.instrument.grating,\n",
    "                                                                                                                        ratefile_open.meta.instrument.filter)) #rate files have units of DN/s\n",
    " \n",
    "show_image(ratefile_dq, 0, 10, units='Bit Value', scale='linear',zoom_in=[650,700, 1250,1300], ysize=20, xsize=20,\n",
    "           title='Data Quality Map \\n Detector: {} \\n 8-Cycle Dither Position Index: {} \\n GRATING/FILTER: {}/{}'.format(ratefile_open.meta.instrument.detector,\n",
    "                                                                                                                        ratefile_open.meta.dither.position_number, \n",
    "                                                                                                                        ratefile_open.meta.instrument.grating,\n",
    "                                                                                                                        ratefile_open.meta.instrument.filter)) \n",
    "\n",
    "file = glob.glob(os.path.join(mast_products_dir, '*02103*00004_nrs2_rate.fits'))[0]\n",
    "print('rate file: ',file)\n",
    "ratefile_open = datamodels.open(file)\n",
    "ratefile_sci = ratefile_open.data #get the pixel data (the SCI extension of the fits file)\n",
    "ratefile_dq = ratefile_open.dq #data quality map data (DQ extension)\n",
    "             \n",
    "#Plot the slope image and small section of the countrate image & corresponding section of the DQ map\n",
    "\n",
    "show_image(ratefile_sci, 0,10, units='DN/s',zoom_in=[650,700, 1720,1770], ysize=20, xsize=20,\n",
    "           title='Countrate Image \\n Detector: {} \\n 8-Cycle Dither Position Index: {} \\n GRATING/FILTER: {}/{}'.format(ratefile_open.meta.instrument.detector,\n",
    "                                                                                                                        ratefile_open.meta.dither.position_number, \n",
    "                                                                                                                        ratefile_open.meta.instrument.grating,\n",
    "                                                                                                                        ratefile_open.meta.instrument.filter)) #rate files have units of DN/s\n",
    " \n",
    "show_image(ratefile_dq, 0, 10, units='Bit Value', scale='linear',zoom_in=[650,700, 1720,1770], ysize=20, xsize=20,\n",
    "           title='Data Quality Map \\n Detector: {} \\n 8-Cycle Dither Position Index: {} \\n GRATING/FILTER: {}/{}'.format(ratefile_open.meta.instrument.detector,\n",
    "                                                                                                                        ratefile_open.meta.dither.position_number, \n",
    "                                                                                                                        ratefile_open.meta.instrument.grating,\n",
    "                                                                                                                        ratefile_open.meta.instrument.filter)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217a5889",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    \n",
    "<b>Warning:</b> Please be aware that in the countrate (slope) images found in MAST, many pixels are flagged as Do Not Use (more clearly seen in the corresponding DQ map) and therefore appear white with a value of NaN. This excessive flagging is due to an outdated mask reference file that would mark unreliable slope, bad fit, and telegraph pixels as Do Not Use. Despite the large number of NaNs in the countrate image, the extracted spectra are not significantly affected by them when combining multiple dithered exposures because the number of flagged pixels is still a relatively small fraction. However, due to the high number of flags in the MAST products, it is difficult to see specific details in the slope images, like correlated read noise, which manifests as low-level vertical banding/striping and a \"picture frame\" with the [$IRS^{2}$](https://jwst-docs.stsci.edu/jwst-near-infrared-spectrograph/nirspec-instrumentation/nirspec-detectors/nirspec-detector-readout-modes-and-patterns/nirspec-irs2-detector-readout-mode) readout mode. As of context jwst_1084.pmap, the pipeline now considers unreliable slope, bad fit, and telegraph pixels good for further processing in Full frame data. [Therefore, the reprocessed data below offers improved visibility of the correlated read noise.](#level1_rerun)\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    \n",
    "<b>Warning:</b> Please be aware that many exposures are suffering from snowballs (see NRS2 in the above plot) which are caused by large cosmic ray events (https://jwst-docs.stsci.edu/data-artifacts-and-features/snowballs-and-shower-artifacts). To mitigate this ``expand_large_events`` needs to be set to `True` in the jump_detection algorithm of the `callwebb_detector1` step. This is currently deactivate by default hence a rerun is needed. This is especially important for deep exposures with long integration times. A rough estimate is 1 snowball per detector per 20s.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941f42ed",
   "metadata": {},
   "source": [
    "### 6.2 Stage 2 Products Found In MAST  <a id='level2_mast'></a>\n",
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b37ffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 2 Products -- Calibrated 3-D data cubes for each GRATING/FILTER combination\n",
    "\n",
    "#Plotting the 4th (out of 8) dither position for both NRS1 and NRS2\n",
    "s3d_g140h_stage2 = sorted(glob.glob(os.path.join(mast_products_dir, '*2105*00004_nrs?_s3d.fits')))\n",
    "s3d_g235h_stage2 = sorted(glob.glob(os.path.join(mast_products_dir, '*2103*00004_nrs?_s3d.fits')))\n",
    "s3d_g395h_stage2 = sorted(glob.glob(os.path.join(mast_products_dir, '*2101*00004_nrs?_s3d.fits')))\n",
    "s3d_stage2_list = s3d_g140h_stage2+s3d_g235h_stage2+s3d_g395h_stage2\n",
    "\n",
    "title_stage2_mast='Tarantula Nebula \\n Level 2 IFU Product: 3-D Cube Slices vs. Corresponding 3-D Weighted Map'\n",
    "\n",
    "#Characteristics of the plot \n",
    "nrs1_wavelengths = [1.0,2.3,3.4] #Wavelength slices (microns) to take from the 3-D data cube\n",
    "nrs2_wavelengths = [1.4,2.5,4.0]\n",
    "\n",
    "nrs1_spaxel_locs = [[30,29],[28,39],[14,25]] #Spaxel locations for associated 1-D spectrum (one spaxel plotted per slice)\n",
    "nrs2_spaxel_locs = [[30,29],[28,39],[14,25]]\n",
    "\n",
    "nrs1_vmin_vmax = [[0,2e2],[0,1e2],[0,1.2e3]] #Minimum & Maximum signal values for scaling each slice\n",
    "nrs2_vmin_vmax = [[0,2e2],[0,1e2],[0,1.2e3]]\n",
    "\n",
    "nrs1_yscales = [[-80,150], [-80,150], [-80,200]] #Spaxel plot y-limits\n",
    "nrs2_yscales = [[-80,200], [-80,150], [-80,200]]\n",
    "\n",
    "#Plot using the convience function defined above\n",
    "show_ifu_cubeslices(s3d_stage2_list, wavelength_slices=[nrs1_wavelengths,nrs2_wavelengths], \n",
    "                    spaxel_locs=[nrs1_spaxel_locs,nrs2_spaxel_locs],vmin_vmax=[nrs1_vmin_vmax,nrs2_vmin_vmax], \n",
    "                    y_scale = [nrs1_yscales,nrs2_yscales], title=title_stage2_mast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e44863",
   "metadata": {},
   "source": [
    "### 6.3 Stage 3 Products Found In MAST  <a id='level3_mast'></a>\n",
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94514cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 3 Products -- Combined Calibrated 3-D data cubes for each GRATING/FILTER combination\n",
    "\n",
    "s3d_stage3_list = sorted(glob.glob(os.path.join(mast_products_dir, '*nirspec*_s3d.fits')))\n",
    "\n",
    "title_stage3_mast='Tarantula Nebula \\n Level 3 IFU Product: 3-D Cube Slices vs. Corresponding 3-D Weighted Map'\n",
    "\n",
    "#Characteristics of the plot \n",
    "wavelengths = [1.4,2.3,4.0] #Wavelength slices (microns) to take from the combined 3-D data cube\n",
    "spaxel_locs = [[29,32],[29,32],[29,32]] #Spaxel locations for associated 1-D spectrum (one spaxel plotted per slice)\n",
    "vmin_vmax = [[0,2e2],[0,1e2],[0,1.2e3]] #Minimum & Maximum signal values for scaling each slice\n",
    "yscales = [[0,2e3], [0,7e3], [0,2e4]]\n",
    "\n",
    "#Plot using the convience function defined above\n",
    "show_ifu_cubeslices(s3d_stage3_list, wavelength_slices=[wavelengths],spaxel_locs=[spaxel_locs],\n",
    "                    vmin_vmax=[vmin_vmax], y_scale = [yscales], title=title_stage3_mast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bff147-5b78-4a72-aa5d-ea013e6b9ac6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    \n",
    "<b>Warning:</b> Please note that in the final product (stage 3) downloaded from MAST, a significant portion of the data got rejected, returning a value of zero in the weight maps. This over-rejection of data is due to the outdated `outlier_detection` step that MAST automatically enables during stage 3 of the pipeline. A new outlier detection algorithm has been developed specifically for IFU data that overcomes some of these limitations (as of DMS build B9.3rc1/CAL_VER 1.11.0). Due to the limitations of the previous outlier detection algorithm, the user recommendation is to skip the `outlier_detection` step if using an older version of the pipleine or manually rerun stage 3 of the pipleine with outlier detection on with the most up-to-date pipeline version (detailed in the next section of this notebook).\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> \n",
    "When the source type is extended, the default extraction aperture for the `extract_1d` step covers the entire cube.\n",
    "Since also pixels at the edges of the FoV are used where often only 1 or 2 dither positions are available, the 1D spectrum also contains contributions from regions where the outlier rejection cannot work properly due to the lack of data. Therefore, we are extracting an arbitrary box of 4x4 spaxels (y: 29 to 33 and x: 27 to 30). Typically users are not collapsing their cubes to create a single spectrum for an extended source when using IFU data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d54809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just a check to see what verison of the pipeline and what pmap was used\n",
    "x1d3_mast = fits.open(glob.glob(os.path.join(mast_products_dir, '*_x1d.fits'))[0])\n",
    "\n",
    "print(\"Products found in MAST used JWST calibration pipeline version: {} and {}\".format(x1d3_mast[0].header['CAL_VER'],x1d3_mast[0].header['CRDS_CTX']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1b09ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 3 Products -- Combined Extracted 1-D Spectrum \n",
    "\n",
    "fig = plt.figure(figsize=(15,9))\n",
    "colors = ['darkred', 'darkturquoise', 'blue']\n",
    "\n",
    "x1d3_mast_list = sorted(glob.glob(os.path.join(mast_products_dir, '*nirspec*_x1d.fits')))\n",
    "\n",
    "s3d_mast_list = sorted(glob.glob(os.path.join(mast_products_dir, '*nirspec*_s3d.fits')))\n",
    "\n",
    "\n",
    "for i, x1d3_file in enumerate(x1d3_mast_list):\n",
    "    x1d3_file_open = datamodels.open(x1d3_file) \n",
    "    cube = fits.open(s3d_mast_list[i])['SCI'].data\n",
    "\n",
    "    #Wavelength & Surface Brightness Arrays\n",
    "    x1d3wave_mast = x1d3_file_open.spec[0].spec_table.WAVELENGTH\n",
    "    x1d3flux_mast = x1d3_file_open.spec[0].spec_table.SURF_BRIGHT\n",
    "\n",
    "    plt.plot(x1d3wave_mast,np.mean(cube[:, 29:34,27:31], axis=(1,2)),color=colors[i], linewidth =2, label='Grating/Filter: {}/{}'.format(x1d3_file_open.meta.instrument.grating,\n",
    "                                                                                             x1d3_file_open.meta.instrument.filter))\n",
    "\n",
    "plt.xlabel('$\\lambda [\\mu$m]', fontsize =15)\n",
    "plt.ylabel('Surface Brightness (MJy/sr)', fontsize =15)\n",
    "plt.title(\"Tarantula Nebula \\n Level 3 IFU Product in MAST: Extracted 1-D Spectrum\", fontsize =20)\n",
    "plt.ylim(-1e1, 5e3)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b899f0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    \n",
    "<b>Warning:</b> Most of the large negative and positive flux spikes extending beyond the plot range are likely due to bad/hot pixels that are not flagged in the current DQ masks. The mask reference file gets directly pulled from CRDS. The products found in MAST use a specific CRDS context (.pmap) when processing data. However, the CRDS is constantly updating the operational .pmap.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de115eed",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    \n",
    "<b>Warning:</b> The systematically lower flux \\& wavy continua in the red portions of the spectrum from each grating are artifacts due to correlated read noise. This is apparent in the full frame images, manifesting as vertical banding often accompanied by a \"picture frame\" effect, and is caused by low-level detector instabilities that even the $IRS^{2}$ algorithm cannot remove. The effect is typically only noticeable in read-noise limited data, and is most prominent on the NRS2 detector. The pipeline currently does not apply any correction for this, but there is an external algorithm, \"NSClean\", developed by Bernie Rauscher at GSFC, that is available to the public; see https://webb.nasa.gov/content/forScientists/publications.html#NSClean for details.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842a8837",
   "metadata": {},
   "source": [
    "## 7. Re-processing the Data <a id='reprocessing'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> Many parameter we show in the below examples are set to the default ones. This should only provide an overview over some of the most common parameters that can be adjusted to get the best out of the science **but** often they require a few iterations to find the best possible parameter set for a given observation. \n",
    "</div>\n",
    "\n",
    "Due to lengthy processing times, only one exposure of the observations (G235H/F170LP) will be re-processed in this demonstration if `jwebbinar=True`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126569cf",
   "metadata": {},
   "source": [
    "### 7.1 Stage 1 Rerun & Products  <a id='level1_rerun'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> The most notebale difference to the MAST products will be the snowball rejection, which are large cosmic ray event. This can be acomplished setting `\"expand_large_events\": True` in the `jump` step. Setting the `\"expand_factor\": 3` seems to be a good value for NIRSpec observations to cover most snowballs. A manual check of the rate files is recommended.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e624ce66-c24d-4206-9dc1-784efbcd2d7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Stage 1 Processing \n",
    "\n",
    "if jwebbinar == True:\n",
    "    filelist = sorted(glob.glob(os.path.join(mast_products_dir, '*02103*00004_nrs?_uncal.fits')))\n",
    "else:\n",
    "    filelist = sorted(glob.glob(os.path.join(mast_products_dir, '*_uncal.fits')))\n",
    "\n",
    "for uncal_file in filelist: \n",
    "    print(\"Applying Stage 1 Corrections & Calibrations to: \"+ os.path.basename(uncal_file))\n",
    "\n",
    "    result = Detector1Pipeline.call(uncal_file,\n",
    "                                    save_results = True,\n",
    "                                    output_dir = output_dir,\n",
    "                                    steps = {\"jump\":{\"skip\": False,\n",
    "                                                     \"expand_large_events\": True, ### this activates the snowball rejection\n",
    "                                                     \"maximum_cores\": \"all\", ### you can limit the number of used CPUs here\n",
    "                                                     \"expand_factor\": 3, ### the non default value 3 seems to be better for NIRSpec to mask the full region\n",
    "                                                     # \"rejection_threshold\": 4.0,\n",
    "                                                     # \"four_group_rejection_threshold\": 5.0,\n",
    "                                                     # \"flag_4_neighbors\": True,\n",
    "                                                     # \"max_jump_to_flag_neighbors\": 200,\n",
    "                                                     # \"min_jump_to_flag_neighbors\": 10,\n",
    "                                                     # \"edge_size\": 4,\n",
    "                                                     # \"sat_expand\": 0.,\n",
    "                                                     # \"sat_required_snowball\": False,\n",
    "                                                     # \"min_jump_area\": 2.,\n",
    "                                                     \"save_results\": True,\n",
    "                                                     },\n",
    "                                             \"refpix\": {\"skip\": False,\n",
    "                                                        \"odd_even_columns\": True,\n",
    "                                                        # \"use_side_ref_pixels\": True,\n",
    "                                                        # \"side_smoothing_lenght\": 11,\n",
    "                                                        # \"side_gain\": 1.0,\n",
    "                                                        \"ovr_corr_mitigation_ftr\": 3.0\n",
    "                                                       },\n",
    "                                             \"ramp_fit\": {\"skip\": False,\n",
    "                                                         \"suppress_one_group\": False,\n",
    "                                                         \"maximum_cores\": 'all'\n",
    "                                                         },\n",
    "                                             \"saturation\": {\"skip\": False,\n",
    "                                                           \"n_pix_grow_sat\": 1\n",
    "                                                           },\n",
    "                                             \n",
    "                                             })\n",
    "\n",
    "\n",
    "if jwebbinar == True:\n",
    "\n",
    "    pre_computed_filelist = sorted(glob.glob(os.path.join(pre_computed_run_dir, '*_rate*.fits')))\n",
    "    for file in pre_computed_filelist:\n",
    "        output = os.path.join(output_dir, os.path.basename(file))\n",
    "        print(file, ' => ', output)\n",
    "        shutil.copy(file, output)\n",
    "\n",
    "print(\"Hurray ...  this step has been completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da176563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 1 slope products -- level 2a images\n",
    "\n",
    "#Plot 1 dither position (spectra fall on both NRS1 & NRS2) for GRATING/FILTER G235H/F170LP combination  \n",
    "\n",
    "file = glob.glob(os.path.join(output_dir, '*02103*00004_nrs1_rate.fits'))[0]\n",
    "print(\"rate file: \", file)\n",
    "\n",
    "ratefile_open = datamodels.open(file)\n",
    "ratefile_sci = ratefile_open.data #get the pixel data (the SCI extension of the fits file)\n",
    "ratefile_dq = ratefile_open.dq #data quality map data (DQ extension)\n",
    "             \n",
    "#Plot the slope image and small section of the countrate image & corresponding section of the DQ map\n",
    "\n",
    "show_image(ratefile_sci, 0,10, units='DN/s',zoom_in=[650,700, 1250,1300], ysize=20, xsize=20,\n",
    "           title='Countrate Image \\n Detector: {} \\n 8-Cycle Dither Position Index: {} \\n GRATING/FILTER: {}/{}'.format(ratefile_open.meta.instrument.detector,\n",
    "                                                                                                                        ratefile_open.meta.dither.position_number, \n",
    "                                                                                                                        ratefile_open.meta.instrument.grating,\n",
    "                                                                                                                        ratefile_open.meta.instrument.filter)) #rate files have units of DN/s\n",
    " \n",
    "show_image(ratefile_dq, 0, 10, units='Bit Value', scale='linear',zoom_in=[650,700, 1250,1300], ysize=20, xsize=20,\n",
    "           title='Data Quality Map \\n Detector: {} \\n 8-Cycle Dither Position Index: {} \\n GRATING/FILTER: {}/{}'.format(ratefile_open.meta.instrument.detector,\n",
    "                                                                                                                        ratefile_open.meta.dither.position_number, \n",
    "                                                                                                                        ratefile_open.meta.instrument.grating,\n",
    "                                                                                                                        ratefile_open.meta.instrument.filter)) \n",
    "\n",
    "file = glob.glob(os.path.join(output_dir, '*02103*00004_nrs2_rate.fits'))[0]\n",
    "print(\"rate file: \", file)\n",
    "\n",
    "ratefile_open = datamodels.open(file)\n",
    "ratefile_sci = ratefile_open.data #get the pixel data (the SCI extension of the fits file)\n",
    "ratefile_dq = ratefile_open.dq #data quality map data (DQ extension)\n",
    "\n",
    "#Plot the slope image and small section of the countrate image & corresponding section of the DQ map\n",
    "show_image(ratefile_sci, 0,10, units='DN/s',zoom_in=[650,700, 1720,1770], ysize=20, xsize=20,\n",
    "           title='Countrate Image \\n Detector: {} \\n 8-Cycle Dither Position Index: {} \\n GRATING/FILTER: {}/{}'.format(ratefile_open.meta.instrument.detector,\n",
    "                                                                                                                        ratefile_open.meta.dither.position_number, \n",
    "                                                                                                                        ratefile_open.meta.instrument.grating,\n",
    "                                                                                                                        ratefile_open.meta.instrument.filter)) #rate files have units of DN/s\n",
    " \n",
    "show_image(ratefile_dq, 0, 10, units='Bit Value', scale='linear',zoom_in=[650,700, 1720,1770], ysize=20, xsize=20,\n",
    "           title='Data Quality Map \\n Detector: {} \\n 8-Cycle Dither Position Index: {} \\n GRATING/FILTER: {}/{}'.format(ratefile_open.meta.instrument.detector,\n",
    "                                                                                                                        ratefile_open.meta.dither.position_number, \n",
    "                                                                                                                        ratefile_open.meta.instrument.grating,\n",
    "                                                                                                                        ratefile_open.meta.instrument.filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84c9f5b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> Compared to the [countrate (slope) products found in MAST](#level1_mast), fewer pixels are flagged as Do Not Use when using the most up-to-date pmap in CRDS. With the latest pmap, one can observe low-level vertical banding in the central regions of the detector, and the \"picture frame\" towards the edge of both detectors, where there is less correlated read noise a lot easier. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf378c9d",
   "metadata": {},
   "source": [
    "### 7.2 Stage 2 Rerun & Products  <a id='level2_rerun'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "\n",
    "During stage 2 of the pipeline, the countrate (slope) image products from stage 1, which have units of DN/s, are converted to units of surface brightness (MJy/sr) for both extended and point sources (as of DMS build 9.3/CAL_VER 1.10.2). For extended targets, like the Tarantula Nebula, the `extract_1d` step is controlled by a different set of parameters in the EXTRACT1D reference file: \n",
    "\n",
    "> For an extended source, rectangular aperture photometry is used, with the entire image being extracted, and no background subtraction, regardless of what was specified in the reference file or step arguments. [More Info ...](https://jwst-pipeline.readthedocs.io/en/latest/jwst/extract_1d/description.html)\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Warning:</b> Note there has been a bug in the `cube_build` step that caused the point source flux to not be conserved when using different spatial sampling. A fix has been implemented as of release DMS build 9.3/CAL_VER 1.10.2. In order to enable the correct functionality, the units of the cal.fits files and cubes will now be in surface brightness, and only the 1-D extracted spectra will be in units of Jy.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796a6aab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Stage 2 Processing \n",
    "\n",
    "if jwebbinar == True:\n",
    "    filelist = sorted(glob.glob(os.path.join(output_dir, '*02103*00004_nrs?*rate.fits')))\n",
    "else:\n",
    "    filelist = sorted(glob.glob(os.path.join(output_dir, '*_rate.fits')))\n",
    "\n",
    "#Process each rate file seperately \n",
    "for rate_file in filelist:\n",
    "        \n",
    "    print(\"Applying Stage 2 Calibrations & Corrections to: \"+ os.path.basename(rate_file))\n",
    "    \n",
    "    result = Spec2Pipeline.call(rate_file,\n",
    "                                save_results = True,\n",
    "                                output_dir = output_dir,\n",
    "                                steps = {\"msa_flagging\":{\"skip\": False   ### Masks those pixels that are affected by stuck open MSA shutters\n",
    "                                                         },\n",
    "                                         \"imprint_subtract\":{\"skip\": True    ### This step is needed if LEAKCAL observations were provided\"\n",
    "                                                    },\n",
    "                                         \"bkg_subtract\":{\"skip\": True,    ### This step is needed if background observations were provided\n",
    "                                                       \"sigma\": 3,\n",
    "                                                       \"maxiters\": None,\n",
    "                                                       \"save_combined_background\": False\n",
    "                                                       },\n",
    "                                          \"flat_field\":{\"skip\": False,\n",
    "                                                        \"save_interpolated_flat\": False   ### A flag to indicate whether to save to a file the NIRSpec flat field that was constructed on-the-fly by the step.\n",
    "                                                        },\n",
    "                                         \"pathloss\":{\"skip\": False\n",
    "                                                     },\n",
    "                                         \"photom\":{\"skip\": False   ### photmetric calibration \n",
    "                                                   },\n",
    "                                         \"cube_build\":{\"skip\": False    ### builds the 3D cube for each exposure. This is not necessary in the Spec2 step unless you want to inspect the individual cubes before combining them\n",
    "                                                       },\n",
    "                                         \"extract_1d\":{\"skip\": False   ### Extracts the 1D spectra for each exposure . Is not necessary in the Spec2 step unless you want to inspect the individual extracted spectra\n",
    "                                                       }\n",
    "                                         }\n",
    "                                )\n",
    "\n",
    "if jwebbinar == True:\n",
    "\n",
    "    pre_computed_filelist = sorted(glob.glob(os.path.join(pre_computed_run_dir, '*_cal*.fits')))\n",
    "    for file in pre_computed_filelist:\n",
    "        output = os.path.join(output_dir, os.path.basename(file))\n",
    "        print(file, ' => ', output)\n",
    "        shutil.copy(file, output)\n",
    "\n",
    "print(\"Hurray ...  this step has been completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ea3199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 2 Products -- Calibrated 3-D data cubes for each GRATING/FILTER combination\n",
    "\n",
    "#Plotting the 4th (out of 8) dither position for both NRS1 and NRS2\n",
    "s3d_stage2_list = sorted(glob.glob(os.path.join(output_dir, '*2103*00004_nrs?_s3d.fits')))\n",
    "\n",
    "title_stage2_rerun='Tarantula Nebula \\n Level 2 IFU Product: 3-D Cube Slices vs. Corresponding 3-D Weighted Map'\n",
    "\n",
    "#Characteristics of the plot \n",
    "nrs1_wavelengths = [2.3] #Wavelength slices (microns) to take from the 3-D data cube\n",
    "nrs2_wavelengths = [2.5]\n",
    "\n",
    "nrs1_spaxel_locs = [[28,39]] #Spaxel locations for associated 1-D spectrum (one spaxel plotted per slice)\n",
    "nrs2_spaxel_locs = [[28,39]]\n",
    "\n",
    "nrs1_vmin_vmax = [[0,1e2]] #Minimum & Maximum signal values for scaling each slice\n",
    "nrs2_vmin_vmax = [[0,1e2]]\n",
    "\n",
    "nrs1_yscales = [[-80,150]] #Spaxel plot y-limits\n",
    "nrs2_yscales = [[-80,150]]\n",
    "\n",
    "#Plot using the convience function defined above\n",
    "show_ifu_cubeslices(s3d_stage2_list, wavelength_slices=[nrs1_wavelengths,nrs2_wavelengths], \n",
    "                    spaxel_locs=[nrs1_spaxel_locs,nrs2_spaxel_locs],vmin_vmax=[nrs1_vmin_vmax,nrs2_vmin_vmax], \n",
    "                    y_scale = [nrs1_yscales,nrs2_yscales], title=title_stage2_rerun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ac83a4",
   "metadata": {},
   "source": [
    "### 7.3 Stage 3 Rerun & Products  <a id='level3_rerun'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "***Level 3 ASN File***\n",
    "\n",
    "> Observations that use a nod-type/dither patterns, their exposures are related. [Association files (ASN)](https://jwst-pipeline.readthedocs.io/en/stable/jwst/associations/overview.html) describe how multiple exposures are related to one another and how they depend on one another. Processing an ASN file permits exposures to be calibrated, archived, retrieved, and reprocessed as a set rather than individual objects. IFU exposures taken with a dither pattern are not used for pixel-to-pixel background subtraction by the calibration pipeline (unlike exposures taken with a nod pattern).\n",
    "\n",
    "Therefore, all calibration files (`cal.fits`) in our spec3 ASN file should be labeled as science exposures (`exptype: science`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ea47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy ASN file from MAST\n",
    "\n",
    "asnfiles_mast = glob.glob(os.path.join(mast_products_dir, '*_spec3_*_asn.json')) #ASN file found in MAST\n",
    "\n",
    "for file in asnfiles_mast:\n",
    "\n",
    "    asnfile_dest = os.path.join(output_dir, os.path.basename(file))\n",
    "    \n",
    "    print(file, \" => \" , asnfile_dest)\n",
    "    shutil.copy(file, asnfile_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aebc610-ab4d-4321-a323-1b5461cfed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Show the G235H/F170LP ASN file for which we will run CalSpec3\n",
    "\n",
    "asnfile_g140h = glob.glob(os.path.join(output_dir, '*_spec3_00003_asn.json'))[0]\n",
    "asnfile_g235h = glob.glob(os.path.join(output_dir, '*_spec3_00001_asn.json'))[0]\n",
    "asnfile_g395h = glob.glob(os.path.join(output_dir, '*_spec3_00002_asn.json'))[0]\n",
    "\n",
    "with open(asnfile_g235h, 'r') as f_obj:\n",
    "    asnfile_data = json.load(f_obj)\n",
    "\n",
    "JSON(asnfile_data, expanded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3669d28",
   "metadata": {},
   "source": [
    "#### 7.3.1 New Outlier Detection Algorithm<a id='outlier_detection_new'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "The new outlier detection algorithm for IFU data (as of DMS build B9.3rc1/CAL_VER 1.11.0) implements the basic outlier detection algorithm -- searches for pixels that are consistent outliers in the calibrated images created by the `calwebb_spec2` pipeline. The algorithm generally operates as follows:\n",
    "\n",
    "> * Identifies outlier pixels by comparing them with their neighboring pixels in the spatial direction across a set of input files within an association.\n",
    "> * For NIRSpec data, it calculates differences between pixels located above and below each science pixel.\n",
    "> * The pixel differences for every input model in the association are computed and stored in a stack of pixel differences.\n",
    "> * For each pixel, the algorithm determines the minimum difference across this stack and then performs normalization. This normalization process employs a local median derived from the difference array, with the size of the median determined by the kernel size.\n",
    "> * A pixel is flagged as an outlier if this normalized minimum difference is greater than the input threshold percentage. \n",
    "> * Pixels that are found to be outliers are flaged in in the DQ array.\n",
    "> * [More Info ...](https://jwst-pipeline.readthedocs.io/en/latest/jwst/outlier_detection/outlier_detection_ifu.html#outlier-detection-ifu)\n",
    "\n",
    "\n",
    "**[The outlier_detection step for IFU data has the following optional arguments that control the behavior of the processing](https://github.com/spacetelescope/jwst/blob/master/docs/jwst/outlier_detection/arguments.rst):**\n",
    "\n",
    "* `kernel_size` (string, default='7 7'): The size of the kernel to use to normalize the pixel differences. The kernel size must only contain odd values.\n",
    "* `threshold_percent` (float, default=99.8): The threshold (in percent) of the normalized minimum pixel difference used to identify bad pixels. Pixels with a normalized minimum pixel difference above this percentage are flagged as a outlier.\n",
    "* `save_intermediate_results` (boolean, default=False): Specifies whether or not to save any intermediate products created during step processing.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> The default `kernel_size` of **7 7** was developed for MIRI/MRS and tests showed that **3 3** works the better option for NIRSpec.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a12db-7809-4f0d-8e9d-b8d81131e63c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Rerun stage 3\n",
    "\n",
    "if jwebbinar == True:\n",
    "    filelist = [asnfile_g235h]\n",
    "else:\n",
    "    filelist = [asnfile_g140h, asnfile_g235h, asnfile_g395h]\n",
    "\n",
    "for asn_file in filelist:\n",
    "\n",
    "    result = Spec3Pipeline.call(asn_file,\n",
    "                                save_results = True,\n",
    "                                output_dir = output_dir,\n",
    "                                steps = {\"outlier_detection\":{\"skip\": False,\n",
    "                                                              \"save_results\": True,\n",
    "                                                              \"kernel_size\": '3 3',    # the default of 7 7 was developed for MIRI/MRS and from testing 3 3 is the better option for NIRSpec\n",
    "                                                              \"threshold_percent\": 99.8\n",
    "                                                             },\n",
    "                                        \"cube_build\":{\"skip\": False,\n",
    "                                                      # \"gratings\": \"ALL\",      ### “ALL” is used, then all the gratings in the association are used.\n",
    "                                                      # \"output_type\": \"multi\", ### combines data into a single “uber” IFU cube \"\n",
    "                                                      \"weighting\": 'emsm'    ### From testing emsm seems to be working better than drizzle for NIRSpec\n",
    "                                                     },\n",
    "                                        \"extract_1d\":{\"skip\": False\n",
    "                                                      # \"center_xy\" = \"27, 28\"  ### A list of two integer values giving the desired x/y location for the center of the circular extraction aperture,\n",
    "                                                      # \"ifu_autocen\" = True  ### Switch to select whether or not to enable auto-centroiding of the extraction aperture for IFU point sources\n",
    "                                                     }\n",
    "                                        })\n",
    "\n",
    "\n",
    "if jwebbinar == True:\n",
    "\n",
    "    pre_computed_filelist = sorted(glob.glob(os.path.join(pre_computed_run_dir, '*lp_??d.fits')))\n",
    "    for file in pre_computed_filelist:\n",
    "        output = os.path.join(output_dir, os.path.basename(file))\n",
    "        print(file, ' => ', output)\n",
    "        shutil.copy(file, output)\n",
    "\n",
    "print(\"Hurray ...  this step has been completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c93f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 3 Products -- Combined Calibrated 3-D data cubes for GRATING/FILTER combination G235H/F170LP\n",
    "\n",
    "s3d_stage3_list = sorted(glob.glob(os.path.join(output_dir, '*nirspec*_s3d.fits')))\n",
    "\n",
    "title_stage3_mast='Tarantula Nebula \\n Level 3 IFU Product: 3-D Cube Slices vs. Corresponding 3-D Weighted Map'\n",
    "\n",
    "#Characteristics of the plot \n",
    "wavelengths = [1.4,2.3,4.0] #Wavelength slices (microns) to take from the combined 3-D data cube\n",
    "spaxel_locs = [[29,32],[29,32],[29,32]] #Spaxel locations for associated 1-D spectrum (one spaxel plotted per slice)\n",
    "vmin_vmax = [[0,2e2],[0,1e2],[0,1.2e3]] #Minimum & Maximum signal values for scaling each slice\n",
    "yscales = [[0,2e3], [0,7e3], [0,2e4]] #Spaxel plot y-limits\n",
    "\n",
    "#Plot using the convience function defined above\n",
    "show_ifu_cubeslices(s3d_stage3_list, wavelength_slices=[wavelengths],spaxel_locs=[spaxel_locs],\n",
    "                    vmin_vmax=[vmin_vmax], y_scale = [yscales], title=title_stage3_mast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322f8a59",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> In comparison to the [weight maps for the 3-D data cube products found in MAST](#level3_mast), the implementation of the new outlier detection algorithm leads to a notable decrease in data rejection.\n",
    "\n",
    "<b>Note:</b> \n",
    "When the source type is extended, the default extraction aperture for the `extract_1d` step covers the entire cube.\n",
    "Since also pixels at the edges of the FoV are used where often only 1 or 2 dither positions are available, the 1D spectrum also contains contributions from regions where the outlier rejection cannot work properly due to the lack of data. Therefore, we are extracting an arbitrary box of 4x4 spaxels (y: 29 to 33 and x: 27 to 30). Typically users are not collapsing their cubes to create a single spectrum for an extended source when using IFU data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c96634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 3 Products -- Combined Extracted 1-D Spectrum \n",
    "\n",
    "fig = plt.figure(figsize=(15,9))\n",
    "colors = ['darkred', 'darkturquoise', 'blue']\n",
    "\n",
    "x1d3_rerun_list = sorted(glob.glob(os.path.join(output_dir, '*nirspec*_x1d.fits')))\n",
    "s3d_rerun_list = sorted(glob.glob(os.path.join(output_dir, '*nirspec*_s3d.fits')))\n",
    "\n",
    "x1d3_mast_list = sorted(glob.glob(os.path.join(mast_products_dir, '*nirspec*_x1d.fits')))\n",
    "s3d_mast_list = sorted(glob.glob(os.path.join(mast_products_dir, '*nirspec*_s3d.fits')))\n",
    "\n",
    "labels = ['', '', 'MAST product']\n",
    "\n",
    "for i, x1d3_file in enumerate(x1d3_rerun_list):\n",
    "    x1d3_file_open = datamodels.open(x1d3_file) \n",
    "    \n",
    "    #Wavelength & Surface Brightness Arrays\n",
    "    x1d3wave_rerun = x1d3_file_open.spec[0].spec_table.WAVELENGTH\n",
    "    x1d3flux_rerun = x1d3_file_open.spec[0].spec_table.SURF_BRIGHT\n",
    "\n",
    "    cube = fits.open(s3d_rerun_list[i])['SCI'].data\n",
    "    plt.plot(x1d3wave_rerun,np.mean(cube[:, 29:34,27:31], axis=(1,2)),color=colors[i], linewidth =2, label='Grating/Filter: {}/{}'.format(x1d3_file_open.meta.instrument.grating,\n",
    "                                                                                             x1d3_file_open.meta.instrument.filter), zorder=2)\n",
    "    x1d3_mast_file_open = datamodels.open(x1d3_mast_list[i]) \n",
    "    x1d3wave_mast = x1d3_mast_file_open.spec[0].spec_table.WAVELENGTH\n",
    "\n",
    "    mast_cube = fits.open(s3d_mast_list[i])['SCI'].data\n",
    "    plt.plot(x1d3wave_mast,np.mean(mast_cube[:, 29:34,27:31], axis=(1,2)),color='grey',alpha=0.5, linewidth =2, zorder=0, label = labels[i])\n",
    "    \n",
    "\n",
    "#Where wavelength slice was taken above\n",
    "plt.xlabel('$\\lambda [\\mu$m]', fontsize =15)\n",
    "plt.ylabel('Surface Brightness (MJy/sr)', fontsize =15)\n",
    "plt.title(\"Tarantula Nebula \\n Level 3 IFU Product in MAST: Extracted 1-D Spectrum\", fontsize =20)\n",
    "plt.ylim(-1e1, 6e3)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7a3626-71bb-45e5-bc1f-ffeccf930aa4",
   "metadata": {},
   "source": [
    "## Conclusion <a id='conclusion'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "In conclusion, this notebook walks users through processing real data (Tarantula Nebula) from ERO Proposal ID 2729 and comparing automated products in MAST with those generated using the latest version of the JWST calibration pipeline and latest CRDS context. For optimal results, users are strongly encouraged to reprocess their own data using the most recent pipeline version and CRDS context, taking advantage of bug fixes and algorithm improvements (i.e., the new IFU outlier detection algorithm). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass",
   "language": "python",
   "name": "masterclass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
