{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "763e51fb",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src='logo.png' alt=\"logo\" class=\"bg-primary\" align=\"right\" style=\"width: 150px; height: 150px;\"/>\n",
    "</figure>\n",
    "\n",
    "<a id='top'></a>\n",
    "# NIRSpec IFU Pipeline Processing for point sources: ERO 2732 - NGC 7319 AGN\n",
    "<hr style=\"border:3px solid black\"  width=80% align=\"left\">\n",
    "\n",
    "\n",
    "## About this Notebook <a id='about'></a>\n",
    "<hr style=\"border:1px solid gray\" width=80% align=\"left\">\n",
    "\n",
    "**Authors**: Peter Zeidler (zeidler@stsci.edu) based on the work by Kayli Glidic (kglidic@stsci.edu), Maria Pena-Guerrero (pena@stsci.edu), Leonardo Ubeda (lubeda@stsci.edu)\n",
    "\n",
    "**Update On**: 2023-11-28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0d06b8",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [1. Introduction](#intro)\n",
    "* [2. Import Library](#imports)\n",
    "* [3. Convenience Functions](#func)\n",
    "* [4. Directory Set-Up](#dir_setup)\n",
    "* [5. Download the data](#data)\n",
    "* [6. Products Found In MAST](#mast_products)\n",
    "* [7. Re-processing the Data](#reprocessing)\n",
    "    * [7.1 Stage 1 Rerun & Products](#level1_rerun)\n",
    "    * [7.2 Stage 2 Rerun & Products](#level2_rerun)\n",
    "    * [7.3 Stage 3 Rerun & Products](#level3_rerun)\n",
    "        * [7.3.1 New Outlier Detection Algorithm](#outlier_detection_new)\n",
    "* [8. Extract 1-D Step: Modified Reference File](#extract_1d)\n",
    "* [Conclusion](#conclusion)\n",
    "\n",
    "## 1. Introduction <a id='intro'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "End-to-end calibration of JWST data is divided into 3 main stages of processing. This notebook explores how to run the JWST calibration pipeline stages 1-3 for NIRSpec IFU spectroscopic data.\n",
    "   <figure>\n",
    "       <img src='./nirspec_ifu_point_source/NGC_7319_AGN.png' title=\"Figure 1: NGC 7319 AGN\" alt=\"NGC 7319 AGN\" class=\"bg-primary\" align=\"right\" style=\"width: 400px; height: 350px;\"/>\n",
    "   </figure>\n",
    "\n",
    ">* **`STAGE 1`** ([calwebb_detector1](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_detector1.html#calwebb-detector1)): consists of detector-level corrections, performed on a group-by-group basis, followed by ramp fitting.\n",
    "    * **Input**: Raw exposure (`uncal.fits`) containing original data from all detector readouts (ncols x nrows x ngroups x nintegrations).\n",
    "    * **Output**: Corrected countrate (slope) image (`rate.fits`) \n",
    ">* **`STAGE 2`** ([calwebb_spec2](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_spec2.html#calwebb-spec2)): consists of additional instrument-level and observing mode corrections and calibrations.\n",
    "    * **Input**: A single corrected countrate (slope) image (`rate.fits`) or an ASN file listing multiple inputs.\n",
    "    * **Output**: A fully calibrated unrectified exposure (`cal.fits`). For NIRSpec IFU data, the `cube_build` step returns a 3-D IFU spectroscopic cube (`s3d.fits`). The `extract_1d` step  returns 1-D extracted spectral data products (`x1d.fits`)\n",
    ">* **`STAGE 3`** ([calwebb_spec3](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_spec3.html#calwebb-spec3)): consists of additional corrections (e.g. `outlier_detection`) and routines for combining calibrated data from multiple exposures (e.g. dither/nod pattern) into a single combined 2-D or 3-D spectral product and a combined 1-D spectrum. \n",
    "    * **Input**: An ASN file that lists multiple calibrated exposures (`cal.fits`).\n",
    "    * **Output**: For NIRSpec IFU data, a resampled and combined 3-D IFU cube (`s3d.fits`) and a 1-D extracted spectrum (`x1d.fits`)\n",
    "\n",
    "Here, we will focus on the mechanics of processing \"real\" example data (NGC 7319 AGN) from Proposal ID 2732, including how to use associations for multi-exposure combination and how to interact and work with data models for each product. Our objective is to examine the automated products found in MAST and compare them to products generated with the most up-to-date version of the JWST calibration pipeline.\n",
    "\n",
    "Most processing runs shown here use the default reference files from the Calibration Reference Data System (CRDS). Please note that pipeline software development is a continuous process, so results in some cases may be slightly different if using a subsequent version. There are also a few known issues with some of the pipeline steps in this build that we expect to be fixed in the near future. Until then, at various steps, we provide users with the current processing recommendations when running the pipeline manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcee7ed7",
   "metadata": {},
   "source": [
    "## 2. Import Library <a id='imports'></a>\n",
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5b543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "\n",
    "#--------------------------------------JWST Calibration Pipeline Imports-------------------------------------------\n",
    "\n",
    "import jwst\n",
    "import crds\n",
    "from jwst import datamodels\n",
    "from jwst.pipeline import Detector1Pipeline   #calwebb_detector1\n",
    "from jwst.pipeline import Spec2Pipeline       #calwebb_spec2\n",
    "from jwst.pipeline import Spec3Pipeline       #calwebb_spec3\n",
    "from jwst.extract_1d import Extract1dStep     #Extract1D Individual Step\n",
    "\n",
    "%env CRDS_CONTEXT  jwst_1146.pmap\n",
    "\n",
    "print(\"===============================================================================\")\n",
    "print(\"These are the installed pipeline and current operational CRDS context versions:\")\n",
    "print(\" \")\n",
    "print(\"JWST Calibration Pipeline Version={}\".format(jwst.__version__))\n",
    "print(\"Current Operational CRDS Context = {}\".format(crds.get_default_context()))\n",
    "print(\"===============================================================================\")\n",
    "\n",
    "#----------------------------------------------General Imports-----------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #Set to 'default' to turn warnings back on\n",
    "\n",
    "#--------------------------------------------File Operation Imports------------------------------------------------\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import asdf\n",
    "import json\n",
    "import shutil\n",
    "from IPython.display import JSON\n",
    "\n",
    "#--------------------------------------------Astropy/Astroquery Imports--------------------------------------------\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy import wcs\n",
    "from astropy.wcs import WCS\n",
    "from astropy.visualization import ImageNormalize, ManualInterval, LogStretch, LinearStretch, AsinhStretch, SqrtStretch\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "import astroquery\n",
    "from astroquery.mast import Mast\n",
    "from astroquery.mast import Observations\n",
    "\n",
    "#------------------------------------------------Plotting Imports--------------------------------------------------\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Circle\n",
    "import matplotlib.gridspec as grd\n",
    "from matplotlib import cm\n",
    "\n",
    "# Use this version for non-interactive plots (easier scrolling of the notebook)\n",
    "%matplotlib inline\n",
    "# Use this version (outside of Jupyter Lab) if you want interactive plots\n",
    "#%matplotlib notebook\n",
    "\n",
    "# These gymnastics are needed to make the sizes of the figures\n",
    "# be the same in both the inline and notebook versions\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches': None}\n",
    "mpl.rcParams['savefig.dpi'] = 80\n",
    "mpl.rcParams['figure.dpi'] = 80\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17178e7",
   "metadata": {},
   "source": [
    "## 3. Convenience Functions <a id='func'></a>\n",
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb4f2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(data_2d, vmin, vmax, xsize=15, ysize=15, title=None, zoom_in=None, aspect=1, scale='log', units='DN/s', cmap='jet'):\n",
    "    \"\"\"\n",
    "    Function to generate a 2-D, log-scaled image of the data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_2d : numpy.ndarray\n",
    "        2-D image to be displayed\n",
    "    vmin : float\n",
    "        Minimum signal value to use for scaling\n",
    "    vmax : float\n",
    "        Maximum signal value to use for scaling\n",
    "    xsize, ysize: int\n",
    "        Figure Size\n",
    "    title : str\n",
    "        String to use for the plot title\n",
    "    zoom_in: list \n",
    "        Zoomed in Region of interest [xstart,xstop,ystart,ystop]\n",
    "    aspect: int\n",
    "        Aspect ratio of the axes\n",
    "    scale : str\n",
    "        Specify scaling of the image. Can be 'log' or 'linear' or 'Asinh'\n",
    "    units : str\n",
    "        Units of the data. Used for the annotation in the color bar. Defualt is DN/s for countrate images\n",
    "    cmap: str\n",
    "        Color Map for plot\n",
    "    \"\"\"\n",
    "    #-----------------------------------------Scaling Information----------------------------------------\n",
    "    \n",
    "    if scale == 'log':\n",
    "        norm = ImageNormalize(data_2d, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                              stretch=LogStretch())\n",
    "    elif scale == 'linear':\n",
    "        norm = ImageNormalize(data_2d, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                              stretch=LinearStretch())\n",
    "    elif scale == 'Asinh':\n",
    "        norm = ImageNormalize(data_2d, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                              stretch=AsinhStretch())\n",
    "    \n",
    "    #--------------------------------------------Set Up Figure-------------------------------------------\n",
    "\n",
    "    fig = plt.figure(figsize=(xsize, ysize))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    \n",
    "    im = ax.imshow(data_2d, origin='lower', norm=norm, aspect=aspect, cmap=cmap)\n",
    "\n",
    "    fig.colorbar(im, label=units)\n",
    "    plt.xlabel('Pixel column')\n",
    "    plt.ylabel('Pixel row')\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "    #Zoom in on a portion of the image? \n",
    "    if zoom_in:\n",
    "        #inset axis \n",
    "        axins = ax.inset_axes([0.5, 0.6, 0.5, 0.3])\n",
    "        \n",
    "        axins.imshow(data_2d, origin=\"lower\", norm=norm, aspect=aspect, cmap=cmap)\n",
    "        \n",
    "        # subregion of the original image\n",
    "        axins.set_xlim(zoom_in[0], zoom_in[1])\n",
    "        axins.set_ylim(zoom_in[2], zoom_in[3])\n",
    "        axins.set_xticklabels([])\n",
    "        axins.set_yticklabels([])\n",
    "        ax.indicate_inset_zoom(axins, color=\"black\",edgecolor=\"black\", linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b1838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ifu_cubeslices(s3d_file_list, wavelength_slices=[], spaxel_locs=[], y_scale=None, cmap='jet', vmin_vmax = [[[0,15e1]]], save_figure=False, title=None, title_font = 30):\n",
    "    \"\"\"\n",
    "    Function to that takes a 3-D IFU data cube and generates: \n",
    "    \n",
    "    > 2-D cube slices based on wavelength (microns)\n",
    "    > Associated 1-D spectrum for a designated spaxel (spatial pixel) in the data cube\n",
    "    > Corresponding 3-D weight image giving the relative weights of the output spaxels\n",
    "    \n",
    "    Note: This function can accomidate multiple detectors plotted side-by-side. \n",
    "    The general format would follow [[detector 1 info], [detector 2 info]].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s3d_file_list: list of str\n",
    "        3-D IFU data cube fits file list \n",
    "    wavelength_slices: tuple\n",
    "        List of wavelength values (microns) at which to create 2-D slices. \n",
    "    spaxel_locs: tuple\n",
    "        List of spaxel locations in which to plot the associated 1-D spectrum. (One spaxel location per slice)\n",
    "    y_scale: tuple\n",
    "        Y-axis limits for the associated 1-D spectrum of the spaxel. Default is to use the ymin and ymax of the data. \n",
    "    cmap: str\n",
    "        Color Map \n",
    "    vmin_vmax: tuple\n",
    "        Minimum & Maximum signal value to use for scaling (e.g., [[[vmin,vmax],[vmin,vmax]], [[vmin,vmax], [vmin,vmax]]])\n",
    "    title: str\n",
    "        Figure Title. Default is None. \n",
    "    title_font:int\n",
    "        Title Font Size\n",
    "    save_figure: bool\n",
    "        Save figure?         \n",
    "    \"\"\"\n",
    "    \n",
    "    #---------------------------------------------- Set-up Figure -------------------------------------------------\n",
    "\n",
    "    #Plot Slices From the Cube\n",
    "    fig = plt.figure(figsize=(8*np.array(wavelength_slices).size,18))\n",
    "    gs = grd.GridSpec(3, np.array(wavelength_slices).size, height_ratios=[1]*3, width_ratios=[1]*np.array(wavelength_slices).size, hspace=0.4,wspace=0.7)\n",
    "\n",
    "    total_num_plots=3*np.array(wavelength_slices).size\n",
    "    \n",
    "    plot_count = 0\n",
    "    #---------------------------------------------Open Files------------------------------------------------------\n",
    "    \n",
    "    for s3d_file in s3d_file_list:\n",
    "        \n",
    "        root=s3d_file[:-9] #Root file name \n",
    "        print(s3d_file)\n",
    "        s3d = fits.open(s3d_file) #3-D IFU data cube fits file \n",
    "        x1d3 = datamodels.open(root+'_x1d.fits') #1-D Extracted Spectrum            \n",
    "    \n",
    "        #--------------------------------Wavelength & Surface Brightness/Flux Arrays------------------------------\n",
    "    \n",
    "        x1d3wave = x1d3.spec[0].spec_table.WAVELENGTH\n",
    "            \n",
    "        #--------------------------------------Data & Header Information------------------------------------------\n",
    "\n",
    "    \n",
    "        #SCI Extension: [Type:ImageHDU  Cards:92   Dimensions:(57, 61, 973)   Format:float32]\n",
    "        cube = s3d[1].data #Science data\n",
    "        wcs = WCS(s3d[1].header) #World Coordinate System (WCS) Transformation keywords \n",
    "        wmap = s3d[4].data #3-D weight image giving the relative weights of the output spaxels.\n",
    "        cdelt1 = s3d[1].header['CDELT1']*3600. #Axis 1 coordinate increment at reference point \n",
    "        cdelt2 = s3d[1].header['CDELT2']*3600. #Axis 2 coordinate increment at reference point \n",
    "        cdelt3 = s3d[1].header['CDELT3'] #Axis 3 coordinate increment at reference point \n",
    "        crval3 = s3d[1].header['CRVAL3'] #third axis value at the reference pixel  \n",
    "\n",
    "        #Wavelength range of the grating/filter combination\n",
    "        wavstart = s3d[1].header['WAVSTART']\n",
    "        wavend = s3d[1].header['WAVEND']\n",
    "        s3d.close()\n",
    "    \n",
    "        #---------------------------------------------------Plots-------------------------------------------------\n",
    "        \n",
    "        cmap_custom = cm.colors.LinearSegmentedColormap.from_list(\"\", [\"darkred\",\"darkturquoise\",\"blue\"])\n",
    "        colors = cmap_custom(np.linspace(0, 1, np.array(wavelength_slices).size))\n",
    "\n",
    "        #To Account for if NRS1 & NRS2 are both being plotted Side-by-side\n",
    "        if len(wavelength_slices) != 1:\n",
    "            if 'nrs1' in s3d_file:\n",
    "                wavelengths = wavelength_slices[0]\n",
    "                spaxel_loc = spaxel_locs[0]\n",
    "                vmin_vmax_vals = vmin_vmax[0]\n",
    "                \n",
    "                if y_scale:\n",
    "                    y_scales = y_scale[0]\n",
    "\n",
    "            elif 'nrs2' in s3d_file:\n",
    "                wavelengths = wavelength_slices[1]\n",
    "                spaxel_loc = spaxel_locs[1]\n",
    "                vmin_vmax_vals = vmin_vmax[1]\n",
    "                if y_scale:\n",
    "                    y_scales = y_scale[1]\n",
    "\n",
    "        else:\n",
    "            wavelengths = wavelength_slices[0]\n",
    "            spaxel_loc = spaxel_locs[0]\n",
    "            vmin_vmax_vals = vmin_vmax[0]\n",
    "            if y_scale:\n",
    "                    y_scales = y_scale[0]\n",
    "\n",
    "            \n",
    "        #Loop through each wavelength slices\n",
    "        for i, wave_slice in enumerate(wavelengths):\n",
    "\n",
    "            if float(wavstart)<=wave_slice*10**-6<=float(wavend):\n",
    "                \n",
    "                #--------------------------------------------2-D Cube Slice------------------------------------------------\n",
    "            \n",
    "                #Min & Max Image Values & Scaling\n",
    "                if len(vmin_vmax_vals) != 1:\n",
    "                    vmax_val = vmin_vmax_vals[i][1]\n",
    "                    vmin_val = vmin_vmax_vals[i][0]\n",
    "                else:\n",
    "                    vmax_val = vmin_vmax_vals[0][1]\n",
    "                    vmin_val = vmin_vmax_vals[0][0]\n",
    "\n",
    "                slicewave = wave_slice\n",
    "                nslice = int((slicewave - crval3)/cdelt3) #the slice of the cube we want to plot\n",
    "                ax1 = plt.subplot(gs[0+plot_count], projection=wcs, slices=('x', 'y', nslice)) #set up the subplot space\n",
    "\n",
    "                slice_mean = np.nanmean(cube[(nslice-2):(nslice+2), :, :], axis=0) #Mean of the slice looking in the range (nslice-2):(nslice+2)\n",
    "                slice_norm=ImageNormalize(slice_mean, vmin=vmin_val, vmax=vmax_val, stretch=AsinhStretch()) #normalize &stretch \n",
    "                slice_image= ax1.imshow(slice_mean, norm=slice_norm, origin='lower', aspect='auto',cmap=cmap) #plot slice\n",
    "\n",
    "                cb_image = fig.colorbar(slice_image, fraction=0.046, pad=0.04)\n",
    "                cb_image.set_label('MJy/sr', labelpad=-1, fontsize = 22)\n",
    "                cb_image.ax.tick_params(labelsize=20)\n",
    "                cb_image.ax.yaxis.get_offset_text().set_fontsize(20)\n",
    "                \n",
    "                ax1.set_xlabel('RA', fontsize =22)\n",
    "                ax1.set_ylabel('DEC', labelpad=-1, fontsize=22)\n",
    "                ax1.set_title('Detector {} \\n Grating/Filter: {}/{} \\n {} microns'.format(s3d[0].header['DETECTOR'],s3d[0].header['GRATING'], s3d[0].header['FILTER'], str(slicewave)), fontsize =25)\n",
    "                ax1.tick_params(axis='both', which='major', labelsize=20)\n",
    "                ax1.coords[0].set_ticklabel(rotation=13, ha='right', pad=24)\n",
    "\n",
    "               \n",
    "                #------------------------------------------Spaxel 1-D Spectrum---------------------------------------------\n",
    "                \n",
    "                #Zoom in on a Spaxel: Spectrum\n",
    "                loc = [spaxel_loc[i][0],spaxel_loc[i][1]]\n",
    "                x1d3flux_loc = cube[:, loc[1], loc[0]]\n",
    "                ax2 = plt.subplot(gs[int(total_num_plots/3)+plot_count])\n",
    "\n",
    "                #Spaxel Box Highlight \n",
    "                spaxel_rect = plt.Rectangle((loc[0]-.5, loc[1]-.5), 1,1, fill=False, color='black', linewidth=2)\n",
    "                ax1.add_patch(spaxel_rect)\n",
    "                \n",
    "                ax2.plot(x1d3wave, x1d3flux_loc, linewidth=1, color=colors[i])\n",
    "                ax2.grid(linewidth=2)\n",
    "                ax2.set_xlabel('$\\u03BB [\\u03BC$m]',fontsize=22)\n",
    "                ax2.set_ylabel(\"Surface Brightness \\n (MJy/sr)\",fontsize=22)\n",
    "                ax2.set_title('Spaxel at (x, y)='+repr(loc), fontsize=25)\n",
    "                ax2.tick_params(axis='both', which='major', labelsize=20)\n",
    "                ax2.yaxis.get_offset_text().set_fontsize(15)\n",
    "                \n",
    "                #Scale Information\n",
    "                if y_scale:\n",
    "                    ymin, ymax = y_scales[i][0], y_scales[i][1]\n",
    "                else:\n",
    "                    ymin, ymax = ax2.set_ylim()\n",
    "                \n",
    "                ax2.set_ylim(ymin, ymax)\n",
    "                ax2.xaxis.set_tick_params(labelsize=20)\n",
    "                ax2.yaxis.set_tick_params(labelsize=20)\n",
    "                ax2.set_aspect(0.5/ax2.get_data_ratio())\n",
    "                \n",
    "                #-----------------------------------------------Weight Map-------------------------------------------------\n",
    "                \n",
    "                #Corresponding Weight Map (wmap) for Cube Slice\n",
    "                ax3 = plt.subplot(gs[int(total_num_plots)-np.array(wavelength_slices).size+plot_count], projection=wcs, slices=('x', 'y', nslice)) #set up the subplot space\n",
    "                \n",
    "                slice_mean_wmap = np.nanmean(wmap[(nslice-2):(nslice+2), :, :], axis=0) #Mean of the wmap slice looking in the range (nslice-2):(nslice+2)\n",
    "                slice_norm_wmap=ImageNormalize(slice_mean_wmap, stretch=AsinhStretch()) #normalize &stretch\n",
    "                slice_wmap = ax3.imshow(slice_mean_wmap, norm=slice_norm_wmap, origin='lower',aspect='auto', cmap=cmap) #plot slice\n",
    "\n",
    "                cb_wmap = fig.colorbar(slice_wmap, fraction=0.046, pad=0.04)\n",
    "                cb_wmap.set_label('Weight', labelpad=-1, fontsize = 22)\n",
    "                cb_wmap.ax.tick_params(labelsize=20)\n",
    "                cb_wmap.ax.yaxis.get_offset_text().set_fontsize(20)\n",
    "                \n",
    "                ax3.set_xlabel('RA', fontsize=22)\n",
    "                ax3.set_ylabel('DEC', labelpad=-1, fontsize=22)\n",
    "                #ax3.grid(color='gray', ls='solid')\n",
    "                ax3.set_title(str(slicewave)+' microns: Weight Map', fontsize=25)\n",
    "                ax3.tick_params(axis='both', which='major', labelsize=20)\n",
    "                ax3.coords[0].set_ticklabel(rotation=13, ha='right', pad=24)\n",
    "\n",
    "                plot_count += 1\n",
    "                    \n",
    "            else:\n",
    "                None\n",
    "    \n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=title_font)\n",
    "        plt.subplots_adjust(top=0.8) \n",
    "\n",
    "    if save_figure == True:\n",
    "        fig.savefig(root+\".png\",dpi=24, bbox_inches=\"tight\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347a9a54",
   "metadata": {},
   "source": [
    "## 4. Directory Set-Up and defining some base parameters <a id='dir_setup'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Warning:</b> Note: For this JWebbinar we pre-computed **all but one** products for [calwebb_detector1](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_detector1.html#calwebb-detector1) and [calwebb_spec2](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipelin/calwebb_spec2.html#calwebb-spec2) to save time. Those will be copied into the output folder. If `jwebbinar = False` **ALL** products are created, which can take a significant amount of time. For [calwebb_spec3](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_spec3.html#calwebb-spec3) this is not possible since all products are needed to create the final datacube.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c870b4c4-bc8d-48d8-8f19-ec3d54d1f6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "jwebbinar = True\n",
    "\n",
    "if not jwebbinar:\n",
    "    print('')\n",
    "    print('JWebbinar is deactivated: ALL OBSERATIONS WILL BE REDUCED!!!')\n",
    "\n",
    "basedir = os.path.join(os.getcwd(),'nirspec_ifu_point_source')\n",
    "output_dir = os.path.join(basedir,'run_folder')\n",
    "mast_products_dir = os.path.join(basedir,'mast_products')\n",
    "pre_computed_run_dir = os.path.join(basedir,'pre_computed_run')\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "if not os.path.exists(mast_products_dir):\n",
    "    os.makedirs(mast_products_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ad59a3-6297-4c6b-b379-ea79701985d9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Warning:</b> Note: To allow everyone to get the same results we fixed the used PMAP to `jwst_1146.pmap`. To save download time we also provide the CRDS cache and to not overwrite any of your systems settings we saved the cache in  \"../crds_cache\". The following commands\n",
    "`os.environ['CRDS_PATH'] = \"../crds_cache\"`, and\n",
    "`os.environ['CRDS_CONTEXT'] = 'jwst_1146.pmap'`\n",
    "overwrite the system settings for **THIS NOTEBOOK ONLY**. To run the notebook with the latest reference files these two lines should be commented out\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564b30de-7c75-4568-846a-74b3dfba2cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('')\n",
    "print(\"Setting up the CRDS-cache and pmap\")\n",
    "\n",
    "'''\n",
    "The following should be uncommented to used the already cached files to save \n",
    "download time. Set if different to default set in bash_rc file. The CRDS_CONTEXT\n",
    "ensures that everybody uses the same pmap for this exercise.\n",
    "This MUST commented out to ensure that the latest reference files in CRDS\n",
    "will be used\n",
    "'''\n",
    "os.environ['CRDS_PATH'] = \"../crds_cache\" \n",
    "os.environ['CRDS_CONTEXT'] = 'jwst_1146.pmap' ### \n",
    "\n",
    "print('CRDS-cache is set to:', os.getenv('CRDS_PATH'))\n",
    "print(\"Current activated CRDS Context = {}\".format(os.getenv('CRDS_CONTEXT')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad6ed15",
   "metadata": {},
   "source": [
    "## 5. Download the Data <a id='data'></a>\n",
    "\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "| Target: NGC 7319 AGN |       |   |   |   |\n",
    "|:-----------:|:-------:|---|---|---|\n",
    "| Proposal ID | 02732 |   |   |   |\n",
    "| [GRATING/FILTER](https://jwst-docs.stsci.edu/jwst-near-infrared-spectrograph/nirspec-observing-modes/nirspec-ifu-spectroscopy)   | PRISM/CLEAR | \u03bb: 0.6\u20135.3 \u03bcm (a low resolution, R ~ 100) |   |   |\n",
    "|   DURATION  | 160.478 [s] | Total duration of one exposure |   |   |   |\n",
    "|   READPATT  | NRSIRS2RAPID | Readout Pattern |   |   |   |\n",
    "|   PATTTYPE  | CYCLING | Primary dither pattern type |   |   |\n",
    "|   PATTSIZE  | LARGE | Primary dither pattern size (1.0\" extent) |   |   |\n",
    "|   NUMDTHPT  | 8 | Total number of points in pattern |   |   | \n",
    "|   SRCTYAPT  | UNKNOWN | Source Type selected in APT |   |   | \n",
    "\n",
    "MAST products are saved to a folder called `mast_products` within the designated output directory defined earlier in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30347914",
   "metadata": {},
   "source": [
    "## 6. Products Found In MAST <a id='mast_products'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "Here we show and plot the products as they are provided in MAST. This will also demonstrate why in most science cases reprocessing the data is needed.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Tip:</b> To optimally use your science data some parameters need to be uniquly tweaked specifically for your observations. No parameter setting wil be sufficient for **all** data.\n",
    "    \n",
    "</div> \n",
    "\n",
    "> In [APT](https://jwst-docs.stsci.edu/jwst-astronomers-proposal-tool-overview), the observer has three options for source type (`SRCTYAPT` keyword): `POINT`, `EXTENDED`, or `UNKNOWN`. In stage 2, the `srctype` step will first check if the `SRCTYAPT` keyword is present and populated. If `SRCTYAPT` is not present or is set to `UNKNOWN`, the step determines a suitable value based on the observing mode, command line input, and other characteristics of the exposure. If the exposure is identified as a background exposure (`BKGDTARG = True`), the exposures default to a source type of `EXTENDED`. Exposures that are part of a nodded pattern (identified by keyword `PATTYPE`), which are assumed to only be used with point-like targets, default to a source type of `POINT`. [More Info ...](https://jwst-pipeline.readthedocs.io/en/latest/jwst/srctype/description.html#single-source-observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217a5889",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    \n",
    "<b>Warning:</b> Please be aware that many exposures are suffering from snowballs (see NRS2 in the above plot) which are caused by large cosmic ray events (https://jwst-docs.stsci.edu/data-artifacts-and-features/snowballs-and-shower-artifacts). To mitigate this ``expand_large_events`` needs to be set to `True` in the jump_detection algorithm of the `callwebb_detector1` step. This is currently deactivate by default hence a rerun is needed. This is especially important for deep exposures with long integration times. A rough estimate is 1 snowball per detector per 20s.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d54809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just a check to see what verison of the pipeline and what pmap was used\n",
    "x1d3_mast = fits.open(glob.glob(os.path.join(mast_products_dir, '*_x1d.fits'))[0])\n",
    "\n",
    "print(\"Products found in MAST used JWST calibration pipeline version: {} and {}\".format(x1d3_mast[0].header['CAL_VER'],x1d3_mast[0].header['CRDS_CTX']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842a8837",
   "metadata": {},
   "source": [
    "## 7. Re-processing the Data <a id='reprocessing'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> Many parameter we show in the below examples are set to the default ones. This should only provide an overview over some of the most common parameters that can be adjusted to get the best out of the science **but** often they require a few iterations to find the best possible parameter set for a given observation. \n",
    "</div>\n",
    "\n",
    "Due to lengthy processing times, only one exposure of will be re-processed in this demonstration if `jwebbinar=True`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126569cf",
   "metadata": {},
   "source": [
    "### 7.1 Stage 1 Rerun & Products  <a id='level1_rerun'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> The most notebale difference to the MAST products will be the snowball rejection, which are large cosmic ray event. This can be acomplished setting `\"expand_large_events\": True` in the `jump` step. Setting the `\"expand_factor\": 3` seems to be a good value for NIRSpec observations to cover most snowballs. A manual check of the rate files is recommended.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e624ce66-c24d-4206-9dc1-784efbcd2d7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Stage 1 Processing \n",
    "\n",
    "if jwebbinar == True:\n",
    "    filelist = sorted(glob.glob(os.path.join(mast_products_dir, '*02101*00001_nrs1_uncal.fits')))\n",
    "else:\n",
    "    filelist = sorted(glob.glob(os.path.join(mast_products_dir, '*nrs1_uncal.fits')))\n",
    "\n",
    "for uncal_file in filelist: \n",
    "    print(\"Applying Stage 1 Corrections & Calibrations to: \"+ os.path.basename(uncal_file))\n",
    "\n",
    "    result = Detector1Pipeline.call(uncal_file,\n",
    "                                    save_results = True,\n",
    "                                    output_dir = output_dir,\n",
    "                                    steps = {\"jump\":{\"skip\": False,\n",
    "                                                     \"expand_large_events\": True, ### this activates the snowball rejection\n",
    "                                                     \"maximum_cores\": \"all\", ### you can limit the number of used CPUs here\n",
    "                                                     \"expand_factor\": 3, ### the non default value 3 seems to be better for NIRSpec to mask the full region\n",
    "                                                     # \"rejection_threshold\": 4.0,\n",
    "                                                     # \"four_group_rejection_threshold\": 5.0,\n",
    "                                                     # \"flag_4_neighbors\": True,\n",
    "                                                     # \"max_jump_to_flag_neighbors\": 200,\n",
    "                                                     # \"min_jump_to_flag_neighbors\": 10,\n",
    "                                                     # \"edge_size\": 4,\n",
    "                                                     # \"sat_expand\": 0.,\n",
    "                                                     # \"sat_required_snowball\": False,\n",
    "                                                     # \"min_jump_area\": 2.,\n",
    "                                                     \"save_results\": True,\n",
    "                                                     },\n",
    "                                             \"refpix\": {\"skip\": False,\n",
    "                                                        \"odd_even_columns\": True,\n",
    "                                                        # \"use_side_ref_pixels\": True,\n",
    "                                                        # \"side_smoothing_lenght\": 11,\n",
    "                                                        # \"side_gain\": 1.0,\n",
    "                                                        \"ovr_corr_mitigation_ftr\": 3.0\n",
    "                                                       },\n",
    "                                             \"ramp_fit\": {\"skip\": False,\n",
    "                                                         \"suppress_one_group\": False,\n",
    "                                                         \"maximum_cores\": 'all'\n",
    "                                                         },\n",
    "                                             \"saturation\": {\"skip\": False,\n",
    "                                                           \"n_pix_grow_sat\": 1\n",
    "                                                           },\n",
    "                                             \n",
    "                                             })\n",
    "\n",
    "\n",
    "if jwebbinar == True:\n",
    "\n",
    "    pre_computed_filelist = sorted(glob.glob(os.path.join(pre_computed_run_dir, '*_rate*.fits')))\n",
    "    for file in pre_computed_filelist:\n",
    "        output = os.path.join(output_dir, os.path.basename(file))\n",
    "        print(file, ' => ', output)\n",
    "        shutil.copy(file, output)\n",
    "\n",
    "print(\"Hurray ...  this step has been completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da176563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 1 slope products -- level 2a images\n",
    "\n",
    "#Plot 1 dither position\n",
    "\n",
    "file = glob.glob(os.path.join(output_dir, '*00001_nrs1_rate.fits'))[0]\n",
    "print(\"rate file: \", file)\n",
    "\n",
    "ratefile_open = datamodels.open(file)\n",
    "ratefile_sci = ratefile_open.data #get the pixel data (the SCI extension of the fits file)\n",
    "ratefile_dq = ratefile_open.dq #data quality map data (DQ extension)\n",
    "             \n",
    "show_image(ratefile_sci, 0,10, units='DN/s',zoom_in=[500,550, 1250,1300], ysize=20, xsize=20,\n",
    "           title='Countrate Image \\n Detector: {} \\n 8-Cycle Dither Position Index: {} \\n GRATING/FILTER: {}/{}'.format(ratefile_open.meta.instrument.detector,\n",
    "                                                                                                                        ratefile_open.meta.dither.position_number, \n",
    "                                                                                                                        ratefile_open.meta.instrument.grating,\n",
    "                                                                                                                        ratefile_open.meta.instrument.filter)) #rate files have units of DN/s\n",
    " \n",
    "show_image(ratefile_dq, 0, 10, units='Bit Value', scale='linear',zoom_in=[500,550, 1250,1300], ysize=20, xsize=20,\n",
    "           title='Data Quality Map \\n Detector: {} \\n 8-Cycle Dither Position Index: {} \\n GRATING/FILTER: {}/{}'.format(ratefile_open.meta.instrument.detector,\n",
    "                                                                                                                        ratefile_open.meta.dither.position_number, \n",
    "                                                                                                                        ratefile_open.meta.instrument.grating,\n",
    "                                                                                                                        ratefile_open.meta.instrument.filter)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84c9f5b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> Compared to the [countrate (slope) products found in MAST](#level1_mast), fewer pixels are flagged as Do Not Use when using the most up-to-date pmap in CRDS (at the time jwst_1106.pmap). With the latest pmap, one can observe low-level vertical banding in the central regions of the detector, and the \"picture frame\" towards the edge of both detectors, where there is less correlated read noise a lot easier. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf378c9d",
   "metadata": {},
   "source": [
    "### 7.2 Stage 2  <a id='stage2'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "This IFU data set focuses on an AGN target, which has a compact region at the center of its galaxy that can be considered a point source. To treat this IFU data as a point source, one must change the `SRCTYPE=POINT` header keyword in the `cal.fits` files before running stages 2 and 3 of the calibration pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8268fa96-01fc-496b-a794-48a000b8b657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treating the IFU data as a point source \n",
    "#To run as a point source, alter the rate file header keywrod SRCTYAPT=POINT & rerun stage 2 of the pipeline \n",
    "#Loop through the copied rate files and update the source type keyword\n",
    "for rate_file in sorted(glob.glob(os.path.join(output_dir, '*nrs1_rate.fits'))):\n",
    "    rate_file_hdu = fits.open(rate_file, 'update')\n",
    "    \n",
    "    #Change source type to point \n",
    "    rate_file_hdu[0].header['SRCTYAPT'] = 'POINT'\n",
    "    rate_file_hdu.close()\n",
    "\n",
    "    print(\"Changed file: \", rate_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd042310-1379-484b-a0dd-65bbf207c628",
   "metadata": {},
   "source": [
    "During stage 2 of the pipeline, the countrate (slope) image products from stage 1, which have units of DN/s, are converted to units of surface brightness (MJy/sr) for both extended and point sources (as of DMS build 9.3/CAL_VER 1.10.2). For IFU point sources, the `extract_1d` step is controlled by a different set of parameters in the EXTRACT1D reference file: \n",
    "\n",
    "> For a point source, the spectrum is extracted using circular aperture photometry, **optionally (automatically) including background subtraction** using a circular annulus. [More Info ...](https://jwst-pipeline.readthedocs.io/en/latest/jwst/extract_1d/description.html)\n",
    "\n",
    "When processing the IFU as a point source, the `extract_1d` step will automatically apply background subtraction unless otherwise told not to. The `extract_1d` step will also use the default circular extraction apertures for the source and background, an example of how to modify the EXTRACT1D reference file can be found at the end of this notebook.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Warning:</b> Note there has been a bug in the `cube_build` step that caused the point source flux to not be conserved when using different spatial sampling. A fix has been implemented as of release DMS build 9.3/CAL_VER 1.10.2. In order to enable the correct functionality, the units of the cal.fits files and cubes will now be in surface brightness, and only the 1-D extracted spectra will be in units of Jy.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796a6aab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Stage 2 Processing \n",
    "\n",
    "\n",
    "if jwebbinar == True:\n",
    "    filelist = sorted(glob.glob(os.path.join(output_dir, '*02101*00001*nrs1*rate.fits')))\n",
    "else:\n",
    "    filelist = sorted(glob.glob(os.path.join(output_dir, '*nrs1_rate.fits')))\n",
    "\n",
    "#Process each rate file seperately \n",
    "for rate_file in filelist:\n",
    "        \n",
    "    print(\"Applying Stage 2 Calibrations & Corrections to: \"+ os.path.basename(rate_file))\n",
    "    \n",
    "    result = Spec2Pipeline.call(rate_file,\n",
    "                                save_results = True,\n",
    "                                output_dir = output_dir,\n",
    "                                steps = {\"msa_flagging\":{\"skip\": False   ### Masks those pixels that are affected by stuck open MSA shutters\n",
    "                                                         },\n",
    "                                         \"imprint_subtract\":{\"skip\": True    ### This step is needed if LEAKCAL observations were provided\"\n",
    "                                                    },\n",
    "                                         \"bkg_subtract\":{\"skip\": True,    ### This step is needed if background observations were provided\n",
    "                                                       \"sigma\": 3,\n",
    "                                                       \"maxiters\": None,\n",
    "                                                       \"save_combined_background\": False\n",
    "                                                       },\n",
    "                                          \"flat_field\":{\"skip\": False,\n",
    "                                                        \"save_interpolated_flat\": False   ### A flag to indicate whether to save to a file the NIRSpec flat field that was constructed on-the-fly by the step.\n",
    "                                                        },\n",
    "                                         \"pathloss\":{\"skip\": False\n",
    "                                                     },\n",
    "                                         \"photom\":{\"skip\": False   ### photmetric calibration \n",
    "                                                   },\n",
    "                                         \"cube_build\":{\"skip\": False    ### builds the 3D cube for each exposure. This is not necessary in the Spec2 step unless you want to inspect the individual cubes before combining them\n",
    "                                                       },\n",
    "                                         \"extract_1d\":{\"skip\": False   ### Extracts the 1D spectra for each exposure . Is not necessary in the Spec2 step unless you want to inspect the individual extracted spectra\n",
    "                                                       }\n",
    "                                         }\n",
    "                                )\n",
    "\n",
    "if jwebbinar == True:\n",
    "\n",
    "    pre_computed_filelist = sorted(glob.glob(os.path.join(pre_computed_run_dir, '*_cal*.fits')))\n",
    "    for file in pre_computed_filelist:\n",
    "        output = os.path.join(output_dir, os.path.basename(file))\n",
    "        print(file, ' => ', output)\n",
    "        shutil.copy(file, output)\n",
    "\n",
    "print(\"Hurray ...  this step has been completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ea3199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 2 Products -- Calibrated 3-D data cubes for three different wavelengths\n",
    "\n",
    "#Plotting the 4th (out of 8) dither position for both NRS1 and NRS2\n",
    "s3d_stage2_list = sorted(glob.glob(os.path.join(output_dir, '*00001_nrs?_s3d.fits')))\n",
    "\n",
    "title_stage2_rerun='NGC 7319 AGN \\n Level 2 IFU Product: 3-D Cube Slices vs. Corresponding 3-D Weighted Map'\n",
    "\n",
    "#Characteristics of the plot \n",
    "nrs1_wavelengths = [1.4,3.3,4.5] #Wavelength slices (microns) to take from the 3-D data cube\n",
    "nrs1_spaxel_locs = [[30,29],[28,39],[14,25]] #Spaxel locations for associated 1-D spectrum (one spaxel plotted per slice)\n",
    "\n",
    "#Plot using the convience function defined above\n",
    "show_ifu_cubeslices(s3d_stage2_list, wavelength_slices=[nrs1_wavelengths], \n",
    "                    spaxel_locs=[nrs1_spaxel_locs], title=title_stage2_rerun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ac83a4",
   "metadata": {},
   "source": [
    "### 7.3 Stage 3 Rerun & Products  <a id='level3_rerun'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "***Level 3 ASN File***\n",
    "\n",
    "> Observations that use a nod-type/dither patterns, their exposures are related. [Association files (ASN)](https://jwst-pipeline.readthedocs.io/en/stable/jwst/associations/overview.html) describe how multiple exposures are related to one another and how they depend on one another. Processing an ASN file permits exposures to be calibrated, archived, retrieved, and reprocessed as a set rather than individual objects. IFU exposures taken with a dither pattern are not used for pixel-to-pixel background subtraction by the calibration pipeline (unlike exposures taken with a nod pattern).\n",
    "\n",
    "Therefore, all calibration files (`cal.fits`) in our spec3 ASN file should be labeled as science exposures (`exptype: science`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ea47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy ASN file from MAST\n",
    "\n",
    "asnfiles_mast = glob.glob(os.path.join(mast_products_dir, '*_spec3_*_asn.json')) #ASN file found in MAST\n",
    "print(mast_products_dir)\n",
    "print(asnfiles_mast)\n",
    "\n",
    "for file in asnfiles_mast:\n",
    "\n",
    "    asnfile_dest = os.path.join(output_dir, os.path.basename(file))\n",
    "    \n",
    "    print(file, \" => \" , asnfile_dest)\n",
    "    shutil.copy(file, asnfile_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aebc610-ab4d-4321-a323-1b5461cfed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Show the ASN file for which we will run CalSpec3\n",
    "\n",
    "asnfile = glob.glob(os.path.join(output_dir, '*_spec3_00001_asn.json'))[0]\n",
    "\n",
    "with open(asnfile, 'r') as f_obj:\n",
    "    asnfile_data = json.load(f_obj)\n",
    "        \n",
    "JSON(asnfile_data, expanded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3669d28",
   "metadata": {},
   "source": [
    "#### 7.3.1 New Outlier Detection Algorithm<a id='outlier_detection_new'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "The new outlier detection algorithm for IFU data (as of DMS build B9.3rc1/CAL_VER 1.11.0) implements the basic outlier detection algorithm -- searches for pixels that are consistent outliers in the calibrated images created by the `calwebb_spec2` pipeline. The algorithm generally operates as follows:\n",
    "\n",
    "> * Identifies outlier pixels by comparing them with their neighboring pixels in the spatial direction across a set of input files within an association.\n",
    "> * For NIRSpec data, it calculates differences between pixels located above and below each science pixel.\n",
    "> * The pixel differences for every input model in the association are computed and stored in a stack of pixel differences.\n",
    "> * For each pixel, the algorithm determines the minimum difference across this stack and then performs normalization. This normalization process employs a local median derived from the difference array, with the size of the median determined by the kernel size.\n",
    "> * A pixel is flagged as an outlier if this normalized minimum difference is greater than the input threshold percentage. \n",
    "> * Pixels that are found to be outliers are flaged in in the DQ array.\n",
    "> * [More Info ...](https://jwst-pipeline.readthedocs.io/en/latest/jwst/outlier_detection/outlier_detection_ifu.html#outlier-detection-ifu)\n",
    "\n",
    "\n",
    "**[The outlier_detection step for IFU data has the following optional arguments that control the behavior of the processing](https://github.com/spacetelescope/jwst/blob/master/docs/jwst/outlier_detection/arguments.rst):**\n",
    "\n",
    "* `kernel_size` (string, default='7 7'): The size of the kernel to use to normalize the pixel differences. The kernel size must only contain odd values.\n",
    "* `threshold_percent` (float, default=99.8): The threshold (in percent) of the normalized minimum pixel difference used to identify bad pixels. Pixels with a normalized minimum pixel difference above this percentage are flagged as a outlier.\n",
    "* `save_intermediate_results` (boolean, default=False): Specifies whether or not to save any intermediate products created during step processing.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> The default `kernel_size` of **7 7** was developed for MIRI/MRS and tests showed that **3 3** works the better option for NIRSpec.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a12db-7809-4f0d-8e9d-b8d81131e63c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Rerun stage 3\n",
    "\n",
    "result = Spec3Pipeline.call(asnfile,\n",
    "                            save_results = True,\n",
    "                            output_dir = output_dir,\n",
    "                            steps = {\"outlier_detection\":{\"skip\": False,\n",
    "                                                          \"save_results\": True,\n",
    "                                                          \"kernel_size\": '3 3',    # the default of 7 7 was developed for MIRI/MRS and from testing 3 3 is the better option for NIRSpec\n",
    "                                                          \"threshold_percent\": 99.8\n",
    "                                                         },\n",
    "                                    \"cube_build\":{\"skip\": False,\n",
    "                                                  # \"gratings\": \"ALL\",      ### \u201cALL\u201d is used, then all the gratings in the association are used.\n",
    "                                                  # \"output_type\": \"multi\", ### combines data into a single \u201cuber\u201d IFU cube \"\n",
    "                                                  \"weighting\": 'emsm'    ### From testing emsm seems to be working better than drizzle for NIRSpec\n",
    "                                                 },\n",
    "                                    \"extract_1d\":{\"skip\": False,\n",
    "                                                  \"subtract_background\": False, ### Do not automatically apply background subtraction until we modify the extraction region\n",
    "                                                  # \"center_xy\": \"27, 28\",  ### A list of two integer values giving the desired x/y location for the center of the circular extraction aperture,\n",
    "                                                  \"ifu_autocen\": True  ### Switch to select whether or not to enable auto-centroiding of the extraction aperture for IFU point sources\n",
    "                                                 }\n",
    "                                    })\n",
    "print(\"Hurray ... this step has been completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c93f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 3 Products -- Combined Calibrated 3-D data cubes at various wavelentgths\n",
    "\n",
    "s3d_stage3_list = sorted(glob.glob(os.path.join(output_dir, '*nirspec*_s3d.fits')))\n",
    "title_stage3_rerun='NGC 7319 AGN \\n Level 3 IFU Product: 3-D Cube Slices vs. Corresponding 3-D Weighted Map'\n",
    "\n",
    "#Characteristics of the plot \n",
    "nrs1_wavelengths = [1.4,3.3,4.5] #Wavelength slices (microns) to take from the 3-D data cube\n",
    "nrs1_spaxel_locs = [[30,29],[28,39],[14,25]] #Spaxel locations for associated 1-D spectrum (one spaxel plotted per slice)\n",
    "vmin_vmax_point = [[0,150],[0,150],[0,150]]\n",
    "\n",
    "#Plot using the convience function defined above\n",
    "show_ifu_cubeslices(s3d_stage3_list, wavelength_slices=[nrs1_wavelengths], spaxel_locs=[nrs1_spaxel_locs],vmin_vmax=[vmin_vmax_point], title=title_stage3_rerun, title_font=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322f8a59",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> In comparison to the [weight maps for the 3-D data cube products found in MAST](#level3_mast), the implementation of the new outlier detection algorithm leads to a notable decrease in data rejection.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c96634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 3 Products -- Combined Extracted 1-D Spectrum \n",
    "\n",
    "#Combined 1-D extracted spectrum\n",
    "x1d3_rerun_point = datamodels.open(glob.glob(os.path.join(output_dir, '*nirspec_prism-clear_x1d.fits'))[0])\n",
    "s3d = fits.open(glob.glob(os.path.join(output_dir, '*nirspec_prism-clear_s3d.fits'))[0])\n",
    "x1d = fits.open(glob.glob(os.path.join(output_dir, '*nirspec_prism-clear_x1d.fits'))[0])\n",
    "\n",
    "### Obtaining the reference file from teh CRDS cache\n",
    "# extract1d_ref_og = glob.glob(os.path.join(os.getenv('CRDS_PATH'),'references', 'jwst', 'nirspec', '*extract1d*.asdf'))[0]\n",
    "extract1d_ref_og = Spec3Pipeline().get_reference_file(glob.glob(os.path.join(output_dir, '*nirspec_prism-clear_s3d.fits'))[0], 'extract1d')\n",
    "\n",
    "\n",
    "#Wavelength & Surface Brightness Arrays\n",
    "x1d3wave_rerun_point = x1d3_rerun_point.spec[0].spec_table.WAVELENGTH\n",
    "x1d3flux_rerun_point = x1d3_rerun_point.spec[0].spec_table.FLUX\n",
    "\n",
    "#Plot the Extracted 1-D Spectrum\n",
    "fig = plt.figure(figsize=(25,9))\n",
    "gs = grd.GridSpec(1, 8, hspace=0.4,wspace=0.7)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 0:5])\n",
    "ax2 = fig.add_subplot(gs[0, 5:])\n",
    "\n",
    "ax1.plot(x1d3wave_rerun_point,x1d3flux_rerun_point, linewidth =2)\n",
    "\n",
    "#Where wavelength slice was taken above\n",
    "ax1.vlines(1.4, 0., 400., 'black', 'dotted', label='1.4 microns')\n",
    "ax1.vlines(3.3, 0., 400., 'red', 'dotted', label='3.3 microns')\n",
    "ax1.vlines(4.5, 0., 400., 'green', 'dotted', label='4.5 microns')\n",
    "\n",
    "ax1.set_xlabel('$\\lambda [\\mu$m]', fontsize =20)\n",
    "ax1.set_ylabel('Flux (Jy)', fontsize =20)\n",
    "ax1.set_title(\"NGC 7319 AGN \\n Level 3 IFU Product in MAST: Extracted 1-D Spectrum\", fontsize=20)\n",
    "ax1.set_ylim(0, 10**-1.6)\n",
    "ax1.ticklabel_format(axis='y', style='sci', scilimits=(0,-2))\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "#Extraction Region Preview\n",
    "#Open Combined 3-D Cube FITS file\n",
    "s3d = fits.open(glob.glob(os.path.join(output_dir, '*nirspec_prism-clear_s3d.fits'))[0])\n",
    "cube = s3d[1].data #Science data\n",
    "\n",
    "#plot the full IFU cube\n",
    "slice_mean = np.nanmean(cube[400:500, :, :], axis=0) #Mean of the slice looking in the range (nslice2-2):(nslice2+2)\n",
    "slice_norm=ImageNormalize(slice_mean, vmin=0, vmax=150, stretch=AsinhStretch()) #normalize &stretch\n",
    "slice_full = ax2.imshow(slice_mean, norm=slice_norm, origin='lower', cmap='jet') #plot slice\n",
    "\n",
    "#colorbar\n",
    "cb_image = plt.colorbar(slice_full, fraction=0.046, pad=0.04)\n",
    "cb_image.set_label('MJy/sr', labelpad=-1, fontsize = 10)\n",
    "cb_image.ax.tick_params(labelsize=10)\n",
    "cb_image.ax.yaxis.get_offset_text().set_fontsize(10)\n",
    "\n",
    "\n",
    "with asdf.open(extract1d_ref_og, mode='r') as ff:\n",
    "    print(\"===========================================================\")\n",
    "    print(\"          Radius [arcsec]:\", ff.tree['data']['radius'][0])\n",
    "    print(\"Inner background [arcsec]:\", ff.tree['data']['inner_bkg'][0])\n",
    "    print(\"Outer background [arcsec]:\", ff.tree['data']['outer_bkg'][0])\n",
    "    print(\"===========================================================\")\n",
    "    \n",
    "    radius = Circle((x1d[1].header['EXTR_X'],x1d[1].header['EXTR_Y']),ff.tree['data']['radius'][0] * 10, fill=False, label='Radius')\n",
    "    inner_bkg = Circle((x1d[1].header['EXTR_X'],x1d[1].header['EXTR_Y']),ff.tree['data']['inner_bkg'][0] * 10, color='b',fill=False, label='Inner Background Radius')\n",
    "    outer_bkg= Circle((x1d[1].header['EXTR_X'],x1d[1].header['EXTR_Y']),ff.tree['data']['outer_bkg'][0] * 10, color='r',fill=False, label='Outer Background Radius')\n",
    "\n",
    "\n",
    "ax2.add_patch(radius)\n",
    "ax2.add_patch(inner_bkg)\n",
    "ax2.add_patch(outer_bkg)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.set_xlabel('X (pixels)', fontsize=10)\n",
    "ax2.set_ylabel('Y (pixels)', fontsize=10)\n",
    "ax2.grid(color='white', ls='solid')\n",
    "ax2.set_title('Full IFU Cube: \\n Extraction Region Preview', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6599ead0-6eb4-4450-b13c-2f66f377851d",
   "metadata": {},
   "source": [
    "## 8. Extract 1-D Step: Modified Reference File<a id='extract_1d'></a>\n",
    "<hr style=\"border:1px solid gray\">  \n",
    "\n",
    "As a point source, the `extract_1d` step is controlled by a different set of parameters in the EXTRACT1D reference file:\n",
    "\n",
    ">[Extraction for 3-D IFU Data:](https://jwst-pipeline.readthedocs.io/en/latest/jwst/extract_1d/description.html)\n",
    ">\n",
    "> For point source data the extraction aperture is centered at the RA/DEC target location indicated by the header. If the target location is undefined in the header, then the extraction region is the center of the IFU cube.\n",
    ">\n",
    ">For point sources a circular extraction aperture is used, along with an optional circular annulus for background extraction and subtraction. The size of the extraction region and the background annulus size varies with wavelength. The extraction related vectors are found in the asdf EXTRACT1D reference file. For each element in the wavelength vector there are three size components: `radius`, `inner_bkg`, and `outer_bkg`. The radius vector sets the extraction size; while `inner_bkg` and `outer_bkg` specify the limits of an annular background aperture. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "The `ifu_autocen` parameter provides a new method to center on the point sources even if the header information is not perfect due to inaccruacries caused by, e.g., FGS.\n",
    "Nevertheless, I you woudl like to adjust the extraction position, we show how to modify the EXTRACT1D reference file to obtain better results. \n",
    "\n",
    "</div>\n",
    "\n",
    "To do so we first need to obtain the correct `extract1d` reference file from CRDS and copy it into the run folder and change the the `radius` and `inner_bkg` and `outer_bkg` parameters.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Warning:</b> The default extraction aperture radius has been set to match what was used to derive the flux calibration. If you want to use a different aperture size, you will need to compute and apply a custom aperture correction to ensure the correct flux, as we have not yet updated the aperture correction reference files.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e87608a-82e3-4cde-95b8-fc0d088a309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab the defualt extract1d reference file and copy to working directory\n",
    "extract1d_ref_og = Spec3Pipeline().get_reference_file(glob.glob(os.path.join(output_dir, '*nirspec_prism-clear_s3d.fits'))[0], 'extract1d')\n",
    "\n",
    "if not os.path.exists(os.path.join(output_dir, os.path.basename(extract1d_ref_og))):\n",
    "    shutil.copy(extract1d_ref_og, os.path.join(output_dir, os.path.basename(extract1d_ref_og)))\n",
    "\n",
    "#Make Changes to the ASDF file and Write to a new file\n",
    "\n",
    "with asdf.open(os.path.join(output_dir, os.path.basename(extract1d_ref_og)), mode='rw') as ff:\n",
    "\n",
    "    ff.tree['data']['radius'] = np.full((2048,), 0.9, dtype='float32')\n",
    "    ff.tree['data']['inner_bkg'] = np.full((2048,), 1.0, dtype='float32')\n",
    "    ff.tree['data']['outer_bkg'] = np.full((2048,), 1.5, dtype='float32')\n",
    "    ff.write_to(os.path.join(output_dir, 'new_' + os.path.basename(extract1d_ref_og)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c9ad41-8ca6-4b94-a5f5-f800e0840acc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Now we re-extract the 1D spectrum but just running the `Extract1dStep` and overriding the reference file.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8714203e-4ea9-43df-ae40-dac33fb8cadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Extract1dStep.call(glob.glob(os.path.join(output_dir, '*nirspec_prism-clear_s3d.fits'))[0], \n",
    "                       save_results = True,\n",
    "                       output_dir = output_dir,\n",
    "                       override_extract1d = os.path.join(output_dir,  'new_' + os.path.basename(extract1d_ref_og)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e491187-78c1-474e-a571-85f948a75a97",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Finally we plot the newly extracted 1D spectrum while also showing the originally extracted one.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e7fb9-181f-4b0e-9e65-579eb153fd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 3 Products -- Combined Extracted 1-D Spectrum \n",
    "\n",
    "#Combined 1-D extracted spectrum\n",
    "x1d3_shifted_extract_point = datamodels.open(glob.glob(os.path.join(output_dir, '*nirspec_prism-clear_extract1dstep.fits'))[0])\n",
    "s3d = fits.open(glob.glob(os.path.join(output_dir, '*nirspec_prism-clear_s3d.fits'))[0])\n",
    "x1d = fits.open(glob.glob(os.path.join(output_dir, '*nirspec_prism-clear_extract1dstep.fits'))[0])\n",
    "\n",
    "#Wavelength & Surface Brightness Arrays\n",
    "x1d3wave_shifted_extract_point = x1d3_shifted_extract_point.spec[0].spec_table.WAVELENGTH\n",
    "x1d3flux_shifted_extract_point = x1d3_shifted_extract_point.spec[0].spec_table.FLUX\n",
    "\n",
    "#Plot the Extracted 1-D Spectrum\n",
    "fig = plt.figure(figsize=(25,9))\n",
    "gs = grd.GridSpec(1, 8, hspace=0.4,wspace=0.7)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 0:5])\n",
    "ax2 = fig.add_subplot(gs[0, 5:])\n",
    "\n",
    "ax1.plot(x1d3wave_shifted_extract_point,x1d3flux_shifted_extract_point, linewidth =2, label=\"shifted extraction\")\n",
    "ax1.plot(x1d3wave_rerun_point, x1d3flux_rerun_point, linewidth =2, color='grey', label=\"original extraction\")\n",
    "\n",
    "\n",
    "#Where wavelength slice was taken above\n",
    "ax1.vlines(1.4, 0., 400., 'black', 'dotted', label='1.4 microns')\n",
    "ax1.vlines(3.3, 0., 400., 'red', 'dotted', label='3.3 microns')\n",
    "ax1.vlines(4.5, 0., 400., 'green', 'dotted', label='4.5 microns')\n",
    "\n",
    "ax1.set_xlabel('$\\lambda [\\mu$m]', fontsize =20)\n",
    "ax1.set_ylabel('Flux (Jy)', fontsize =20)\n",
    "ax1.set_title(\"NGC 7319 AGN \\n Level 3 IFU Product in MAST: Extracted 1-D Spectrum\", fontsize=20)\n",
    "ax1.set_ylim(0, 10**-1.6)\n",
    "ax1.ticklabel_format(axis='y', style='sci', scilimits=(0,-2))\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "#Extraction Region Preview\n",
    "#Open Combined 3-D Cube FITS file\n",
    "s3d = fits.open(glob.glob(os.path.join(output_dir, '*nirspec_prism-clear_s3d.fits'))[0])\n",
    "cube = s3d[1].data #Science data\n",
    "\n",
    "#plot the full IFU cube\n",
    "slice_mean = np.nanmean(cube[400:500, :, :], axis=0) #Mean of the slice looking in the range (nslice2-2):(nslice2+2)\n",
    "slice_norm=ImageNormalize(slice_mean, vmin=0, vmax=150, stretch=AsinhStretch()) #normalize &stretch\n",
    "slice_full = ax2.imshow(slice_mean, norm=slice_norm, origin='lower', cmap='jet') #plot slice\n",
    "\n",
    "#colorbar\n",
    "cb_image = plt.colorbar(slice_full, fraction=0.046, pad=0.04)\n",
    "cb_image.set_label('MJy/sr', labelpad=-1, fontsize = 10)\n",
    "cb_image.ax.tick_params(labelsize=10)\n",
    "cb_image.ax.yaxis.get_offset_text().set_fontsize(10)\n",
    "\n",
    "\n",
    "with asdf.open(os.path.join(output_dir, 'new_' + os.path.basename(extract1d_ref_og)), mode='r') as ff:\n",
    "    print(\"          Radius [arcsec]:\", ff.tree['data']['radius'][0])\n",
    "    print(\"Inner background [arcsec]:\", ff.tree['data']['inner_bkg'][0])\n",
    "    print(\"Outer background [arcsec]:\", ff.tree['data']['outer_bkg'][0])\n",
    "    \n",
    "    radius = Circle((x1d[1].header['EXTR_X'],x1d[1].header['EXTR_Y']),ff.tree['data']['radius'][0] * 10, fill=False, label='Radius')\n",
    "    inner_bkg = Circle((x1d[1].header['EXTR_X'],x1d[1].header['EXTR_Y']),ff.tree['data']['inner_bkg'][0] * 10, color='b',fill=False, label='Inner Background Radius')\n",
    "    outer_bkg= Circle((x1d[1].header['EXTR_X'],x1d[1].header['EXTR_Y']),ff.tree['data']['outer_bkg'][0] * 10, color='r',fill=False, label='Outer Background Radius')\n",
    "\n",
    "\n",
    "ax2.add_patch(radius)\n",
    "ax2.add_patch(inner_bkg)\n",
    "ax2.add_patch(outer_bkg)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.set_xlabel('X (pixels)', fontsize=10)\n",
    "ax2.set_ylabel('Y (pixels)', fontsize=10)\n",
    "ax2.grid(color='white', ls='solid')\n",
    "ax2.set_title('Full IFU Cube: \\n Extraction Region Preview', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10a83b7-9146-4b06-85ab-748f03bea734",
   "metadata": {},
   "source": [
    "## Conclusion <a id='conclusion'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "In conclusion, this notebook walks users through processing real data (NGC 7319 AGN) from Proposal ID 2732 and comparing automated products in MAST with those generated using the latest version of the JWST calibration pipeline and latest CRDS context. For optimal results, users are strongly encouraged to reprocess their own data using the most recent pipeline version and CRDS context, taking advantage of bug fixes and algorithm improvements (i.e., the new IFU outlier detection algorithm). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass",
   "language": "python",
   "name": "masterclass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}