{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "095a295c",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src='https://github.com/spacetelescope/jwst-pipeline-notebooks/raw/main/_static/stsci_header.png' alt=\"stsci_logo\" width=\"900px\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0393e357-9d9d-4516-b28d-4d335fad33a0",
   "metadata": {},
   "source": [
    "# MIRI Imaging Pipeline Notebook\n",
    "\n",
    "**Authors**: M. Cracraft<br>\n",
    "**Last Updated**: January 16, 2025<br>\n",
    "**Pipeline Version**: 1.17.1 (Build 11.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a74b566-3d8c-4985-a4f3-d654a6d39371",
   "metadata": {},
   "source": [
    "**Purpose**:<br>\n",
    "This notebook provides a framework for processing generic Mid-Infrared Instrument \n",
    "(MIRI) Imaging data through all\n",
    "three James Webb Space Telescope (JWST) pipeline stages.  Data is assumed\n",
    "to be located in one observation folder according to paths set up below.\n",
    "It should not be necessary to edit any cells other than in the\n",
    "[Configuration](#1.-Configuration) section unless modifying the standard\n",
    "pipeline processing options.\n",
    "\n",
    "**Data**:<br>\n",
    "This example is set up to use an example dataset is from\n",
    "[Program ID](https://www.stsci.edu/jwst/science-execution/program-information)\n",
    "1040 (PI: O. Detre, Co-I: A. Noriega-Crespo) which is an external flat commissioning program.\n",
    "The MIRI imaging dataset uses a 5-step dither pattern. Example input data to use will be\n",
    "downloaded automatically unless disabled (i.e., to use local files instead).\n",
    "\n",
    "**JWST pipeline version and CRDS context**:<br>\n",
    "This notebook was written for the calibration pipeline version given above and uses the context associated with this version of the JWST Calibration Pipeline. Information about this an other contexts can be found in the JWST Calibration Reference Data System (CRDS) [server]((https://jwst-crds.stsci.edu/)). If you use different pipeline\n",
    "versions, please refer to the table [here](https://jwst-crds.stsci.edu/display_build_contexts/) to determine what context to use. To learn more about the differences for the pipeline, read the relevant [documentation](https://jwst-docs.stsci.edu/jwst-science-calibration-pipeline/jwst-operations-pipeline-build-information)<br>\n",
    "\n",
    "**Updates**:<br>\n",
    "This notebook is regularly updated as improvements are made to the\n",
    "pipeline. Find the most up to date version of this notebook at:\n",
    "https://github.com/spacetelescope/jwst-pipeline-notebooks/\n",
    "\n",
    "**Recent Changes**:<br>\n",
    "September 25, 2024: original notebook released<br>\n",
    "November 22, 2024: Updates to workflow when skipping pipeline modules<br>\n",
    "January 16, 2025: Add handling for dedicated backgrounds, update to jwst 1.17.1<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecaabc8",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231ccda6",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Configuration](#1.-Configuration)\n",
    "2. [Package Imports](#2.-Package-Imports)\n",
    "3. [Demo Mode Setup (ignore if not using demo data)](#3.-Demo-Mode-Setup-(ignore-if-not-using-demo-data))\n",
    "4. [Directory Setup](#4.-Directory-Setup)\n",
    "3. [Detector 1 Pipeline](#5.-Detector1-Pipeline)\n",
    "4. [Image2 Pipeline](#6.-Image2-Pipeline)\n",
    "5. [Image3 Pipeline](#7.-Image3-Pipeline)\n",
    "6. [Visualize the data](#8.-Visualize-the-drizzle-combined-image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5f7ab9",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bd07d7",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "------------------\n",
    "Set basic configuration for running notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026a649d-a0d2-4e3f-ab6d-cf8c26e6ce1d",
   "metadata": {},
   "source": [
    "### Install dependencies and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b6c02c-a7cd-4999-96a0-87ce398d7e9a",
   "metadata": {},
   "source": [
    "To make sure that the pipeline version is compatabile with the steps\n",
    "discussed below and the required dependencies and packages are installed,\n",
    "you can create a fresh conda environment and install the provided\n",
    "`requirements.txt` file before starting this notebook: <br>\n",
    "```\n",
    "conda create -n miri_imaging_pipeline python=3.11\n",
    "conda activate miri_imaging_pipeline\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Set the basic parameters to use with this notebook. These will affect\n",
    "what data is used, where data is located (if already in disk), and\n",
    "pipeline modules run in this data. The list of parameters are:\n",
    "\n",
    "* demo_mode\n",
    "* directories with data\n",
    "* pipeline modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ea414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic import necessary for configuration\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bb14e6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Note that <code>demo_mode</code> must be set appropriately below.\n",
    "</div>\n",
    "\n",
    "Set <code>demo_mode = True </code> to run in demonstration mode. In this\n",
    "mode this notebook will download example data from the Barbara A.\n",
    "Mikulski Archive for Space Telescopes\n",
    "([MAST](https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html))\n",
    "and process it through the pipeline. This will all happen in a local\n",
    "directory unless modified in\n",
    "[Section 3](#3.-Demo-Mode-Setup-(ignore-if-not-using-demo-data)) below.<br>\n",
    "\n",
    "Set <code>demo_mode = False</code> if you want to process your own data\n",
    "that has already been downloaded and provide the location of the data.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323f87d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for demo_mode and processing steps.\n",
    "\n",
    "# -----------------------------Demo Mode---------------------------------\n",
    "demo_mode = True\n",
    "\n",
    "if demo_mode:\n",
    "    print('Running in demonstration mode using online example data!')\n",
    "\n",
    "# --------------------------User Mode Directories------------------------\n",
    "# If demo_mode = False, look for user data in these paths\n",
    "if not demo_mode:\n",
    "    # Set directory paths for processing specific data; these will need\n",
    "    # to be changed to your local directory setup (below are given as\n",
    "    # examples)\n",
    "    user_home_dir = os.path.expanduser('~')\n",
    "\n",
    "    # Point to where science observation data are\n",
    "    # Assumes uncalibrated data in sci_dir/uncal/ and results in stage1,\n",
    "    # stage2, stage3 directories\n",
    "    sci_dir = os.path.join(user_home_dir, 'FlightData/APT1040/data/Obs001/')\n",
    "    \n",
    "    # Point to where background observation data are\n",
    "    # Assumes uncalibrated data in bg_dir/uncal/ and results in stage1 directory\n",
    "    #bg_dir = os.path.join(user_home_dir, 'FlightData/APT1714/data/Obs02/')\n",
    "    bg_dir = '' # If no background observation, use an empty string\n",
    "\n",
    "# --------------------------Set Processing Steps--------------------------\n",
    "# Individual pipeline stages can be turned on/off here.  Note that a later\n",
    "# stage won't be able to run unless data products have already been\n",
    "# produced from the prior stage.\n",
    "\n",
    "# Science processing\n",
    "dodet1 = True  # calwebb_detector1\n",
    "doimage2 = True  # calwebb_image2\n",
    "doimage3 = True  # calwebb_image3\n",
    "doviz = True # Visualize calwebb_image3 results\n",
    "\n",
    "# Background processing (if present)\n",
    "dodet1bg = True  # calwebb_detector1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1070079a",
   "metadata": {},
   "source": [
    "### Set CRDS context and server\n",
    "Before importing <code>CRDS</code> and <code>JWST</code> modules, we need\n",
    "to configure our environment. This includes defining a CRDS cache\n",
    "directory in which to keep the reference files that will be used by the\n",
    "calibration pipeline.<br>\n",
    "\n",
    "If the root directory for the local CRDS cache directory has not been set\n",
    "already, it will be set to create one in the home directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf7070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------Set CRDS context and paths----------------------\n",
    "# Each version of the calibration pipeline is associated with a specific CRDS\n",
    "# context file. The pipeline will select the appropriate context file behind\n",
    "# the scenes while running. However, if you wish to override the default context\n",
    "# file and run the pipeline with a different context, you can set that using\n",
    "# the CRDS_CONTEXT environment variable. Here we show how this is done,\n",
    "# although we leave the line commented out in order to use the default context.\n",
    "# If you wish to specify a different context, uncomment the line below.\n",
    "#%env CRDS_CONTEXT jwst_1293.pmap\n",
    "\n",
    "# Check whether the local CRDS cache directory has been set.\n",
    "# If not, set it to the user home directory\n",
    "if (os.getenv('CRDS_PATH') is None):\n",
    "    os.environ['CRDS_PATH'] = os.path.join(os.path.expanduser('~'), 'crds')\n",
    "\n",
    "# Check whether the CRDS server URL has been set.  If not, set it.\n",
    "if (os.getenv('CRDS_SERVER_URL') is None):\n",
    "    os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu'\n",
    "\n",
    "# Echo CRDS path in use\n",
    "print(f\"CRDS local filepath: {os.environ['CRDS_PATH']}\")\n",
    "print(f\"CRDS file server: {os.environ['CRDS_SERVER_URL']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be716575",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575588c8",
   "metadata": {},
   "source": [
    "## 2. Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4415f6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the entire available screen width for this notebook\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9f7f54-ff98-428b-9fa9-b39c50210c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic system utilities for interacting with files\n",
    "# ----------------------General Imports------------------------------------\n",
    "import glob\n",
    "import time\n",
    "from pathlib import Path\n",
    "#import urllib.request\n",
    "\n",
    "# Numpy for doing calculations\n",
    "import numpy as np\n",
    "\n",
    "# To display full ouptut of cell, not just the last result\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# --------------------Astroquery Imports------------------------------\n",
    "# ASCII files, and downloading demo files\n",
    "from astroquery.mast import Observations\n",
    "\n",
    "# ----------------Matplotlib for visualizing images-------------------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------Astropy routines for visualizing detected sources----------\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "\n",
    "# ----------------------JWST calibration pipeline------------------------\n",
    "import jwst\n",
    "import crds\n",
    "\n",
    "from jwst.pipeline import Detector1Pipeline\n",
    "from jwst.pipeline import Image2Pipeline\n",
    "from jwst.pipeline import Image3Pipeline\n",
    "\n",
    "# JWST pipeline utilities\n",
    "from jwst import datamodels\n",
    "from jwst.datamodels import ImageModel\n",
    "from jwst.associations import asn_from_list as afl  # Tools for creating association files\n",
    "from jwst.associations.lib.rules_level2_base import DMSLevel2bBase  # Definition of a Lvl2 association file\n",
    "from jwst.associations.lib.rules_level3_base import DMS_Level3_Base  # Definition of a Lvl3 association file\n",
    "\n",
    "# Echo pipeline version and CRDS context in use\n",
    "print(f\"JWST Calibration Pipeline Version: {jwst.__version__}\")\n",
    "print(f\"Using CRDS Context: {crds.get_context_name('jwst')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5844d476-f8b3-4c24-9c79-091d6016314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a timer to keep track of runtime\n",
    "time0 = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae973c7",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef8050f",
   "metadata": {},
   "source": [
    "## 3. Demo Mode Setup (ignore if not using demo data)\n",
    "------------------\n",
    "If running in demonstration mode, set up the program information to\n",
    "retrieve the uncalibrated data automatically from MAST using\n",
    "[astroquery](https://astroquery.readthedocs.io/en/latest/mast/mast.html).\n",
    "MAST allows for flexibility of searching by the proposal ID and the\n",
    "observation ID instead of just filenames.<br>\n",
    "\n",
    "For illustrative purposes, we focus on data taken through the MIRI\n",
    "[F770W filter](https://jwst-docs.stsci.edu/jwst-mid-infrared-instrument/miri-observing-modes/miri-imaging#MIRIImaging-MIRIFiltersImagingfilters)\n",
    "and start with uncalibrated data products. The files are named\n",
    "`jw01040001005_03103_0000n_miri_uncal.fits`, where *n* refers to the\n",
    "dither step number which ranges from 1 - 5.\n",
    "\n",
    "More information about the JWST file naming conventions can be found at:\n",
    "https://jwst-pipeline.readthedocs.io/en/latest/jwst/data_products/file_naming.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d595f1e-2590-4f01-bb92-13bb43a22b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the program information and paths for demo program\n",
    "if demo_mode:\n",
    "    print('Running in demonstration mode and will download example data from MAST!')\n",
    "    program = '01040'\n",
    "    sci_observtn = \"001\"\n",
    "    visit = \"005\"\n",
    "    data_dir = os.path.join('.', 'mir_im_demo_data')\n",
    "    download_dir = data_dir\n",
    "    sci_dir = os.path.join(data_dir, 'Obs' + sci_observtn)\n",
    "    uncal_dir = os.path.join(sci_dir, 'uncal')\n",
    "    bg_dir = ''\n",
    "\n",
    "    # Ensure filepaths for input data exist\n",
    "    if not os.path.exists(uncal_dir):\n",
    "        os.makedirs(uncal_dir)\n",
    "\n",
    "    # Create directory if it does not exist\n",
    "    if not os.path.isdir(data_dir):\n",
    "        os.mkdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6674a8b8",
   "metadata": {},
   "source": [
    "Identify list of science (SCI) uncalibrated files associated with visits.\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "Selects only filter <i>f770w</i> data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b22375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a list of observation IDs for the specified demo program\n",
    "if demo_mode:\n",
    "    # Science data\n",
    "    sci_obs_id_table = Observations.query_criteria(instrument_name=[\"MIRI/IMAGE\"],\n",
    "                                                   provenance_name=[\"CALJWST\"],  # Executed observations\n",
    "                                                   filters=['F770W'],  # Data for Specific Filter\n",
    "                                                   obs_id=['jw' + program + '-o' + sci_observtn + '*']\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a666350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the list of visits into a list of uncalibrated data files\n",
    "if demo_mode:\n",
    "    # Define types of files to select\n",
    "    file_dict = {'uncal': {'product_type': 'SCIENCE',\n",
    "                           'productSubGroupDescription': 'UNCAL',\n",
    "                           'calib_level': [1]}}\n",
    "\n",
    "    # Science files\n",
    "    sci_files_to_download = []\n",
    "\n",
    "    # Loop over visits identifying uncalibrated files that are associated\n",
    "    # with them\n",
    "    for exposure in (sci_obs_id_table):\n",
    "        products = Observations.get_product_list(exposure)\n",
    "        for filetype, query_dict in file_dict.items():\n",
    "            filtered_products = Observations.filter_products(products, productType=query_dict['product_type'],\n",
    "                                                             productSubGroupDescription=query_dict['productSubGroupDescription'],\n",
    "                                                             calib_level=query_dict['calib_level'])\n",
    "            sci_files_to_download.extend(filtered_products['dataURI'])\n",
    "\n",
    "    # Download only the files in a single visit\n",
    "    sci_files_to_download = [match for match in sci_files_to_download if ('jw' + program + sci_observtn + visit) in match]\n",
    "    sci_files_to_download = sorted(sci_files_to_download)\n",
    "    print(f\"Science files selected for downloading: {len(sci_files_to_download)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36a54be",
   "metadata": {},
   "source": [
    "Download all the uncal files and place them into the appropriate\n",
    "directories.<br>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "Warning: If this notebook is halted during this step the downloaded file\n",
    "may be incomplete, and cause crashes later on!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764fa682",
   "metadata": {},
   "outputs": [],
   "source": [
    "if demo_mode:\n",
    "    for filename in sci_files_to_download:\n",
    "        sci_manifest = Observations.download_file(filename,\n",
    "                                                  local_path=os.path.join(uncal_dir, Path(filename).name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46eeea8",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c51254-6295-4f98-bc25-d07300e0d8f4",
   "metadata": {},
   "source": [
    "## 4. Directory Setup\n",
    "---------------------\n",
    "Set up detailed paths to input/output stages here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffbedc3-fbe3-4c56-ad18-85b5d0c7d880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output subdirectories to keep science data products organized\n",
    "uncal_dir = os.path.join(sci_dir, 'uncal')  # Uncalibrated pipeline inputs should be here\n",
    "det1_dir = os.path.join(sci_dir, 'stage1')  # calwebb_detector1 pipeline outputs will go here\n",
    "image2_dir = os.path.join(sci_dir, 'stage2')  # calwebb_spec2 pipeline outputs will go here\n",
    "image3_dir = os.path.join(sci_dir, 'stage3')  # calwebb_spec3 pipeline outputs will go here\n",
    "\n",
    "# Output subdirectories to keep background data products organized\n",
    "uncal_bgdir = os.path.join(bg_dir, 'uncal')  # Uncalibrated pipeline inputs should be here\n",
    "det1_bgdir = os.path.join(bg_dir, 'stage1')  # calwebb_detector1 pipeline outputs will go here\n",
    "\n",
    "# We need to check that the desired output directories exist, and if not\n",
    "# create them\n",
    "if not os.path.exists(det1_dir):\n",
    "    os.makedirs(det1_dir)\n",
    "if not os.path.exists(image2_dir):\n",
    "    os.makedirs(image2_dir)\n",
    "if not os.path.exists(image3_dir):\n",
    "    os.makedirs(image3_dir)\n",
    "    \n",
    "if ((bg_dir != '') & (not os.path.exists(det1_bgdir))):\n",
    "    os.makedirs(det1_bgdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f843ff7f-58b6-4294-bfaa-606c29abc524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the time benchmark\n",
    "time1 = time.perf_counter()\n",
    "print(f\"Runtime so far: {time1 - time0:0.0f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c14d80",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267e28e0-a63f-4790-b8a0-3ad4bff5a167",
   "metadata": {},
   "source": [
    "## 5. Detector1 Pipeline\n",
    "Run the datasets through the\n",
    "[Detector1](https://jwst-docs.stsci.edu/jwst-science-calibration-pipeline-overview/stages-of-jwst-data-processing/calwebb_detector1)\n",
    "stage of the pipeline to apply detector level calibrations and create a\n",
    "countrate data product where slopes are fitted to the integration ramps.\n",
    "These `*_rate.fits` products are 2D (nrows x ncols), averaged over all\n",
    "integrations. 3D countrate data products (`*_rateints.fits`) are also\n",
    "created (nintegrations x nrows x ncols) which have the fitted ramp slopes\n",
    "for each integration.<br>\n",
    "\n",
    "By default, all steps in the `Detector1` stage of the pipeline are run for\n",
    "MIRI except: the `group_scale`, `ipc` and the `gain_scale` steps.<br>\n",
    "\n",
    "MIRI performs a few pipeline steps in calwebb_detector1 that are not performed for other instruments.\n",
    "The [emicorr](https://jwst-pipeline.readthedocs.io/en/latest/jwst/emicorr/index.html#emicorr-step) step corrects\n",
    "for known noise patterns in MIRI data. For certain subarrays, these noise patterns are clearly imprinted on\n",
    "the data in the `rate.fits` files.<br>\n",
    "\n",
    "The [firstframe](https://jwst-pipeline.readthedocs.io/en/latest/jwst/firstframe/index.html#firstframe-step) step flags the first frame in each integration as bad, if the number of groups per integration is greater than 3.<br>\n",
    "\n",
    "The [lastframe](https://jwst-pipeline.readthedocs.io/en/latest/jwst/lastframe/index.html#lastframe-step) step\n",
    "flags the last frame in each integration as bad, if the number of groups per integration is greater than 2.<br>\n",
    "\n",
    "The [reset](https://jwst-pipeline.readthedocs.io/en/latest/jwst/reset/index.html#reset-step) correction step\n",
    "corrects for the reset anomaly effect. This effect is caused by the non-ideal behavior of the field effect\n",
    "transistor (FET) upon resetting in the dark causing the initial frames in an integration to be offset\n",
    "from their expected values.<br>\n",
    "\n",
    "The [rscd](https://jwst-pipeline.readthedocs.io/en/latest/jwst/rscd/index.html#rscd-step) step reads a reference\n",
    "file for each data file and determines how many frames at the start of a ramp should be flagged as bad. There are a\n",
    "number of nonlinearities at the start of MIRI ramps, and the flagging allows the more linear portion of the ramp to\n",
    "be used for jump detection and ramp fitting, without using the initial, non-linear portion of the ramp. The number\n",
    "of groups flagged depend on filter and subarray.<br>\n",
    "\n",
    "As of CRDS context `jwst_1201.pmap` and later, the\n",
    "[jump](https://jwst-pipeline.readthedocs.io/en/latest/api/jwst.jump.JumpStep.html) step\n",
    "of the `DETECTOR1` stage of the pipeline will remove residuals associated\n",
    "with [showers](https://jwst-docs.stsci.edu/known-issues-with-jwst-data/shower-and-snowball-artifacts)\n",
    "for the MIRI imaging mode, but only for data with filter F1500W and shorter. The default parameters for this correction,\n",
    "where `find_showers` set to `True` turns on the shower\n",
    "removal algorithm, are specified in the `pars-jumpstep` parameter\n",
    "reference files. Users may wish to alter parameters to optimize removal of\n",
    "shower residuals. Available parameters are discussed in the\n",
    "[Detection and Flagging of Showers and Snowballs in JWST Technical Report (Regan 2023)](https://www.stsci.edu/files/live/sites/www/files/home/jwst/documentation/technical-documents/_documents/JWST-STScI-008545.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3592ee58-b424-4bd6-973b-88fd081b81d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a dictionary to define how the Detector1 pipeline should be configured\n",
    "\n",
    "# Boilerplate dictionary setup\n",
    "det1dict = {}\n",
    "det1dict['group_scale'], det1dict['dq_init'], det1dict['emicorr'] = {}, {}, {}\n",
    "det1dict['saturation'], det1dict['firstframe'], det1dict['lastframe'] = {}, {}, {}\n",
    "det1dict['reset'], det1dict['linearity'], det1dict['rscd'] = {}, {}, {}\n",
    "det1dict['dark_current'], det1dict['refpix'], det1dict['jump'] = {}, {}, {}\n",
    "det1dict['ramp_fit'], det1dict['gain_scale'] = {}, {}\n",
    "\n",
    "# Overrides for whether or not certain steps should be skipped\n",
    "# skipping the refpix step\n",
    "#det1dict['refpix']['skip'] = True\n",
    "#det1dict['jump']['find_showers'] = False # Turn off detection of cosmic ray showers\n",
    "\n",
    "# Overrides for various reference files\n",
    "# Files should be in the base local directory or provide full path\n",
    "#det1dict['dq_init']['override_mask'] = 'myfile.fits'  # Bad pixel mask\n",
    "#det1dict['saturation']['override_saturation'] = 'myfile.fits'  # Saturation\n",
    "#det1dict['reset']['override_reset'] = 'myfile.fits'  # Reset\n",
    "#det1dict['linearity']['override_linearity'] = 'myfile.fits'  # Linearity\n",
    "#det1dict['rscd']['override_rscd'] = 'myfile.fits'  # RSCD\n",
    "#det1dict['dark_current']['override_dark'] = 'myfile.fits'  # Dark current subtraction\n",
    "#det1dict['jump']['override_gain'] = 'myfile.fits'  # Gain used by jump step\n",
    "#det1dict['ramp_fit']['override_gain'] = 'myfile.fits'  # Gain used by ramp fitting step\n",
    "#det1dict['jump']['override_readnoise'] = 'myfile.fits'  # Read noise used by jump step\n",
    "#det1dict['ramp_fit']['override_readnoise'] = 'myfile.fits'  # Read noise used by ramp fitting step\n",
    "\n",
    "# Turn on multi-core processing (off by default).  Choose what fraction of cores to use (quarter, half, or all)\n",
    "det1dict['jump']['maximum_cores'] = 'half'\n",
    "\n",
    "# Alter parameters to optimize removal of shower residuals (example)\n",
    "#det1dict['jump']['after_jump_flag_dn1'] = X  # A floating point value in units of DN\n",
    "#det1dict['jump']['after_jump_flag_time1'] = x.x # A floating point value in units of seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc8001b",
   "metadata": {},
   "source": [
    "### Calibrating Science Files\n",
    "Look for input science files and run calwebb_detector1 pipeline using the call method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453bba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncal_files = sorted(glob.glob(os.path.join(uncal_dir, '*_uncal.fits')))\n",
    "uncal_bgfiles = sorted(glob.glob(os.path.join(uncal_bgdir, '*_uncal.fits')))\n",
    "\n",
    "print('Found ' + str(len(uncal_files)) + ' science input files')\n",
    "print('Found ' + str(len(uncal_bgfiles)) + ' background input files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024a9df0",
   "metadata": {},
   "source": [
    "Look at the first file to determine exposure parameters and practice using\n",
    "JWST datamodelsÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a7f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dodet1:\n",
    "    # print file name\n",
    "    print(uncal_files[0])\n",
    "\n",
    "    # Open file as JWST datamodel\n",
    "    examine = datamodels.open(uncal_files[0])\n",
    "\n",
    "    # Print out exposure info\n",
    "    print(f\"Instrument: {examine.meta.instrument.name}\")\n",
    "    print(f\"Filter: {examine.meta.instrument.filter}\")\n",
    "    print(f\"Number of integrations: {examine.meta.exposure.nints}\")\n",
    "    print(f\"Number of groups: {examine.meta.exposure.ngroups}\")\n",
    "    print(f\"Readout pattern: {examine.meta.exposure.readpatt}\")\n",
    "    print(f\"Dither position number: {examine.meta.dither.position_number}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee917a7",
   "metadata": {},
   "source": [
    "From the above, we confirm that the demo data file is for the MIRI instrument\n",
    "using the `F770W` filter in the [Filter Wheel](https://jwst-docs.stsci.edu/jwst-mid-infrared-instrument/miri-instrumentation/miri-filters-and-dispersers#gsc.tab=0). This observation uses\n",
    "the MIRI [readout pattern](https://jwst-docs.stsci.edu/jwst-mid-infrared-instrument/miri-instrumentation/miri-detector-overview/miri-detector-readout-overview#gsc.tab=0) FASTR1,\n",
    "6 groups per integration, and 1 integration per exposure. This data file\n",
    "is the 1st dither position in this exposure sequence. For more information\n",
    "about how JWST exposures are defined by up-the-ramp sampling, see the\n",
    "[Understanding Exposure Times JDox article](https://jwst-docs.stsci.edu/understanding-exposure-times).<br>\n",
    "\n",
    "This metadata will be the same for all exposures in this observation other\n",
    "than the dither position number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8f107b-5f80-4674-bc34-2d88791e4409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run Detector1 stage of pipeline, specifying:\n",
    "# output directory to save *_rate.fits files\n",
    "# save_results flag set to True so the rate files are saved\n",
    "\n",
    "if dodet1:\n",
    "    for uncal in uncal_files:\n",
    "        rate_result = Detector1Pipeline.call(uncal, output_dir=det1_dir, steps=det1dict, save_results=True,)\n",
    "else:\n",
    "    print('Skipping Detector1 processing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae69bfe2",
   "metadata": {},
   "source": [
    "### Calibrating Background Files\n",
    "Look for input background files and run calwebb_detector1\n",
    "pipeline using the call method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c536f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Detector1 stage of pipeline on any background files\n",
    "\n",
    "if dodet1bg:\n",
    "    for uncal in uncal_bgfiles:\n",
    "        rate_result = Detector1Pipeline.call(uncal, output_dir=det1_bgdir, steps=det1dict, save_results=True,)\n",
    "else:\n",
    "    print('Skipping Detector1 BG processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cc2b48-7ec7-4b59-b3ee-2dfdf0782c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the time benchmark\n",
    "time1 = time.perf_counter()\n",
    "print(f\"Runtime for Detector1: {time1 - time0:0.0f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc5520a-6097-482b-b3e0-a6bf94cf7af3",
   "metadata": {},
   "source": [
    "### Exploring the data\n",
    "\n",
    "Identify `*_rate.fits` files and verify which pipeline steps were run and\n",
    "which calibration reference files were applied.<br>\n",
    "\n",
    "The header contains information about which calibration steps were\n",
    "completed and skipped and which reference files were used to process the\n",
    "data.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c122766-a545-4042-93e8-f68c18f62fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dodet1:\n",
    "    # find rate files\n",
    "    rate_files = sorted(glob.glob(os.path.join(det1_dir, '*_rate.fits')))\n",
    "\n",
    "    # Read in file as datamodel\n",
    "    rate_f = datamodels.open(rate_files[0])\n",
    "\n",
    "    # Check which steps were run\n",
    "    rate_f.meta.cal_step.instance\n",
    "\n",
    "    # Check which reference files were used to calibrate the dataset:\n",
    "    rate_f.meta.ref_file.instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e4ff98",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350808ee-9579-4cb5-8f02-a74904c91449",
   "metadata": {},
   "source": [
    "## 6. Image2 Pipeline \n",
    "\n",
    "In the [Image2](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_image2.html) stage of the pipeline,\n",
    "calibrated unrectified data products are created (`*_cal.fits` or\n",
    "`*_calints.fits` files, depending on whether the input files are\n",
    "`*_rate.fits` or `*_rateints.fits`). \n",
    "\n",
    "In this pipeline processing stage, the\n",
    "[background subtraction](https://jwst-pipeline.readthedocs.io/en/latest/jwst/background_step/index.html#background-step)\n",
    "step is performed if the data have a dedicated background defined,\n",
    "the [world coordinate system (WCS)](https://jwst-pipeline.readthedocs.io/en/latest/jwst/assign_wcs/index.html#assign-wcs-step)\n",
    "is assigned, the data are [flat fielded](https://jwst-pipeline.readthedocs.io/en/latest/jwst/flatfield/index.html#flatfield-step),\n",
    "and a [photometric calibration](https://jwst-pipeline.readthedocs.io/en/latest/jwst/photom/index.html#photom-step)\n",
    "is applied to convert from units of countrate (ADU/s) to surface brightness (MJy/sr).\n",
    "\n",
    "The [resampling](https://jwst-pipeline.readthedocs.io/en/latest/jwst/resample/index.html#resample-step)\n",
    "step is performed, to create resampled images of each dither position, but this is\n",
    "only a quick-look product. The resampling step occurs during the `Image3` stage by\n",
    "default. While the resampling step is done in the `Image2` stage, the data quality\n",
    "from the `Image3` stage will be better since the bad pixels, which adversely affect\n",
    "both the centroids and photometry in individual images, will be mostly\n",
    "removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a091817-7a3c-4a60-a914-f9ac54d36e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_image2 = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b00fda2-a7c0-445a-bf23-0d9b4f050419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a dictionary to define how the Image2 pipeline should be configured.\n",
    "\n",
    "# Boilerplate dictionary setup\n",
    "image2dict = {}\n",
    "image2dict['bkg_subtract'] = {}\n",
    "image2dict['assign_wcs'], image2dict['flat_field'] = {}, {}\n",
    "image2dict['photom'], image2dict['resample'] = {}, {}\n",
    "\n",
    "# Overrides for whether or not certain steps should be skipped (example)\n",
    "#image2dict['resample']['skip'] = False\n",
    "\n",
    "# Change the nsigma used for clipping the input background data\n",
    "image2dict['bkg_subtract']['sigma'] = 2\n",
    "\n",
    "# Overrides for various reference files\n",
    "# Files should be in the base local directory or provide full path\n",
    "#image2dict['assign_wcs']['override_distortion'] = 'myfile.asdf'  # Spatial distortion (ASDF file)\n",
    "#image2dict['assign_wcs']['override_filteroffset'] = 'myfile.asdf'  # Imager filter offsets (ASDF file)\n",
    "#image2dict['assign_wcs']['override_specwcs'] = 'myfile.asdf'  # Spectral distortion (ASDF file)\n",
    "#image2dict['assign_wcs']['override_wavelengthrange'] = 'myfile.asdf'  # Wavelength channel mapping (ASDF file)\n",
    "#image2dict['flat_field']['override_flat'] = 'myfile.fits'  # Pixel flatfield\n",
    "#image2dict['photom']['override_photom'] = 'myfile.fits'  # Photometric calibration array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd5c61a",
   "metadata": {},
   "source": [
    "Define a function to create association files for Stage 2. This will enable use of the pixel-based background subtraction, if chosen above. This requires *one* input SCI file, but can have multiple input background files.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "Note that the background will not be applied properly to all files if more than *one* SCI file is included in the association.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeae956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writel2asn(onescifile, bgfiles, asnfile, prodname):\n",
    "    # Define the basic association of science files\n",
    "    asn = afl.asn_from_list([onescifile], rule=DMSLevel2bBase, product_name=prodname)  # Wrap in array since input was single exposure\n",
    "\n",
    "    # Filter configuration for this sci file\n",
    "    with fits.open(onescifile) as hdu:\n",
    "        hdu.verify()\n",
    "        hdr = hdu[0].header\n",
    "        this_filter = hdr['FILTER']\n",
    "\n",
    "    # If backgrounds were provided, find which are appropriate to this\n",
    "    # filter and add to association\n",
    "    for file in bgfiles:\n",
    "        with fits.open(file) as hdu:\n",
    "            hdu.verify()\n",
    "            if (hdu[0].header['FILTER'] == this_filter):\n",
    "                asn['products'][0]['members'].append({'expname': file, 'exptype': 'background'})              \n",
    "\n",
    "    # Write the association to a json file\n",
    "    _, serialized = asn.dump()\n",
    "    with open(asnfile, 'w') as outfile:\n",
    "        outfile.write(serialized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247170cd-a3ee-4d9d-b8b3-f930727f8abc",
   "metadata": {},
   "source": [
    "Find and sort all of the input files, ensuring use of absolute paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19cd4e6-cc38-4e26-8e8b-7fb143856940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all Science rate.fits files\n",
    "sstring = os.path.join(det1_dir, 'jw*rate.fits')  # Use files from the detector1 output folder\n",
    "rate_files = sorted(glob.glob(sstring))\n",
    "for ii in range(0, len(rate_files)):\n",
    "    rate_files[ii] = os.path.abspath(rate_files[ii])\n",
    "rate_files = np.array(rate_files)\n",
    "\n",
    "# Background Files\n",
    "sstring = os.path.join(det1_bgdir, 'jw*rate.fits')\n",
    "bgfiles = sorted(glob.glob(sstring))\n",
    "for ii in range(0, len(bgfiles)):\n",
    "    bgfiles[ii] = os.path.abspath(bgfiles[ii])\n",
    "bgfiles = np.array(bgfiles)\n",
    "\n",
    "print(f\"Found  {str(len(rate_files))} science files\")\n",
    "print(f\"Found  {str(len(bgfiles))} background files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d916e5-dd5d-472d-9aff-b2b4c86decf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run Image2 stage of pipeline, specifying the output directory to save *_cal.fits files\n",
    "# and save_results flag set to True so the rate files are saved\n",
    "if doimage2:\n",
    "    for rate in rate_files:\n",
    "        asnfile = os.path.join(sci_dir, 'l2asn.json')\n",
    "        writel2asn(rate, bgfiles, asnfile, 'Level2')\n",
    "        cal_result = Image2Pipeline.call(asnfile, output_dir=image2_dir, steps=image2dict, save_results=True)\n",
    "else:\n",
    "    print(\"Skipping Image2 processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d58b94d-e1d7-4b73-b598-756c99d81174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the time benchmark\n",
    "time1 = time.perf_counter()\n",
    "print(f\"Runtime so far: {time1 - time0:0.0f} seconds\")\n",
    "print(f\"Runtime for Image2: {time1 - time_image2:0.0f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da57b7d0-95ef-4227-b730-6f54a3eaaa16",
   "metadata": {},
   "source": [
    "### Verify which pipeline steps were run and reference files used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27390bbd-ae2d-49e7-977a-59d3765c0946",
   "metadata": {},
   "outputs": [],
   "source": [
    "if doimage2:\n",
    "    # Identify *_cal.fits files\n",
    "    cal_files = sorted(glob.glob(os.path.join(image2_dir, '*_cal.fits')))\n",
    "\n",
    "    cal_f = datamodels.open(cal_files[0])\n",
    "\n",
    "    # Check which steps were run:\n",
    "    cal_f.meta.cal_step.instance\n",
    "\n",
    "    # Check which reference files were used to calibrate the dataset:\n",
    "    cal_f.meta.ref_file.instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5b9a4d",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfbb244-7af9-4cbf-90d9-08598378c16a",
   "metadata": {},
   "source": [
    "## 7. Image3 Pipeline\n",
    "\n",
    "In the [Image3](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_image3.html)\n",
    "stage of the pipeline, the individual `*_cal.fits` files for each of the dither positions are\n",
    "combined to one single distortion corrected image. First, an \n",
    "[Association](https://jwst-pipeline.readthedocs.io/en/latest/jwst/associations/overview.html)\n",
    "needs to be created to inform the pipeline that these individual exposures are linked together.\n",
    "\n",
    "By default, the `Image3` stage of the pipeline performs the following steps on MIRI data:\n",
    "* [tweakreg](https://jwst-pipeline.readthedocs.io/en/latest/jwst/tweakreg/index.html#tweakreg-step) -\n",
    "  creates source catalogs of pointlike sources for each input image. The source catalog for each input\n",
    "  image is compared to each other to derive coordinate transforms to align the images relative to each other.\n",
    "    * As of pipeline version 1.14.0, the default source finding algorithm is `IRAFStarFinder`.\n",
    "* [skymatch](https://jwst-pipeline.readthedocs.io/en/latest/jwst/skymatch/index.html#skymatch-step) -\n",
    "  measures the background level from the sky to use as input into the subsequent `outlier detection` and `resample` steps.\n",
    "* [outlier detection](https://jwst-pipeline.readthedocs.io/en/latest/jwst/outlier_detection/index.html#outlier-detection-step) -\n",
    "  flags any remaining cosmic rays, bad pixels, or other artifacts not already flagged during the `DETECTOR1` stage\n",
    "  of the pipeline, using all input images to create a median image so that outliers in individual images can be identified.\n",
    "* [resample](https://jwst-pipeline.readthedocs.io/en/latest/jwst/resample/index.html#resample-step) -\n",
    "  resamples each input image based on its WCS and distortion information and creates a single undistorted image.\n",
    "* [source catalog](https://jwst-pipeline.readthedocs.io/en/latest/jwst/source_catalog/index.html#source-catalog-step) -\n",
    "  creates a catalog of detected sources along with measured photometries and morphologies (i.e., point-like vs extended).\n",
    "  Useful for quicklooks, but optimization is likely needed for specific science cases. Users may wish to experiment with\n",
    "  changing the `snr_threshold` and `deblend` options. Modifications to the following parameters will not significantly\n",
    "  improve data quality and it is advised to keep them at their default values: `aperture_ee1`, `aperture_ee2`,\n",
    "  `aperture_ee3`, `ci1_star_threshold`, `ci2_star_threshold`.\n",
    "\n",
    "Some values that have been shown to give good results for MIRI data are to set the outlier_detection's parameter `scale`\n",
    "to '1.0 0.8' and to set the resample parameter `weight_type` to 'exptime', both currently set in the \n",
    "[parameter reference file](https://jwst-pipeline.readthedocs.io/en/stable/jwst/stpipe/parameter_files.html#parameter-files)\n",
    "<I>pars-outlierdetectionstep</I>, but can be overridden as indicated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e81dc9-78dd-4bba-879c-9dfa2a4da69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_image3 = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159e63d-3c89-44ef-9a43-caaccd1abb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a dictionary to define how the Image3 pipeline should be configured\n",
    "# Boilerplate dictionary setup\n",
    "image3dict = {}\n",
    "image3dict['assign_mtwcs'], image3dict['tweakreg'], image3dict['skymatch'] = {}, {}, {}\n",
    "image3dict['outlier_detection'], image3dict['resample'], image3dict['source_catalog'] = {}, {}, {}\n",
    "\n",
    "# Overrides for whether or not certain steps should be skipped (example)\n",
    "#image3dict['outlier_detection']['skip'] = True\n",
    "\n",
    "# Overrides for various reference files\n",
    "# Files should be in the base local directory or provide full path\n",
    "#image3dict['source_catalog']['override_apcorr'] = 'myfile.fits'  # Aperture correction parameters\n",
    "#image3dict['source_catalog']['override_abvegaoffset'] = 'myfile.asdf'  # Data to convert from AB to Vega magnitudes (ASDF file)\n",
    "\n",
    "# Overrides for specific parameters in the step (examples)\n",
    "#image3dict['resample']['weight_type'] = ['exptime']\n",
    "#image3dict['outlier_detection']['scale'] = ['1.0 0.8']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10da872-21ae-46c2-a3b1-f9cdefae3b36",
   "metadata": {},
   "source": [
    "Find and sort all of the input files, ensuring use of absolute paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0b5b47-62e9-4593-abc4-7ec630492e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Science Files need are the cal.fits files\n",
    "sstring = os.path.join(image2_dir, 'jw*cal.fits')\n",
    "cal_files = sorted(glob.glob(sstring))\n",
    "for ii in range(0, len(cal_files)):\n",
    "    cal_files[ii] = os.path.abspath(cal_files[ii])\n",
    "calfiles = np.array(cal_files)\n",
    "\n",
    "print(f'Found {str(len(cal_files))} science files to process')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5cb6f5-44a1-4f28-95dc-b23a97451465",
   "metadata": {},
   "source": [
    "### Create Association File\n",
    "\n",
    "An association file lists the exposures to calibrated together in `Stage3`\n",
    "of the pipeline. Note that an association file is available for download\n",
    "from MAST, with a filename of `*_asn.json`. Here we show how to create an\n",
    "association file to point to the data products created when processing data\n",
    "through the pipeline. Note that the output products will have a rootname\n",
    "that is specified by the `product_name` in the association file. For\n",
    "this tutorial, the rootname of the output products will be\n",
    "`image3_association`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b31f80f-8d7b-45ae-8537-15d0208637df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a Level 3 Association\n",
    "if doimage3:\n",
    "    associations = afl.asn_from_list(cal_files, rule=DMS_Level3_Base, product_name='image3_association')\n",
    "\n",
    "    associations.data['asn_type'] = 'image3'\n",
    "    program = datamodels.open(cal_files[0]).meta.observation.program_number\n",
    "    associations.data['program'] = program\n",
    "\n",
    "    # Format association as .json file\n",
    "    asn_filename, serialized = associations.dump(format=\"json\")\n",
    "\n",
    "    # Write out association file\n",
    "    association_im3 = os.path.join(sci_dir, asn_filename)\n",
    "    with open(association_im3, \"w\") as fd:\n",
    "        fd.write(serialized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629cad5b-e5a7-473e-8583-ad12cda55fa4",
   "metadata": {},
   "source": [
    "### Run Image3 stage of the pipeline\n",
    "\n",
    "Given the grouped exposures in the association file, the products if the\n",
    "`Image3` stage of the pipeline are:\n",
    "* a `*_crf.fits` file produced by the `outlier_detection` step, where the `DQ` array marks the pixels flagged as outliers.\n",
    "* a final combined, rectified image with name `*_i2d.fits`,\n",
    "* a source catalog with name `*_cat.ecsv`,\n",
    "* a segmentation map file (`*_segm.fits`) which has integer values at the pixel locations where a source is detected where the pixel values match the source ID number in the catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cebfd8-a650-41a3-8ff0-a8fd43e079d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run Stage 3\n",
    "if doimage3:\n",
    "    i2d_result = Image3Pipeline.call(association_im3, output_dir=image3_dir, steps=image3dict, save_results=True)\n",
    "else:\n",
    "    print('Skipping Spec3 processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67d2c65-4614-4592-aa67-daa2de985013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the time benchmark\n",
    "time1 = time.perf_counter()\n",
    "print(f\"Runtime so far: {time1 - time0:0.0f} seconds\")\n",
    "print(f\"Runtime for Image3: {time1 - time_image3:0.0f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcb6c40-fbb8-4226-b620-64b0c02c8ceb",
   "metadata": {},
   "source": [
    "### Verify which pipeline steps were run and reference files used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c754530a-d4e2-493b-bf8b-bf8d1ad08770",
   "metadata": {},
   "outputs": [],
   "source": [
    "if doimage3:\n",
    "    # Identify *_i2d file and open as datamodel\n",
    "    i2d = glob.glob(os.path.join(image3_dir, \"*_i2d.fits\"))[0]\n",
    "    i2d_f = datamodels.open(i2d)\n",
    "\n",
    "    # Check which steps were run\n",
    "    i2d_f.meta.cal_step.instance\n",
    "\n",
    "    # Check which reference files were used to calibrate the dataset\n",
    "    i2d_f.meta.ref_file.instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947f990e",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46be5421-7fc8-4d96-b2cd-2484f294e082",
   "metadata": {},
   "source": [
    "## 8. Visualize the drizzle-combined image\n",
    "\n",
    "We will use matplotlib routines for visualizing the data. Display the combined i2d image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4994ba3a-1022-4061-85b6-b2bd08477852",
   "metadata": {},
   "outputs": [],
   "source": [
    "if doviz:\n",
    "    # Look at the final i2d image (combined mosaic)\n",
    "    sstring = os.path.join(image3_dir, '*i2d.fits')\n",
    "    miri_mosaic_file = glob.glob(sstring)\n",
    "    print(miri_mosaic_file)\n",
    "\n",
    "    # Read your mosaic image into an ImageModel datamodel\n",
    "    miri_mosaic = ImageModel(miri_mosaic_file[0])\n",
    "    \n",
    "    # Autoscale the stretch\n",
    "    display_vals = [np.nanpercentile(miri_mosaic.data, 1), np.nanpercentile(miri_mosaic.data, 99)]\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    # Set up image\n",
    "    cax = ax.imshow(miri_mosaic.data, cmap='Greys', origin='lower', vmin=display_vals[0], vmax=display_vals[1])\n",
    "\n",
    "    # Set up colorbar\n",
    "    cb = fig.colorbar(cax, fraction=0.046)\n",
    "    cb.ax.set_ylabel('MJy/str', fontsize=14)\n",
    "\n",
    "    # Set labels \n",
    "    ax.set_xlabel('X', fontsize=16)\n",
    "    ax.set_ylabel('Y', fontsize=16)\n",
    "    ax.set_title('Final MIRI mosaic', fontsize=16)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170bb10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018733eb-07ec-44a4-a5a7-d6d2f27d193a",
   "metadata": {},
   "source": [
    "## <a id='detections'>Visualize Detected Sources</a>\n",
    "Using the source catalog created by the `IMAGE3` stage of the pipeline,\n",
    "mark the detected sources, using different markers for point sources\n",
    "and extended sources. The source catalog is saved in\n",
    "`image3/image3_association_cat.ecsv` file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad6ee55-f940-4be3-96c9-114bc83eb784",
   "metadata": {},
   "source": [
    "### Read in catalog file and identify point/extended sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32235fdc-4ec2-42e6-89e7-b9f62824e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "if doviz:\n",
    "    catalog_file = glob.glob(os.path.join(image3_dir, \"*_cat.ecsv\"))[0]\n",
    "    catalog = Table.read(catalog_file)\n",
    "\n",
    "    # find where sources are considered extended or point sources\n",
    "    pt_src, = np.where(~catalog['is_extended'])\n",
    "    ext_src, = np.where(catalog['is_extended'])\n",
    "\n",
    "    # Get x and y coordinates of the objects found \n",
    "    miri_x = catalog['xcentroid'][pt_src]\n",
    "    miri_y = catalog['ycentroid'][pt_src]\n",
    "\n",
    "    ext_x = catalog['xcentroid'][ext_src]\n",
    "    ext_y = catalog['ycentroid'][ext_src]\n",
    "\n",
    "    # Show catalog\n",
    "    catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9e9069-375d-431b-bbfb-e84e6cefc2d4",
   "metadata": {},
   "source": [
    "### Mark the extended and point sources on the image\n",
    "\n",
    "Display combined image with point sources marked with red dots and extended sources marked with blue triangles. You will see that there are a grouping of sources near the top edge of the MIRI image, several of which may be spurious sources, which tend to be found near image edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafd7ef5-f2c1-4698-8a66-1b8009871c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "if doviz:\n",
    "    # Look at mosaic data and sources found with source_catalog\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    # Set up image\n",
    "    cax = ax.imshow(miri_mosaic.data, cmap='Greys', origin='lower', vmin=display_vals[0], vmax=display_vals[1])\n",
    "    ax.scatter(miri_x, miri_y, lw=1, s=10, color='red')  # overplot point source positions\n",
    "    ax.scatter(ext_x, ext_y, lw=1, s=20, color='blue', marker='v')  # overplot extended source positions\n",
    "\n",
    "    # Set up colorbar\n",
    "    cb = fig.colorbar(cax, fraction=0.046)\n",
    "    cb.ax.set_ylabel('MJy/str', fontsize=14)\n",
    "\n",
    "    # Set labels\n",
    "    ax.set_xlabel('X', fontsize=16)\n",
    "    ax.set_ylabel('Y', fontsize=16)\n",
    "    ax.set_title('Final MIRI mosaic', fontsize=16)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59557af",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6303c0e7-13af-4e4c-bed7-8b85cc8e3645",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src=\"https://github.com/spacetelescope/jwst-pipeline-notebooks/raw/main/_static/stsci_footer.png\" alt=\"stsci_logo\" width=\"200px\"/> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
