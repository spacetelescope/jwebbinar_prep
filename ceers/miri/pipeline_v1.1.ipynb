{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "# CEERS: Reducing MIRI Imaging Data\n",
    "---\n",
    "**Author**: Guang Yang (gyang206265@gmail.com) \n",
    "\n",
    "**Latest Update**: 12 November 2021\n",
    "\n",
    "This notebook will reduce all available raw MIRI images through the JWST Calibration Pipeline, with some custom steps developed for our simulated data. At the end, it also tests the output photometry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Imports](#imports)\n",
    "* [Notebook setup](#setup)\n",
    "* [Pipeline information](#info)\n",
    "* [The calwebb_detector1 and calwebb_image2 pipelines](#steps1&2) \n",
    "* [The calwebb_image3 pipeline](#step3) \n",
    "* [Photometry tests](#photometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imports'></a>\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell loads necessary modules \n",
    "import numpy as np\n",
    "import os\n",
    "from astropy.io import fits\n",
    "\n",
    "from jwst import pipeline\n",
    "from jwst.pipeline import Detector1Pipeline\n",
    "from jwst.pipeline import Image2Pipeline\n",
    "from jwst.pipeline import Image3Pipeline\n",
    "from jwst.associations import asn_from_list\n",
    "from jwst.associations.lib.rules_level3 import Asn_Lv3Image\n",
    "\n",
    "from glob import glob\n",
    "import sep\n",
    "from astroscrappy import detect_cosmics\n",
    "\n",
    "from astropy.wcs import WCS\n",
    "from astropy.table import Table\n",
    "\n",
    "from collections import defaultdict\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "import math\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will reduce all raw data located in `[data_dir]/CEERS*/F*W/`, where `CEERS*` are each individual CEERS MIRI pointing, and the raw files are organized by filter (`F*W`).\n",
    "\n",
    "**Change the path for `data_dir` in the next cell to match the location of your downloaded CEERS MIRI raw images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell set the data directory and search for the raw images\n",
    "\n",
    "# Set the directory where all the data are\n",
    "#data_dir = \"./\"\n",
    "data_dir = \"/home/shared/preloaded-fits/ceers-data/miri/part1\"\n",
    "\n",
    "# Search the work directories hosting raw images\n",
    "wk_dirs = glob(f\"{data_dir}/CEERS*/*W\")\n",
    "\n",
    "print(wk_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='info'></a>\n",
    "##  Pipeline information\n",
    "\n",
    "The cells below will run the [JWST Calibration Pipeline](https://github.com/spacetelescope/jwst). \n",
    "We briefly summarize the pipeline below, and more details can be found in the [User Manual](https://jwst-pipeline.readthedocs.io/en/latest/index.html#user-manual).\n",
    "\n",
    "The inputs are raw MIRI images and the outputs are calibrated science images, weight images, and catalogs (optional; see below).  \n",
    "\n",
    "The pipeline has three stages: \n",
    "* [Stage 1](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_detector1.html#calwebb-detector1) applies basic detector-level corrections, yielding a count-rate map for each exposure.\n",
    "* [Stage 2](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_image2.html#calwebb-image2) applies additional instrumental corrections and calibrations that result in a fully calibrated individual exposure.  \n",
    "* [Stage 3](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_image3.html) combines the calibrated multiple exposures into a single rectified image and perform source detections (if desired). \n",
    "\n",
    "Below, we adopt the default settings for Stages 1 & 2 (except skipping a function in Stage 1; see below), but significantly modify Stage 3. The reason is that Stage 3 is still under intensive development and the current default settings cannot produce optimal results for our simulated data (see [Yang et al. 2021](https://ui.adsabs.harvard.edu/abs/2021ApJ...908..144Y/abstract) for details). Also, our MIRISIM-simulated raw data do not contain the physical WCS information, and we need to correct the WCS on our own at Stage 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='steps1&2'></a>\n",
    "## The calwebb-detector1 and calwebb_image2 pipelines\n",
    "\n",
    "Converting ramps to slopes ([*calwebb_detector1*, Detector1Pipeline](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_detector1.html#calwebb-detector1)) and producing calibrated slope images ([*calwebb_image2*, Image2Pipeline](https://jwst-pipeline.readthedocs.io/en/stable/jwst/pipeline/calwebb_image2.html)). \n",
    "\n",
    "We will call the pipeline using the [`run()` method](https://jwst-pipeline.readthedocs.io/en/stable/jwst/stpipe/call_via_run.html).\n",
    "\n",
    "This cell will take several minutes to run, depending on how many raw images you are reducing. The Stage 1 reduction pipeline steps in particular can take a while for each input raw image.\n",
    "\n",
    "Note: We skip the \"refpix\" function in Stage 1, because MIRISIM dose not put in the targeted noise of this function and running it would cause stripe-like artifacts in the final science images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This cell performs stages 1 & 2 reduction\n",
    "\n",
    "#Option to skip stage 1 if preprocessed data already exists on the system\n",
    "#Use this to save time for JWebbinar instructional purposes\n",
    "skip_stage_1 = True\n",
    "#skip_stage_1 = False\n",
    "\n",
    "# Iterater over each band\n",
    "for wk_dir in wk_dirs:\n",
    "    # Search for raw files \n",
    "    raw_files = glob(os.path.join(wk_dir,'*exp?.fits'))\n",
    "    # The list to save the path of stage1 products \n",
    "    stage1_files = []\n",
    "    # Iterate over the input\n",
    "    det1 = Detector1Pipeline()\n",
    "    # Skip the refpix function\n",
    "    det1.refpix.skip = True\n",
    "    print(raw_files)\n",
    "    for file in raw_files:\n",
    "\n",
    "        # Generate the file name of stage1 product\n",
    "        stage1_bn = os.path.basename(file[:file.rfind('.fits')] + '_stage1.fits')\n",
    "        stage1_fil = os.path.basename(os.path.dirname(file))\n",
    "        stage1_relpath = os.path.join('CEERS7b',stage1_fil)\n",
    "        os.makedirs(stage1_relpath,exist_ok=True)\n",
    "        stage1_file = os.path.join(stage1_relpath,stage1_bn)\n",
    "        \n",
    "        #If pre-staged files exist, link to them from the local directory.\n",
    "        if skip_stage_1 is True:\n",
    "            if not os.path.exists(stage1_file):\n",
    "                os.symlink(os.path.join(wk_dir,stage1_bn),stage1_file)\n",
    "        \n",
    "        #check if stage 1 files exist already.  If not, run stage 1.\n",
    "        if os.path.lexists(stage1_file):\n",
    "            print('stage 1 output exists, skipping..', stage1_file)\n",
    "            stage1_files.append(stage1_file)\n",
    "        else:\n",
    "            # Run the pipeline\n",
    "            result = det1.run(file)\n",
    "        \n",
    "            # Save the stage1 products to file\n",
    "            result.save(stage1_file)\n",
    "            # Save the file name\n",
    "            stage1_files.append(stage1_file)\n",
    "\n",
    "    # Process to stage 2\n",
    "    #stage1_files = glob(wk_dir+'*stage1*.fits')\n",
    "    print(stage1_files)\n",
    "    stage2_files = []\n",
    "    # Iterate over the input\n",
    "    for file in stage1_files:\n",
    "        # Run the pipeline\n",
    "        img2 = Image2Pipeline()\n",
    "        result = img2.run(file)\n",
    "        # Generate the file name of stage2 product\n",
    "        stage2_bn = os.path.basename(file[:file.rfind('stage1.fits')] + 'stage2.fits')\n",
    "        stage2_fil = os.path.basename(os.path.dirname(file))\n",
    "        stage2_relpath = os.path.join('CEERS7b',stage2_fil)\n",
    "        os.makedirs(stage2_relpath,exist_ok=True)\n",
    "        stage2_file = os.path.join(stage2_relpath,stage2_bn)\n",
    "        # Save the results to file\n",
    "        result[0].save(stage2_file)\n",
    "        # Save the file name\n",
    "        stage2_files.append(stage2_file)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redefine work dirs to local path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stage2_files)\n",
    "wk_dirs = glob(f\"CEERS*/*W\")\n",
    "print(wk_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## The calwebb_image3 pipeline\n",
    "\n",
    "Ensemble calibrations ([*calwebb_image3*, Image3Pipeline](https://jwst-pipeline.readthedocs.io/en/stable/jwst/pipeline/calwebb_image3.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell performs Stage 3 reduction, \n",
    "# correct for WCS (only needed for simulated images), and \n",
    "# perform photometry  \n",
    "\n",
    "# Set below to True if you want the pipeline to extract photometry using photutils\n",
    "photo_flag = True\n",
    "\n",
    "# Set the background configurations\n",
    "bkg_cell_size = 16\n",
    "bkg_filt_size = 3\n",
    "fthresh = -99\n",
    "\n",
    "# The correction factors for different bands \n",
    "# These are obtained by simulating bright point-like sources\n",
    "# (see Appendix A of Yang+2021)\n",
    "cor_facs = {\"F560W\":1.069, \n",
    "            \"F770W\":1.156, \n",
    "            \"F1000W\":1.040, \n",
    "            \"F1280W\":0.998, \n",
    "            \"F1500W\":1.062, \n",
    "            \"F1800W\":0.973, \n",
    "            \"F2100W\":1.047}\n",
    "\n",
    "# CR maps (produced by gen_cr_map.ipynb) needed below\n",
    "for wk_dir in wk_dirs:\n",
    "    # Process to stage 3\n",
    "    stage2_files = sorted( glob(os.path.join(wk_dir,'*stage2.fits')) )\n",
    "    # Create an association \n",
    "    asn = dict( asn_from_list.asn_from_list(stage2_files, rule=Asn_Lv3Image, product_name='l3_results') )\n",
    "    asn[\"asn_type\"] = \"image3\"\n",
    "    asn[\"asn_id\"] = \"\"\n",
    "    # Configure the stage 3 pipeline \n",
    "    img3 = Image3Pipeline()\n",
    "    img3.output_dir = wk_dir\n",
    "    img3.output_file = 'stage3_merged_image'\n",
    "    img3.resample.save_results = False\n",
    "    img3.resample.output_dir = wk_dir\n",
    "\n",
    "    # Run the pipeline\n",
    "    res_step3 = img3.skymatch.run(asn)\n",
    "        \n",
    "    # Subtract the position-dependent backgrounds\n",
    "    for seq_idx in range(len(res_step3._models)):\n",
    "        # Extract the data\n",
    "        sci_img = np.array(res_step3._models[seq_idx].data)\n",
    "        dq_img = np.array(res_step3._models[seq_idx].dq)\n",
    "        err_img = np.array(res_step3._models[seq_idx].err)\n",
    "        bkg_level = res_step3._models[seq_idx].meta.background.level\n",
    "        # Mask bad pixels\n",
    "        mask = (dq_img>100)\n",
    "        mask[sci_img < bkg_level/2] = True\n",
    "\n",
    "        # Also mask the nearby pixels\n",
    "        bad_idxs = np.where(mask)\n",
    "        # To avoid index underflow\n",
    "        use_Sidxs = np.where( bad_idxs[0]!=0 )\n",
    "        mask[bad_idxs[0][use_Sidxs]-1, bad_idxs[1][use_Sidxs]] = True\n",
    "        use_Sidxs = np.where( bad_idxs[1]!=0 )\n",
    "        mask[bad_idxs[0][use_Sidxs], bad_idxs[1][use_Sidxs]-1] = True\n",
    "        # To avoid index overflow \n",
    "        use_Sidxs = np.where( bad_idxs[0]!=sci_img.shape[0]-1 )\n",
    "        mask[bad_idxs[0][use_Sidxs]+1, bad_idxs[1][use_Sidxs]] = True\n",
    "        use_Sidxs = np.where( bad_idxs[1]!=sci_img.shape[1]-1 )\n",
    "        mask[bad_idxs[0][use_Sidxs], bad_idxs[1][use_Sidxs]+1] = True\n",
    "        \n",
    "        # Mask coronograph\n",
    "        mask[:, :350] = True\n",
    "        # Estimate background\n",
    "        bkg = sep.Background(sci_img.byteswap().newbyteorder(), \n",
    "                             bw=bkg_cell_size, bh=bkg_cell_size, \n",
    "                             fw=bkg_filt_size, fh=bkg_filt_size, mask=mask, fthresh=fthresh)\n",
    "        # Subtract background\n",
    "        sci_img -= bkg.back()\n",
    "        # Re-set the metadata, indicating background already subtracted\n",
    "        res_step3._models[seq_idx].meta.background.subtracted = True\n",
    "        # Mask defect pixels\n",
    "        mask[sci_img < -10*err_img] = True\n",
    "        # Mask the CR \n",
    "        cr_map = detect_cosmics(sci_img, sigclip=1)[0]*1        \n",
    "        mask[np.where(cr_map)] = True\n",
    "        \n",
    "        # Set masked region to zero\n",
    "        sci_img[mask] = 0\n",
    "        # Update the data\n",
    "        res_step3._models[seq_idx].data = sci_img\n",
    "        # Update dq\n",
    "        res_step3._models[seq_idx].dq[mask] = np.max(res_step3._models[seq_idx].dq)     \n",
    "\n",
    "    # Merge the exposures\n",
    "    res_step4 = img3.resample.run(res_step3)\n",
    "    mask = res_step4.wht==0\n",
    "    # subtract the background\n",
    "    bkg = sep.Background(res_step4.data, \n",
    "                         bw=bkg_cell_size, bh=bkg_cell_size, \n",
    "                         fw=bkg_filt_size, fh=bkg_filt_size, mask=mask, fthresh=fthresh)\n",
    "    res_step4.data -= bkg.back()\n",
    "    res_step4.data[mask] = 0\n",
    "    res_step4.save(os.path.join(wk_dir,'stage3_merged_image_resample.fits'))\n",
    "    \n",
    "    # Updte WCS and output final science and weight images\n",
    "    # Read mirisim products\n",
    "    mirisim_data = fits.open(os.path.join(wk_dir,'stage3_merged_image_resample.fits'))[1]\n",
    "    hd = mirisim_data.header\n",
    "    # Extract the old wcs info.\n",
    "    old_wcs = WCS(hd)\n",
    "\n",
    "    # Read the pointing info.\n",
    "    pt_id = wk_dir[wk_dir.find('CEERS')+5:wk_dir.find('CEERS')+7]\n",
    "    if pt_id[1]=='/': pt_id=pt_id[0]\n",
    "    reg_data = Table.read(os.path.join(data_dir,\"pointing_info/miri%s_reg.fits\" %pt_id))[0]\n",
    "    # Get the new reference pixel\n",
    "    new_crpix_1, new_crpix_2 = old_wcs.all_world2pix([0], [0], 1)\n",
    "    new_crpix_1, new_crpix_2 = new_crpix_1[0], new_crpix_2[0]\n",
    "    # Re-set the ra-dec for the new pix ref\n",
    "    new_crval_1, new_crval_2 = reg_data['RA_Ref'], reg_data['DEC_Ref']\n",
    "    # Update the rotation matrix\n",
    "    theta = reg_data['angle']*np.pi/180 + np.arcsin(mirisim_data.header['PC1_2'])\n",
    "    new_pc1_1, new_pc1_2 = -np.cos(theta), np.sin(theta)\n",
    "    new_pc2_1, new_pc2_2 =  np.sin(theta), np.cos(theta)\n",
    "    # Fill in the new WCS and write to file\n",
    "    mirisim_data.header['CRPIX1'] = new_crpix_1\n",
    "    mirisim_data.header['CRPIX2'] = new_crpix_2\n",
    "    mirisim_data.header['CRVAL1'] = new_crval_1\n",
    "    mirisim_data.header['CRVAL2'] = new_crval_2\n",
    "    mirisim_data.header['PC1_1'] = new_pc1_1\n",
    "    mirisim_data.header['PC1_2'] = new_pc1_2\n",
    "    mirisim_data.header['PC2_1'] = new_pc2_1\n",
    "    mirisim_data.header['PC2_2'] = new_pc2_2\n",
    "        \n",
    "    # Apply corrections \n",
    "    filt = wk_dir[wk_dir.find('F'):wk_dir.find('W')+1]\n",
    "    mirisim_data.data *= cor_facs[filt]\n",
    "    # Write to file\n",
    "    fits.writeto(wk_dir+'final_image.fits', mirisim_data.data, \n",
    "                 header=mirisim_data.header, overwrite=True)\n",
    "    # Write the weight image\n",
    "    wht_data = fits.open(os.path.join(wk_dir,'stage3_merged_image_resample.fits'))[3]\n",
    "    fits.writeto(os.path.join(wk_dir,'final_weight.fits'), wht_data.data, \n",
    "                 header=mirisim_data.header, overwrite=True)\n",
    "    \n",
    "    # Extract photometry (if needed)\n",
    "    if photo_flag:\n",
    "        # Do not save results immediately, as we need to correct WCS\n",
    "        img3.source_catalog.save_results = False\n",
    "        # Perform source detection and photometry extraction \n",
    "        # Parameters can be changed by img3.source_catalog.update_pars\n",
    "        # Use img3.source_catalog.get_pars to display current parameters\n",
    "        res_step5 = img3.source_catalog.run(res_step4)\n",
    "        # Correct for WCS\n",
    "        # Read the corrected WCS\n",
    "        cor_wcs = WCS(mirisim_data.header)\n",
    "        # Transform x,y to ra,dec\n",
    "        ras, decs = cor_wcs.all_pix2world(res_step5['xcentroid'], res_step5['ycentroid'], 0)\n",
    "        # Update ra,dec in res_step5 \n",
    "        for src_idx, _ in enumerate(res_step5):\n",
    "            res_step5['sky_centroid'][src_idx] = \\\n",
    "                SkyCoord(ras[src_idx],decs[src_idx], unit='deg')\n",
    "        # Save the catalog to file\n",
    "        res_step5.write(os.path.join(wk_dir,'photutils_catalog.fits'), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='photometry'></a>\n",
    "## Photometry tests\n",
    "\n",
    "The cells below are an example test, i.e., measured photometry vs. model-input photometry. This example test shows apparent magnitude offsets. This is expected, because the photutils is not fine-tuned when performing photometry (see above). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell define a function to match between two catalogs \n",
    "\n",
    "def match(ra1, de1, ra2, de2, rad, opt = 2, silent=False):\n",
    "    '''\n",
    "    This function will perform one-one match between two catalogs\n",
    "    \n",
    "    Inputs: \n",
    "        ra1, de1, ra2, de2: coordiantes in two catalogs, should be array-like unit: deg\n",
    "        rad: matching radius, unit: arcsec\n",
    "\n",
    "    Keywords:\n",
    "        opt: same as srcor.pro in IDL\n",
    "                0, source in catalog 2 may correspond to >1 sources in catalog 1\n",
    "                1, forced 1-1 match \n",
    "                2, forced 1-1 match, but the program will run two times. At the first run is to obtain the \n",
    "                   median coordinate offset between the two catalogs. Then we apply the offset to\n",
    "                   one catalog to eliminate the systematic difference. The second run is based on the\n",
    "                   updated coordinates. (default) \n",
    "        silent: True, do not display results for opt=0 or 1\n",
    "                False, display results (default)\n",
    "\n",
    "    Outputs:\n",
    "        id1, indexes of matched sources in catalog I \n",
    "        id2, indexes of matched sources in catalog II\n",
    "        dis, distances of the pairs, unit: arcsec \n",
    "    '''\n",
    "\n",
    "    # Format unification\n",
    "    ra1 = np.array(ra1)\n",
    "    de1 = np.array(de1)\n",
    "    ra2 = np.array(ra2)\n",
    "    de2 = np.array(de2)\n",
    "\n",
    "    # Check if all RA, DEC are float\n",
    "    if ( np.where(np.isfinite(ra1))[0].size != ra1.size ) | \\\n",
    "       ( np.where(np.isfinite(de1))[0].size != de1.size ) | \\\n",
    "       ( np.where(np.isfinite(ra2))[0].size != ra2.size ) | \\\n",
    "       ( np.where(np.isfinite(de2))[0].size != de2.size ) : \\\n",
    "        sys.exit('Error: non-float in ra,dec')\n",
    "\n",
    "    if ra1.shape != de1.shape:\n",
    "        raise ValueError('ra1 and dec1 do not match!')\n",
    "    if ra2.shape != de2.shape:\n",
    "        raise ValueError('ra2 and dec2 do not match!')\n",
    "\n",
    "    # Initial match, note that id_2 may contain repetitive elements\n",
    "    if opt == 0:\n",
    "        id1, id2, dis = _ini_match(ra1, de1, ra2, de2, rad/3600.)\n",
    "        if not(silent):\n",
    "            print('Multi-one match: ', len(id1), ' sources')\n",
    "        return id1, id2, dis*3600.\n",
    "\n",
    "    # First match, only the nearest neighbor is left when multi-to-one occurs\n",
    "    id1, id2, dis = _1st_match(ra1, de1, ra2, de2, rad/3600.)\n",
    "    if opt == 1:\n",
    "        if not(silent):\n",
    "            print('Forced one-one match: ', len(id1), ' sources')\n",
    "        return id1, id2, dis*3600.\n",
    "    print('First match: ', len(id1), ' sources')\n",
    "\n",
    "    # Second match, elliminate the offset\n",
    "    print( 'RA offset:', \\\n",
    "           np.median(ra1[id1] - ra2[id2]) * 3600 \\\n",
    "           * math.cos(np.deg2rad(np.median(de1))), 'arcsec', \\\n",
    "           'DEC offset:', \\\n",
    "           np.median(de1[id1] - de2[id2])*3600, 'arcsec')\n",
    "    ra2_new = ra2 + np.median(ra1[id1] - ra2[id2])\n",
    "    de2_new = de2 + np.median(de1[id1] - de2[id2])\n",
    "    id1, id2, dis = _1st_match(ra1, de1, ra2_new, de2_new, rad/3600.)\n",
    "    print('Second match: ', len(id1), ' sources')\n",
    "\n",
    "    return id1, id2, dis*3600\n",
    "            \n",
    "\n",
    "def _1st_match(ra1, de1, ra2, de2, rad):\n",
    "    '''\n",
    "    This function performs the forced 1-1 match. Similar to srcor.pro (opt=1) in IDL.\n",
    "    \n",
    "    Inputs: \n",
    "        ra1, de1, ra2, de2: coordiantes in two catalogs, unit: deg\n",
    "        rad: matching radius, unit: deg\n",
    "    \n",
    "    Outputs:\n",
    "        id1, indexes of matched sources in catalog I \n",
    "        id2, indexes of matched sources in catalog II\n",
    "        dis, distances of the pairs, unit: deg \n",
    "    '''\n",
    "\n",
    "    # Initial match, might produce multi-one match\n",
    "    id1, id2, dis = _ini_match(ra1, de1, ra2, de2, rad)\n",
    "\n",
    "    # Find the repetitive ones  (routine)\n",
    "    rep = defaultdict(list)\n",
    "    for i, item in enumerate(id2):\n",
    "        rep[item].append(i)\n",
    "    rep = {k:v for k,v in rep.items() if len(v) > 1}\n",
    "    # note that k is indexes in catalog II, v is indexes in the matching array\n",
    "\n",
    "    # For them, reserve the nearest one only\n",
    "    kill = []\n",
    "    for dum, idx in rep.items(): \n",
    "        dis_rep = dis[idx] # Their distances \n",
    "        best = dis_rep.argmin()  # Pick up the nearest one\n",
    "        kill.append(np.delete(idx, best)) # Creat the to-be-delete list\n",
    "\n",
    "    buf = np.arange(0) # Transform format from list to numpy array\n",
    "    while kill != []: \n",
    "        buf = np.append(buf, kill.pop())\n",
    "    kill = buf\n",
    "        \n",
    "    id1 = np.delete(id1, kill) # Remove them\n",
    "    id2 = np.delete(id2, kill)\n",
    "    dis = np.delete(dis, kill) \n",
    "\n",
    "    return id1, id2, dis\n",
    "\n",
    "\n",
    "def _ini_match(ra1, de1, ra2, de2, rad):\n",
    "    '''\n",
    "    This function is modified from pyspherematch.py, available at\n",
    "    https://gist.github.com/eteq/4599814\n",
    "    The main change is, turn to match_coordinates_sky (astropy) from KDTree (scipy).\n",
    "    Because the second is based on 'straight-line' distance rather than \n",
    "    'great-circle' distance.\n",
    "\n",
    "    Inputs: \n",
    "        ra1, de1, ra2, de2: coordiantes in two catalogs, unit: deg\n",
    "        rad: matching radius, unit: deg\n",
    "    \n",
    "    Outputs:\n",
    "        id1, indexes of matched sources in catalog I \n",
    "        id2, indexes of matched sources in catalog II\n",
    "        dis, distances of the pairs, unit: deg \n",
    "    '''\n",
    "\n",
    "    cor1 = SkyCoord(ra=ra1*u.deg, dec=de1*u.deg, frame='icrs') # Change to ICRS system\n",
    "    cor2 = SkyCoord(ra=ra2*u.deg, dec=de2*u.deg, frame='icrs')\n",
    "\n",
    "    id2, dis, buf = cor1.match_to_catalog_sky(cor2) # Match\n",
    "    dis = np.array(dis) # Drop the unit\n",
    "    id1 = np.arange(ra1.size)\n",
    "    if id2.size<=1:\n",
    "        id2 = np.array([id2])\n",
    "    else:\n",
    "        id2 = np.array(id2)\n",
    "\n",
    "    msk = dis < rad\t # Filter out those with distance > rad\n",
    "    id1 = id1[msk]\n",
    "    id2 = id2[msk]\n",
    "    dis = dis[msk]\n",
    "\n",
    "    return id1, id2, dis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will compare the input and measure photometry for a given CEERS MIRI pointing and band. \n",
    "\n",
    "**Set the pointing ID and band you want to compare in the first two lines (`pt_id` and `band`)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell makes a plot comparing measured vs. input photometry\n",
    "\n",
    "# Set the pointing ID and the band you want to compare \n",
    "pt_id = '7b'\n",
    "band = 'F770W'\n",
    "\n",
    "# Read the input the measured photometry\n",
    "input_cat = Table.read(os.path.join(data_dir,'model_cat/miri%s_src_sam.fits' %pt_id))\n",
    "meas_cat = Table.read(os.path.join('.','CEERS%s/%s/photutils_catalog.fits' %(pt_id, band)))\n",
    "\n",
    "# Extract ra & dec from photutils results\n",
    "phot_ras, phot_decs = [], []\n",
    "for row in meas_cat:\n",
    "    phot_ras.append(row['sky_centroid'].ra.deg)\n",
    "    phot_decs.append(row['sky_centroid'].dec.deg)\n",
    "# Match photutils and input sources \n",
    "input_phot_idxs, phot_input_idxs, ds = match(input_cat['ra'], input_cat['dec'], phot_ras, phot_decs, 1, opt=2)\n",
    "# Compare the magnitude \n",
    "input_mags = -2.5*np.log10(input_cat[input_phot_idxs][band])+23.9\n",
    "phot_mags = meas_cat['aper_total_abmag'][phot_input_idxs]\n",
    "# Plot mag. vs. mag\n",
    "plt.figure(figsize=(6,8))\n",
    "plt.subplot(211)\n",
    "plt.plot(input_mags, phot_mags, 'ko', alpha=0.5)\n",
    "plt.plot(range(31),'C3')\n",
    "plt.xlim(np.min(input_mags)*0.95, np.max(input_mags)*1.05)\n",
    "plt.ylim(np.min(input_mags)*0.95, np.max(input_mags)*1.05)\n",
    "#plt.xlim(20, 26)\n",
    "#plt.ylim(20, 26)\n",
    "plt.xlabel('model mag')\n",
    "plt.ylabel('photutils mag')\n",
    "# Plot det_mag vs. mag\n",
    "plt.subplot(212)\n",
    "plt.plot(input_mags, phot_mags-input_mags, 'ko', alpha=0.5)\n",
    "plt.plot([0,30],[0,0],'C3')\n",
    "plt.xlim(np.min(input_mags)*0.95, np.max(input_mags)*1.05)\n",
    "#plt.xlim(20, 26)\n",
    "plt.ylim(-2, 2)\n",
    "plt.xlabel('model mag')\n",
    "plt.ylabel(r'$\\Delta$mag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JWebbinar",
   "language": "python",
   "name": "jwebbinar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
